"""
Streamlit Dashboard (Korean) - V24 (Optimized Loading)
This version optimizes the initial data loading process by fetching all external APIs concurrently, significantly reducing the startup time of the application.

- Core Topic: 'The Impact of Climate Change on Employment'
- Key Upgrades:
  1) **Concurrent API Calls**: Implemented `concurrent.futures.ThreadPoolExecutor` to fetch the three main data sources (NASA, NOAA, World Bank) in parallel instead of sequentially.
  2) **Reduced Timeout**: The default timeout for individual API requests in the `retry_get` function has been reduced from 30 to 15 seconds to fail faster on unresponsive servers.
  3) **Improved User Experience**: The initial loading spinner now reflects the parallel fetching process, and the overall time to see the dashboard is much shorter.
"""

import io
import time
import datetime
import os
import json
from typing import Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor

import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.graph_objects as go
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from streamlit_lottie import st_lottie
import openpyxl # For Excel file handling

# = a============================================================================
# 0. CONFIGURATION & INITIAL SETUP
# ==============================================================================
st.set_page_config(
    page_title="Í∏∞ÌõÑ ÏúÑÍ∏∞Îäî ÌôòÍ≤ΩÏùÑ ÎÑòÏñ¥ Ï∑®ÏóÖÍπåÏßÄ ÌùîÎì†Îã§",
    page_icon="üåç",
    layout="wide"
)

# --- Custom CSS for Dark Mode UI ---
st.markdown("""
<style>
    /* Main background color set to dark */
    .stApp {
        background-color: #1E1E1E;
        color: #EAEAEA;
    }
    /* Headers color */
    h1, h2, h3, h4, h5, h6 {
        color: #FFFFFF;
    }
    /* Tab styles for dark mode */
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #1E1E1E; /* Match main background to remove box effect */
        border-radius: 4px 4px 0px 0px;
        border-bottom: 2px solid transparent;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
        color: #A0A0A0;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1E1E1E;
        border-bottom: 2px solid #0078F2; /* Bright blue highlight for active tab */
        color: #FFFFFF;
    }
    /* Metric styling for dark mode */
    div[data-testid="stMetricLabel"] {
        display: flex;
        align-items: center;
        color: #A0A0A0; /* Lighter gray for labels */
    }
    div[data-testid="stMetricValue"] {
        color: #FFFFFF; /* White for values */
    }
    /* Ensure Streamlit widgets have light text */
    .st-emotion-cache-1r6slb0, .st-emotion-cache-1y4p8pa {
        color: #EAEAEA;
    }
</style>
""", unsafe_allow_html=True)


# --- App constants ---
TODAY = datetime.datetime.now().date()
CONFIG = {
    "nasa_gistemp_url": "https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv",
    "worldbank_api_url": "https://api.worldbank.org/v2/country/all/indicator/SL.IND.EMPL.ZS",
    "noaa_co2_url": "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt",
    "lottie_home_url": "https://lottie.host/175b5a27-63f5-4220-8374-e32a13f789e9/5N7sBfSbB6.json",
    "lottie_career_game_url": "https://lottie.host/7e05e830-7456-4c31-b844-93b5a1b55909/Rk4yQO6fS3.json"
}
MEMO_FILE = "memos.json"

# --- Global Session with Retry Strategy ---
_SESSION = requests.Session()
_retry_strategy = Retry(
    total=5,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods=["HEAD", "GET", "OPTIONS"],
    backoff_factor=1
)
_adapter = HTTPAdapter(max_retries=_retry_strategy, pool_maxsize=10)
_SESSION.mount("https://", _adapter)
_SESSION.mount("http://", _adapter)


# ==============================================================================
# 1. UTILITY & DATA FUNCTIONS
# ==============================================================================
def retry_get(url: str, params: Optional[Dict] = None, **kwargs: Any) -> Optional[requests.Response]:
    headers = {'User-Agent': 'Mozilla/5.0 (compatible; StreamlitApp/1.0)'}
    error_message = ""
    try:
        resp = _SESSION.get(url, params=params, headers=headers, timeout=kwargs.get('timeout', 15), allow_redirects=True, verify=True)
        resp.raise_for_status()
        return resp
    except requests.exceptions.ConnectTimeout:
        error_message = f"**API(`{url.split('//')[1].split('/')[0]}`) Ïó∞Í≤∞ ÏãúÍ∞Ñ Ï¥àÍ≥º:** 15Ï¥à ÎÇ¥Ïóê ÏÑúÎ≤ÑÎ°úÎ∂ÄÌÑ∞ ÏùëÎãµÏùÑ Î∞õÏßÄ Î™ªÌñàÏäµÎãàÎã§. ÏÑúÎ≤ÑÍ∞Ä ÏùºÏãúÏ†ÅÏúºÎ°ú ÎäêÎ¶¨Í±∞ÎÇò, ÎÑ§Ìä∏ÏõåÌÅ¨ Ï†úÏïΩ ÎïåÎ¨∏Ïùº Ïàò ÏûàÏäµÎãàÎã§."
    except requests.exceptions.HTTPError as e:
        error_message = f"**API(`{url.split('//')[1].split('/')[0]}`) ÏÑúÎ≤Ñ Ïò§Î•ò:** ÏÑúÎ≤ÑÏóêÏÑú `{e.response.status_code}` Ïò§Î•òÎ•º Î∞òÌôòÌñàÏäµÎãàÎã§."
    except requests.exceptions.RequestException as e:
        error_message = f"**API(`{url.split('//')[1].split('/')[0]}`) ÏöîÏ≤≠ Ïã§Ìå®:** Ïù∏ÌÑ∞ÎÑ∑ Ïó∞Í≤∞ÏùÑ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî. ({e.__class__.__name__})"
    
    if error_message:
        if 'api_errors' not in st.session_state:
            st.session_state.api_errors = []
        if error_message not in st.session_state.api_errors:
            st.session_state.api_errors.append(error_message)
    return None

@st.cache_data(ttl=3600)
def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return pd.DataFrame()
    d = df.copy()
    if 'date' in d.columns:
        d['date'] = pd.to_datetime(d['date'], errors='coerce')
        d = d.dropna(subset=['date'])
        d = d[d['date'].dt.date <= TODAY]
    else:
        return pd.DataFrame()

    d['value'] = pd.to_numeric(d['value'], errors='coerce')
    subset_cols = ['date', 'group'] if 'group' in d.columns else ['date']
    d = d.drop_duplicates(subset=subset_cols)
    sort_cols = ['group', 'date'] if 'group' in d.columns else ['date']
    d = d.sort_values(sort_cols).reset_index(drop=True)
    if 'group' in d.columns:
        d['value'] = d.groupby('group')['value'].transform(lambda s: s.interpolate(method='linear', limit_direction='both'))
    else:
        d['value'] = d['value'].interpolate(method='linear', limit_direction='both')
    return d.dropna(subset=['value']).reset_index(drop=True)

# --- Data Fetching ---
@st.cache_data(ttl=3600)
def fetch_gistemp_csv() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["nasa_gistemp_url"])
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8', errors='replace')
        lines = content.split('\n')
        data_start_index = next((i for i, line in enumerate(lines) if line.strip().startswith('Year,')), -1)
        if data_start_index == -1: raise ValueError("CSV Header 'Year,' not found.")
        df = pd.read_csv(io.StringIO("\n".join(lines[data_start_index:])))
        df.columns = [c.strip() for c in df.columns]
        df_long = df.melt(id_vars=['Year'], value_vars=[m for m in ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'] if m in df.columns], var_name='Month', value_name='Anomaly')
        month_map = {name: num for num, name in enumerate(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], 1)}
        df_long['date'] = pd.to_datetime(df_long['Year'].astype(str) + '-' + df_long['Month'].map(month_map).astype(str), errors='coerce')
        df_final = df_long[['date']].copy()
        df_final['value'] = pd.to_numeric(df_long['Anomaly'], errors='coerce')
        df_final['group'] = 'ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò(‚ÑÉ)'
        return df_final.dropna(subset=['date', 'value'])
    except Exception as e:
        if 'api_errors' not in st.session_state: st.session_state.api_errors = []
        if f"**NASA GISTEMP Parsing Error:** `{e}`" not in st.session_state.api_errors: st.session_state.api_errors.append(f"**NASA GISTEMP Îç∞Ïù¥ÌÑ∞ ÌååÏã± Ïò§Î•ò:** `{e}`")
        return None

@st.cache_data(ttl=3600)
def fetch_noaa_co2_data() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["noaa_co2_url"])
    if resp is None: return None
    try:
        df = pd.read_csv(io.StringIO(resp.content.decode('utf-8')), comment='#', delim_whitespace=True, header=None, names=['year', 'month', 'decimal_date', 'average', 'interpolated', 'trend', 'days', 'uncertainty'])
        df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01')
        df_final = df[['date', 'interpolated']].rename(columns={'interpolated': 'value'})
        df_final['group'] = 'ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ppm)'
        return df_final[df_final['value'] > 0]
    except Exception as e:
        if 'api_errors' not in st.session_state: st.session_state.api_errors = []
        if f"**NOAA CO‚ÇÇ Parsing Error:** `{e}`" not in st.session_state.api_errors: st.session_state.api_errors.append(f"**NOAA CO‚ÇÇ Îç∞Ïù¥ÌÑ∞ ÌååÏã± Ïò§Î•ò:** `{e}`")
        return None

@st.cache_data(ttl=3600)
def fetch_worldbank_employment() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["worldbank_api_url"], params={'format': 'json', 'per_page': '20000'})
    if resp is None: return None
    try:
        data = resp.json()
        if not isinstance(data, list) or len(data) < 2 or not data[1]: return None
        df = pd.json_normalize(data[1])
        df = df[['country.value', 'countryiso3code', 'date', 'value']]
        df.columns = ['group', 'iso_code', 'year', 'value']
        df['date'] = pd.to_datetime(df['year'] + '-01-01', errors='coerce')
        return df[['date', 'group', 'iso_code', 'value']].dropna()
    except Exception as e:
        if 'api_errors' not in st.session_state: st.session_state.api_errors = []
        if f"**World Bank Parsing Error:** `{e}`" not in st.session_state.api_errors: st.session_state.api_errors.append(f"**World Bank Îç∞Ïù¥ÌÑ∞ ÌååÏã± Ïò§Î•ò:** `{e}`")
        return None

# --- Embedded Sample Data ---
@st.cache_data
def get_sample_climate_data() -> pd.DataFrame:
    csv_data = """date,value,group
2018-01-01,0.85,"ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò(‚ÑÉ) (ÏòàÏãú)"
2019-01-01,0.98,"ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò(‚ÑÉ) (ÏòàÏãú)"
2020-01-01,1.16,"ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò(‚ÑÉ) (ÏòàÏãú)"
2021-01-01,0.86,"ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò(‚ÑÉ) (ÏòàÏãú)"
2022-01-01,0.91,"ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò(‚ÑÉ) (ÏòàÏãú)"
2023-01-01,1.08,"ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò(‚ÑÉ) (ÏòàÏãú)"
2024-01-01,1.35,"ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò(‚ÑÉ) (ÏòàÏãú)"
"""
    return pd.read_csv(io.StringIO(csv_data))

@st.cache_data
def get_sample_co2_data() -> pd.DataFrame:
    csv_data = """date,value,group
2018-01-01,408.21,"ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ppm) (ÏòàÏãú)"
2019-01-01,410.92,"ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ppm) (ÏòàÏãú)"
2020-01-01,413.4,"ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ppm) (ÏòàÏãú)"
2021-01-01,415.4,"ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ppm) (ÏòàÏãú)"
2022-01-01,418.28,"ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ppm) (ÏòàÏãú)"
2023-01-01,420.51,"ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ppm) (ÏòàÏãú)"
2024-01-01,423.01,"ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ppm) (ÏòàÏãú)"
"""
    return pd.read_csv(io.StringIO(csv_data))

@st.cache_data
def get_sample_employment_data() -> pd.DataFrame:
    csv_data = """date,group,iso_code,value
2018-01-01,World (ÏòàÏãú),WLD,20.21
2020-01-01,World (ÏòàÏãú),WLD,20.53
2022-01-01,World (ÏòàÏãú),WLD,21.0
2024-01-01,World (ÏòàÏãú),WLD,21.4
2018-01-01,Korea (ÏòàÏãú),KOR,22.8
2020-01-01,Korea (ÏòàÏãú),KOR,23.2
2022-01-01,Korea (ÏòàÏãú),KOR,23.7
2024-01-01,Korea (ÏòàÏãú),KOR,24.1
"""
    return pd.read_csv(io.StringIO(csv_data))

@st.cache_data
def get_sample_korea_employment_data() -> pd.DataFrame:
    csv_data = """Ïó∞ÎèÑ,Ï∑®ÏóÖÏûê Ïàò (Îßå Î™Ö),Ïã§ÏóÖÎ•† (%)
2019,2712.3,3.8
2020,2690.4,4.0
2021,2727.3,3.7
2022,2808.9,2.9
2023,2841.6,2.8
2024,2869.8,2.8
"""
    return pd.read_csv(io.StringIO(csv_data))

# --- Helper Functions ---
@st.cache_data
def load_lottie_data(url: str):
    try:
        r = requests.get(url, timeout=15)
        if r.status_code == 200:
            return r.json()
    except requests.exceptions.RequestException:
        return None
    return None

def load_memos():
    try:
        if not os.path.exists(MEMO_FILE):
            with open(MEMO_FILE, "w", encoding="utf-8") as f:
                json.dump([], f)
        with open(MEMO_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

def save_memos(memos):
    with open(MEMO_FILE, "w", encoding="utf-8") as f:
        json.dump(memos, f, ensure_ascii=False, indent=4)

# ==============================================================================
# 2. UI RENDERING FUNCTIONS FOR TABS
# ==============================================================================
def display_home_tab(climate_df, co2_df, employment_df):
    col1, col2 = st.columns([0.6, 0.4])
    with col1:
        st.markdown("<h1 style='text-align: left;'>üåç Í∏∞ÌõÑ ÏúÑÍ∏∞Îäî<br>ÌôòÍ≤ΩÏùÑ ÎÑòÏñ¥, Ï∑®ÏóÖÍπåÏßÄ ÌùîÎì†Îã§</h1>", unsafe_allow_html=True)
        st.markdown("#### 1403 Í∂åÏ¥àÌòÑ, 1405 ÍπÄÎèôÌòÑ, 1410 Ïã†ÏàòÏïÑ, 1416 Ï°∞Ï†ïÎ™®")
        st.markdown("""
        Í∏∞ÌõÑÎ≥ÄÌôîÎäî Îçî Ïù¥ÏÉÅ Î®º ÎØ∏ÎûòÏùò Ïù¥ÏïºÍ∏∞Í∞Ä ÏïÑÎãôÎãàÎã§. 
        Ïö∞Î¶¨Ïùò **ÎØ∏Îûò ÏÇ∞ÏóÖ Íµ¨Ï°∞**ÏôÄ **Ïª§Î¶¨Ïñ¥**Î•º Í≤∞Ï†ïÏßìÎäî ÌïµÏã¨ Î≥ÄÏàòÍ∞Ä ÎêòÏóàÏäµÎãàÎã§.
        
        Ïù¥ ÎåÄÏãúÎ≥¥ÎìúÎäî Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞Î•º ÌÜµÌï¥ Í∏∞ÌõÑ Î≥ÄÌôîÍ∞Ä ÏßÅÏóÖ ÏÑ∏Í≥ÑÏóê ÎØ∏ÏπòÎäî ÏòÅÌñ•ÏùÑ Î∂ÑÏÑùÌïòÍ≥†,
        ÎØ∏ÎûòÎ•º Ï§ÄÎπÑÌïòÎäî Ï≤≠ÏÜåÎÖÑÎì§ÏóêÍ≤å ÌïÑÏöîÌïú Ïù∏ÏÇ¨Ïù¥Ìä∏ÏôÄ Ï†ÑÎûµÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§.
        """)
    with col2:
        lottie_home = load_lottie_data(CONFIG['lottie_home_url'])
        if lottie_home:
            st_lottie(lottie_home, height=300, key="home_lottie")
    
    st.markdown("---")
    st.subheader("üìä ÎåÄÏãúÎ≥¥Îìú ÌïµÏã¨ ÏßÄÌëú")
    
    mcol1, mcol2, mcol3 = st.columns(3)
    if not all(df.empty for df in [climate_df, co2_df, employment_df]):
        try:
            latest_climate = climate_df.sort_values('date', ascending=False).iloc[0]
            latest_co2 = co2_df.sort_values('date', ascending=False).iloc[0]
            mcol1.metric(label="üå°Ô∏è ÏµúÏã† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò", value=f"{latest_climate['value']:.2f} ‚ÑÉ", help=f"Í∏∞Ï§ÄÏùº: {latest_climate['date']:%Y-%m}")
            mcol2.metric(label="‚òÅÔ∏è ÏµúÏã† CO‚ÇÇ ÎÜçÎèÑ", value=f"{latest_co2['value']:.2f} ppm", help=f"Í∏∞Ï§ÄÏùº: {latest_co2['date']:%Y-%m}")
            mcol3.metric(label="üíº Í≥†Ïö© Îç∞Ïù¥ÌÑ∞ Íµ≠Í∞Ä Ïàò", value=f"{employment_df['group'].nunique()} Í∞ú")
        except (IndexError, ValueError, TypeError):
            st.info("ÌïµÏã¨ ÏßÄÌëúÎ•º Í≥ÑÏÇ∞Ìï† Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±Ìï©ÎãàÎã§.")
    else:
        st.info("Îç∞Ïù¥ÌÑ∞Î•º Î∂àÎü¨Ïò§Îäî Ï§ëÏù¥Í±∞ÎÇò API Ìò∏Ï∂úÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.")

    st.markdown("---")
    st.subheader("üöÄ Ï£ºÏöî Í∏∞Îä• Î∞îÎ°úÍ∞ÄÍ∏∞")
    
    qcol1, qcol2, qcol3 = st.columns(3)
    with qcol1:
        st.markdown("##### üìä Í∏ÄÎ°úÎ≤å ÎèôÌñ• Î∂ÑÏÑù")
        st.write("Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞Î°ú Í∏∞ÌõÑÏôÄ Í≥†Ïö©Ïùò ÌÅ∞ Í∑∏Î¶ºÏùÑ ÌôïÏù∏Ìï¥Î≥¥ÏÑ∏Ïöî.")
    with qcol2:
        st.markdown("##### üöÄ ÎÇòÏùò ÎØ∏Îûò ÏÑ§Í≥Ñ")
        st.write("Í∞ÑÎã®Ìïú ÏãúÎÆ¨Î†àÏù¥ÏÖòÏúºÎ°ú ÎÇòÏùò ÏÑ†ÌÉùÏù¥ ÎØ∏ÎûòÏóê ÎØ∏Ïπ† ÏòÅÌñ•ÏùÑ ÏòàÏ∏°Ìï¥Î≥¥ÏÑ∏Ïöî.")
    with qcol3:
        st.markdown("##### ‚úçÔ∏è Îã§Ïßê Í≥µÏú†ÌïòÍ∏∞")
        st.write("Í∏∞ÌõÑ ÏúÑÍ∏∞ ÎåÄÏùëÏùÑ ÏúÑÌïú ÎãπÏã†Ïùò ÏûëÏùÄ Ïã§Ï≤úÏùÑ Î™®ÎëêÏôÄ Í≥µÏú†Ìï¥Î≥¥ÏÑ∏Ïöî.")

    st.markdown("---")
    display_data_status()
    display_api_errors()

def display_data_status():
    st.subheader("Îç∞Ïù¥ÌÑ∞ Ï∂úÏ≤ò ÌòÑÌô©")
    status = st.session_state.get('data_status', {})
    cols = st.columns(3)
    status_map = {'Live': 'üü¢ Ïã§ÏãúÍ∞Ñ', 'Sample': 'üü° ÏòàÏãú'}
    cols[0].markdown(f"**NASA GISTEMP (Í∏∞Ïò®)**: {status_map.get(status.get('climate'), 'N/A')}")
    cols[1].markdown(f"**NOAA CO‚ÇÇ (Ïù¥ÏÇ∞ÌôîÌÉÑÏÜå)**: {status_map.get(status.get('co2'), 'N/A')}")
    cols[2].markdown(f"**World Bank (Í≥†Ïö©)**: {status_map.get(status.get('employment'), 'N/A')}")

def display_api_errors():
    if st.session_state.get('api_errors'):
        st.warning("‚ö†Ô∏è ÌïòÎÇò Ïù¥ÏÉÅÏùò Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ Î°úÎî©Ïóê Ïã§Ìå®ÌïòÏó¨ ÏòàÏãú Îç∞Ïù¥ÌÑ∞Î°ú ÎåÄÏ≤¥ÎêòÏóàÏäµÎãàÎã§.", icon="üì°")
        with st.expander("ÏÉÅÏÑ∏ Ïò§Î•ò Ï†ïÎ≥¥ Î≥¥Í∏∞"):
            for error in st.session_state.api_errors:
                st.error(error, icon="üî•")

def display_global_trends_tab(climate_df, co2_df, employment_df):
    st.subheader("üìà Í∏ÄÎ°úÎ≤å ÎèôÌñ•: Ïà´ÏûêÍ∞Ä ÎßêÌïòÎäî Í∏∞ÌõÑÏôÄ ÏùºÏûêÎ¶¨ Î≥ÄÌôî")
    
    col1, col2, col3 = st.columns(3)
    if not all(df.empty for df in [climate_df, co2_df, employment_df]):
        try:
            latest_climate = climate_df.sort_values('date', ascending=False).iloc[0]
            latest_co2 = co2_df.sort_values('date', ascending=False).iloc[0]
            col1.metric(label="üå°Ô∏è ÏµúÏã† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò", value=f"{latest_climate['value']:.2f} ‚ÑÉ", help=f"Í∏∞Ï§ÄÏùº: {latest_climate['date']:%Y-%m}")
            col2.metric(label="‚òÅÔ∏è ÏµúÏã† CO‚ÇÇ ÎÜçÎèÑ", value=f"{latest_co2['value']:.2f} ppm", help=f"Í∏∞Ï§ÄÏùº: {latest_co2['date']:%Y-%m}")
            col3.metric(label="üíº Í≥†Ïö© Îç∞Ïù¥ÌÑ∞ Íµ≠Í∞Ä Ïàò", value=f"{employment_df['group'].nunique()} Í∞ú")
        except (IndexError, ValueError, TypeError):
            st.info("ÌïµÏã¨ ÏßÄÌëúÎ•º Í≥ÑÏÇ∞Ìï† Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±Ìï©ÎãàÎã§.")
    else:
        st.info("Îç∞Ïù¥ÌÑ∞Î•º Î∂àÎü¨Ïò§Îäî Ï§ëÏù¥Í±∞ÎÇò API Ìò∏Ï∂úÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.")
    st.markdown("---")

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("##### üå°Ô∏è ÏßÄÍµ¨ ÌèâÍ∑† Ïò®ÎèÑ Ïù¥ÏÉÅÏπò")
        if not climate_df.empty:
            fig = px.line(climate_df, x='date', y='value', labels={'date': '', 'value': 'Ïò®ÎèÑ Ïù¥ÏÉÅÏπò (¬∞C)'}, color_discrete_sequence=['#d62728'])
            fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA')
            st.plotly_chart(fig, use_container_width=True)
    with c2:
        st.markdown("##### üí® ÎåÄÍ∏∞ Ï§ë CO‚ÇÇ ÎÜçÎèÑ (ÎßàÏö∞ÎÇòÎ°úÏïÑ)")
        if not co2_df.empty:
            fig = px.line(co2_df, x='date', y='value', labels={'date': '', 'value': 'CO‚ÇÇ (ppm)'}, color_discrete_sequence=['#1f77b4'])
            fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA')
            st.plotly_chart(fig, use_container_width=True)
    st.markdown("---")
    
    st.markdown("##### üè≠ ÏÇ∞ÏóÖÎ≥Ñ Í≥†Ïö© ÎπÑÏú® Î≥ÄÌôî")
    if not employment_df.empty:
        employment_df['year'] = pd.to_datetime(employment_df['date']).dt.year
        min_year, max_year = int(employment_df['year'].min()), int(employment_df['year'].max())
        selected_year = st.slider("Ïó∞ÎèÑ ÏÑ†ÌÉù:", min_year, max_year, max_year, key="map_year_slider")
        
        map_df = employment_df[employment_df['year'] == selected_year]
        if not map_df.empty:
            fig_map = px.choropleth(map_df, locations="iso_code", color="value", hover_name="group", color_continuous_scale=px.colors.sequential.Plasma, labels={'value': 'Í≥†Ïö© ÎπÑÏú® (%)'}, title=f"{selected_year}ÎÖÑ Ï†Ñ ÏÑ∏Í≥Ñ ÏÇ∞ÏóÖ Í≥†Ïö© ÎπÑÏú®")
            fig_map.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', geo=dict(bgcolor='rgba(0,0,0,0)'), font_color='#EAEAEA')
            st.plotly_chart(fig_map, use_container_width=True)

        all_countries = sorted(employment_df['group'].unique())
        default_countries = [c for c in ['World', 'Korea, Rep.', 'World (ÏòàÏãú)', 'Korea (ÏòàÏãú)'] if c in all_countries] or all_countries[:2]
        selected_countries = st.multiselect("Íµ≠Í∞ÄÎ≥Ñ Ï∂îÏù¥ ÎπÑÍµê:", all_countries, default=default_countries)
        if selected_countries:
            comp_df = employment_df[employment_df['group'].isin(selected_countries)]
            fig_comp = px.line(comp_df, x='year', y='value', color='group', labels={'year':'Ïó∞ÎèÑ', 'value':'ÏÇ∞ÏóÖ Í≥†Ïö© ÎπÑÏú®(%)', 'group':'Íµ≠Í∞Ä'})
            fig_comp.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA', legend=dict(font=dict(color='#EAEAEA')))
            st.plotly_chart(fig_comp, use_container_width=True)

def display_analysis_tab(climate_df, co2_df, employment_df):
    st.subheader("üîç Ïã¨Ï∏µ Î∂ÑÏÑù: Îç∞Ïù¥ÌÑ∞Î°ú Í¥ÄÍ≥Ñ Îì§Ïó¨Îã§Î≥¥Í∏∞")
    
    st.markdown("##### üîÑ Í∏∞ÌõÑ ÏßÄÌëú vs. Í∏ÄÎ°úÎ≤å ÏÇ∞ÏóÖ Í≥†Ïö© ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ")
    if any(df.empty for df in [climate_df, co2_df, employment_df]):
        st.warning("ÏÉÅÍ¥ÄÍ¥ÄÍ≥ÑÎ•º Î∂ÑÏÑùÌïòÍ∏∞ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±Ìï©ÎãàÎã§.")
    else:
        try:
            climate_df['year'] = pd.to_datetime(climate_df['date']).dt.year
            c_ann_agg = climate_df.groupby('year')['value'].mean().reset_index().rename(columns={'value':'temp_anomaly'})
            co2_df['year'] = pd.to_datetime(co2_df['date']).dt.year
            co2_ann_agg = co2_df.groupby('year')['value'].mean().reset_index().rename(columns={'value':'co2_ppm'})
            employment_df['year'] = pd.to_datetime(employment_df['date']).dt.year
            e_ann_agg = employment_df.groupby(['year'])['value'].median().reset_index().rename(columns={'value':'employment_median'})
            
            merged = pd.merge(c_ann_agg, e_ann_agg, on='year', how='inner')
            merged = pd.merge(merged, co2_ann_agg, on='year', how='inner')

            if len(merged) < 2:
                st.warning("Îç∞Ïù¥ÌÑ∞ Í∏∞Í∞ÑÏù¥ ÏßßÏïÑ ÏÉÅÍ¥ÄÍ¥ÄÍ≥ÑÎ•º Î∂ÑÏÑùÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
            else:
                corr_col1, corr_col2 = st.columns(2)
                corr_choice = corr_col1.selectbox("ÎπÑÍµêÌï† Í∏∞ÌõÑ ÏßÄÌëú:", ('Ïò®ÎèÑ Ïù¥ÏÉÅÏπò', 'CO‚ÇÇ ÎÜçÎèÑ'))
                normalize = corr_col2.checkbox("Îç∞Ïù¥ÌÑ∞ Ï†ïÍ∑úÌôî (Ï∂îÏÑ∏ ÎπÑÍµê)", help="Îã®ÏúÑÍ∞Ä Îã§Î•∏ Îëê Îç∞Ïù¥ÌÑ∞Î•º 0~1 ÏÇ¨Ïù¥ Í∞íÏúºÎ°ú Î≥ÄÌôòÌïòÏó¨ Ï∂îÏÑ∏ ÎπÑÍµêÎ•º Ïö©Ïù¥ÌïòÍ≤å Ìï©ÎãàÎã§.")
                
                x_var = 'temp_anomaly' if corr_choice == 'Ïò®ÎèÑ Ïù¥ÏÉÅÏπò' else 'co2_ppm'
                y_var = 'employment_median'
                
                plot_df = merged[['year', x_var, y_var]].copy()
                correlation = plot_df[x_var].corr(plot_df[y_var])
                st.metric(f"{corr_choice} vs. Í≥†Ïö© ÎπÑÏú® ÏÉÅÍ¥ÄÍ≥ÑÏàò", f"{correlation:.3f}")

                if normalize:
                    plot_df[x_var] = (plot_df[x_var] - plot_df[x_var].min()) / (plot_df[x_var].max() - plot_df[x_var].min())
                    plot_df[y_var] = (plot_df[y_var] - plot_df[y_var].min()) / (plot_df[y_var].max() - plot_df[y_var].min())
                
                fig_corr = go.Figure()
                fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[x_var], name=corr_choice, line=dict(color='#d62728')))
                fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[y_var], name='ÏÇ∞ÏóÖ Í≥†Ïö©(Ï†ÑÏÑ∏Í≥Ñ Ï§ëÏïôÍ∞í)', yaxis='y2', line=dict(color='#1f77b4')))
                fig_corr.update_layout(xaxis_title="Ïó∞ÎèÑ", yaxis_title=f"{corr_choice}" if not normalize else "Ï†ïÍ∑úÌôîÎêú Í∞í", yaxis2=dict(title="ÏÇ∞ÏóÖ Í≥†Ïö© ÎπÑÏú® (%)" if not normalize else "Ï†ïÍ∑úÌôîÎêú Í∞í", overlaying="y", side="right"), legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01),
                                     plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA', legend_font_color='#EAEAEA')
                st.plotly_chart(fig_corr, use_container_width=True)
        except Exception as e:
            st.error(f"Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}")
    st.markdown("---")

    st.markdown("##### üá∞üá∑ Íµ≠ÎÇ¥ Îç∞Ïù¥ÌÑ∞ Ïã¨Ï∏µ Î∂ÑÏÑù (e-ÎÇòÎùºÏßÄÌëú ÏÉòÌîå)")
    st.info("e-ÎÇòÎùºÏßÄÌëúÏùò 'Ï∑®ÏóÖÏûê Î∞è Ïã§ÏóÖÏûê' ÌÜµÍ≥Ñ ÏÉòÌîå Îç∞Ïù¥ÌÑ∞Î•º ÌôúÏö©ÌïòÏó¨ Íµ≠ÎÇ¥ Ï∑®ÏóÖ Îç∞Ïù¥ÌÑ∞ÏôÄ Í∏∞ÌõÑ Î≥ÄÌôîÏùò Í¥ÄÍ≥ÑÎ•º Î∂ÑÏÑùÌï©ÎãàÎã§.")
    
    korea_df = get_sample_korea_employment_data()
    
    temp_yearly = climate_df.groupby('year')['value'].mean().reset_index().rename(columns={'value':'temp_anomaly'})
    merged_korea = pd.merge(korea_df, temp_yearly, left_on='Ïó∞ÎèÑ', right_on='year', how='inner')
    
    if len(merged_korea) > 1:
        fig_korea = go.Figure()
        fig_korea.add_trace(go.Scatter(x=merged_korea['Ïó∞ÎèÑ'], y=merged_korea['Ïã§ÏóÖÎ•† (%)'], name='ÌïúÍµ≠ Ïã§ÏóÖÎ•† (%)', line=dict(color='#ff7f0e')))
        fig_korea.add_trace(go.Scatter(x=merged_korea['Ïó∞ÎèÑ'], y=merged_korea['temp_anomaly'], name='ÏßÄÍµ¨ Ïò®ÎèÑ Ïù¥ÏÉÅÏπò (‚ÑÉ)', yaxis='y2', line=dict(color='#d62728')))
        fig_korea.update_layout(title="ÌïúÍµ≠ Ïã§ÏóÖÎ•†Í≥º ÏßÄÍµ¨ Ïò®ÎèÑ Ïù¥ÏÉÅÏπò ÎπÑÍµê", xaxis_title="Ïó∞ÎèÑ", yaxis_title="Ïã§ÏóÖÎ•† (%)", yaxis2=dict(title="Ïò®ÎèÑ Ïù¥ÏÉÅÏπò (‚ÑÉ)", overlaying="y", side="right"),
                              plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA', legend_font_color='#EAEAEA')
        st.plotly_chart(fig_korea, use_container_width=True)
    else:
        st.warning("ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ÏôÄ Í∏∞ÌõÑ Îç∞Ïù¥ÌÑ∞Ïùò Í≥µÌÜµ Ïó∞ÎèÑÍ∞Ä Î∂ÄÏ°±ÌïòÏó¨ ÎπÑÍµê Ï∞®Ìä∏Î•º ÏÉùÏÑ±Ìï† Ïàò ÏóÜÏäµÎãàÎã§.")

def display_job_impact_tab():
    st.subheader("‚öñÔ∏è ÏßÅÎ¨¥ ÏòÅÌñ• Î∂ÑÏÑù: Í∏∞ÌöåÏôÄ ÏúÑÌóò")
    st.markdown("""
    ÌïµÏã¨ ÏõêÏù∏ÏùÄ **'ÎÖπÏÉâ Ï†ÑÌôò(Green Transition)'**ÏûÖÎãàÎã§. Í∏∞ÌõÑ ÎåÄÏùëÏùÑ ÏúÑÌï¥ ÏÇ¨Ìöå Ï†ÑÎ∞òÏù¥ ÏπúÌôòÍ≤Ω Í∏∞Ïà†ÏùÑ ÎèÑÏûÖÌïòÎ©¥ÏÑú ÏÉàÎ°úÏö¥ ÏßÅÎ¨¥Í∞Ä ÏÉùÍ≤®ÎÇòÍ≥† ÏûàÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§. 
    ÏïÑÎûò 'ÏßÅÎ¨¥ Ï†ÑÌôò ÌÉêÏÉâÍ∏∞'Î•º ÌÜµÌï¥ Í∏∞Ï°¥ ÏßÅÎ¨¥Í∞Ä Ïñ¥Îñ§ Í∏∞ÌöåÎ•º ÎßûÏù¥Ìï† Ïàò ÏûàÎäîÏßÄ ÏïåÏïÑÎ≥¥ÏÑ∏Ïöî.
    """)

    job_data = {
        'ÌôîÎ†• Î∞úÏ†ÑÏÜå Í∏∞Ïà†Ïûê': {
            'risk': 'Îß§Ïö∞ ÎÜíÏùå', 'icon': 'üî¥',
            'skills': ['Î∞úÏ†Ñ ÏÑ§ÎπÑ Ïö¥ÏòÅ', 'Í≥†Ïïï Ï†ÑÍ∏∞ Í¥ÄÎ¶¨', 'Í∏∞Í≥Ñ Ïú†ÏßÄÎ≥¥Ïàò'],
            'transitions': {
                'Ïã†Ïû¨ÏÉùÏóêÎÑàÏßÄ Î∞úÏ†Ñ Ï†ÑÎ¨∏Í∞Ä': ['ÌÉúÏñëÍ¥ë/ÌíçÎ†• ÏãúÏä§ÌÖú Ïù¥Ìï¥', 'ÏóêÎÑàÏßÄ Ï†ÄÏû• ÏãúÏä§ÌÖú(ESS)'],
                'Ïä§ÎßàÌä∏ Í∑∏Î¶¨Îìú Ï†ÑÎ¨∏Í∞Ä': ['Ï†ÑÎ†•Îßù ÏµúÏ†ÅÌôî', 'Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù']
            }
        },
        'ÏûêÎèôÏ∞® ÎÇ¥Ïó∞Í∏∞Í¥Ä ÏóîÏßÄÎãàÏñ¥': {
            'risk': 'ÎÜíÏùå', 'icon': 'üü†',
            'skills': ['ÏóîÏßÑ ÏÑ§Í≥Ñ', 'Ïó¥Ïó≠Ìïô', 'Í∏∞Í≥Ñ Í≥µÌïô'],
            'transitions': {
                'Ï†ÑÍ∏∞Ï∞® Î∞∞ÌÑ∞Î¶¨ ÏãúÏä§ÌÖú ÏóîÏßÄÎãàÏñ¥': ['Î∞∞ÌÑ∞Î¶¨ Í¥ÄÎ¶¨ ÏãúÏä§ÌÖú(BMS)', 'Ï†ÑÎ†• Ï†ÑÏûê'],
                'ÏàòÏÜåÏó∞Î£åÏ†ÑÏßÄ Í∞úÎ∞úÏûê': ['Ïó∞Î£åÏ†ÑÏßÄ Ïä§ÌÉù ÏÑ§Í≥Ñ', 'Í≥†Ïïï ÏàòÏÜå Ï†úÏñ¥']
            }
        },
        'ÏÑùÌÉÑ Í¥ëÎ∂Ä': {
            'risk': 'Îß§Ïö∞ ÎÜíÏùå', 'icon': 'üî¥',
            'skills': ['Ï±ÑÍµ¥ Í∏∞Ïà†', 'Ï§ëÏû•ÎπÑ Ïö¥Ïö©', 'ÏïàÏ†Ñ Í¥ÄÎ¶¨'],
            'transitions': {
                'ÏßÄÏó¥ ÏóêÎÑàÏßÄ Í∏∞Ïà†Ïûê': ['ÏãúÏ∂î Í∏∞Ïà†', 'ÌîåÎûúÌä∏ Ïö¥ÏòÅ'],
                'ÌÉúÏñëÍ¥ë/ÌíçÎ†• Îã®ÏßÄ Í±¥ÏÑ§ Î∞è Ïú†ÏßÄÎ≥¥Ïàò': ['Î∂ÄÏßÄ Í¥ÄÎ¶¨', 'Í±¥ÏÑ§ Í∏∞Ïà†']
            }
        },
        'Ï†ÑÌÜµ ÎÜçÏóÖ Ï¢ÖÏÇ¨Ïûê (ÎåÄÍ∑úÎ™® Îã®Ïùº ÏûëÎ¨º)': {
            'risk': 'Î≥¥ÌÜµ', 'icon': 'üü°',
            'skills': ['Í≤ΩÏûë Í∏∞Ïà†', 'Î≥ëÏ∂©Ìï¥ Í¥ÄÎ¶¨', 'ÎÜçÍ∏∞Í≥Ñ Ïö¥Ïö©'],
            'transitions': {
                'Ïä§ÎßàÌä∏Ìåú Ïö¥ÏòÅÏûê': ['Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù', 'ÏûêÎèôÌôî ÏãúÏä§ÌÖú Ï†úÏñ¥', 'IoT ÏÑºÏÑú ÌôúÏö©'],
                'Ï†ïÎ∞Ä ÎÜçÏóÖ Ïª®ÏÑ§ÌÑ¥Ìä∏': ['GIS/ÎìúÎ°† ÌôúÏö©', 'ÌÜ†Ïñë Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù']
            }
        },
        'ÏÑùÏú†ÌôîÌïô Í≥µÏû• Ïö¥ÏòÅÏõê': {
            'risk': 'ÎÜíÏùå', 'icon': 'üü†',
            'skills': ['ÌôîÌïô Í≥µÏ†ï Í¥ÄÎ¶¨', 'ÏïàÏ†Ñ Í¥ÄÎ¶¨', 'ÏÉùÏÇ∞ ÏµúÏ†ÅÌôî'],
            'transitions': {
                'Î∞îÏù¥Ïò§ÌîåÎùºÏä§Ìã± Ïó∞Íµ¨Ïõê': ['ÏÉùÎ∂ÑÌï¥ÏÑ± Í≥†Î∂ÑÏûê', 'Î∞îÏù¥Ïò§Îß§Ïä§ Ï≤òÎ¶¨'],
                'ÌÉÑÏÜå Ìè¨Ïßë/ÌôúÏö©(CCUS) Ï†ÑÎ¨∏Í∞Ä': ['ÌôîÌïô Ìù°ÏàòÎ≤ï', 'Î∂ÑÎ¶¨Îßâ Í∏∞Ïà†']
            }
        }
    }

    selected_job = st.selectbox("Ï†ÑÌôò Í∞ÄÎä•ÏÑ±ÏùÑ ÌÉêÏÉâÌï† ÏßÅÎ¨¥Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî:", list(job_data.keys()))

    if selected_job:
        data = job_data[selected_job]
        st.markdown(f"### {selected_job}")
        
        c1, c2, c3 = st.columns(3)
        c1.markdown(f"**Ï†ÑÌôò ÏúÑÌóòÎèÑ**\n\n## {data['icon']} {data['risk']}")
        
        with c2:
            st.markdown("**Î≥¥Ïú† ÌïµÏã¨ Ïó≠Îüâ**")
            for skill in data['skills']:
                st.markdown(f"- {skill}")
        with c3:
            st.markdown("**ÎØ∏Îûò Ï†ÑÌôò Ï∂îÏ≤ú ÏßÅÎ¨¥**")
            for job, skills in data['transitions'].items():
                st.markdown(f"**- {job}**")
                st.markdown(f"<small> (ÌïÑÏöî Ïó≠Îüâ: {', '.join(skills)})</small>", unsafe_allow_html=True)


def display_career_game_tab():
    st.subheader("üöÄ ÎÇòÏùò ÎØ∏Îûò ÏÑ§Í≥ÑÌïòÍ∏∞ (Ïª§Î¶¨Ïñ¥ ÏãúÎÆ¨Î†àÏù¥ÏÖò)")
    st.info("ÎãπÏã†Ïùò ÏÑ†ÌÉùÏù¥ 10ÎÖÑ ÌõÑ Ïª§Î¶¨Ïñ¥ÏôÄ ÌôòÍ≤ΩÏóê Ïñ¥Îñ§ ÏòÅÌñ•ÏùÑ ÎØ∏ÏπòÎäîÏßÄ ÏãúÎÆ¨Î†àÏù¥ÏÖò Ìï¥Î≥¥ÏÑ∏Ïöî!")
    
    game_col, form_col = st.columns([0.4, 0.6])

    with game_col:
        lottie_career = load_lottie_data(CONFIG['lottie_career_game_url'])
        if lottie_career:
            st_lottie(lottie_career, height=400, key="career_lottie")
        
        st.markdown("""
        ##### üí° Í∏∞ÌõÑ ÏúÑÍ∏∞Î•º Í∏∞ÌöåÎ°ú Î∞îÍæ∏Îäî Ï†ÑÎûµ
        - **Îç∞Ïù¥ÌÑ∞ ÌÉêÍµ¨:** Í∏∞ÌõÑÏôÄ ÏÇ∞ÏóÖ ÌÜµÍ≥ÑÎ•º Î∂ÑÏÑùÌïòÎ©∞ Î≥ÄÌôîÎ•º ÏòàÏ∏°Ìï©ÎãàÎã§.
        - **ÏúµÌï© ÌîÑÎ°úÏ†ùÌä∏:** ÏûêÏã†Ïùò Ï†ÑÍ≥µÍ≥º Í∏∞ÌõÑ ÏúÑÍ∏∞ Î¨∏Ï†úÎ•º Ïó∞Í≤∞ÌïòÎäî ÌîÑÎ°úÏ†ùÌä∏Î•º ÏàòÌñâÌï©ÎãàÎã§.
        - **Î™©ÏÜåÎ¶¨ ÎÇ¥Í∏∞:** Í∏∞ÌõÑ ÎåÄÏùëÍ≥º Ï≤≠ÎÖÑ Í≥†Ïö© Ï∞ΩÏ∂úÏùÑ Ïó∞Í≤∞ÌïòÏó¨ Ï†ïÏ±ÖÏùÑ Ï†úÏïàÌï©ÎãàÎã§.
        """)

    with form_col:
        with st.form("career_game_form"):
            st.markdown("##### üéì 1Îã®Í≥Ñ: ÎåÄÌïôÏÉù")
            major = st.radio("Ï£ºÏöî Ï†ÑÍ≥µ:", ("Ïª¥Ìì®ÌÑ∞Í≥µÌïô (AI Ìä∏Îûô)", "Í∏∞Í≥ÑÍ≥µÌïô", "Í≤ΩÏ†úÌïô"), key="major", horizontal=True)
            project = st.radio("Ï°∏ÏóÖ ÌîÑÎ°úÏ†ùÌä∏:", ("ÌÉÑÏÜå Î∞∞Ï∂úÎüâ ÏòàÏ∏° AI Î™®Îç∏", "Í≥†Ìö®Ïú® ÎÇ¥Ïó∞Í∏∞Í¥Ä ÏÑ§Í≥Ñ", "ESG Í≤ΩÏòÅÏÇ¨Î°Ä Î∂ÑÏÑù"), key="project")

            st.markdown("##### üíº 2Îã®Í≥Ñ: ÏÇ¨ÌöåÏ¥àÎÖÑÏÉù")
            first_job = st.radio("Ï≤´ ÏßÅÏû•:", ("ÏóêÎÑàÏßÄ IT Ïä§ÌÉÄÌä∏ÏóÖ", "ÎåÄÍ∏∞ÏóÖ Ï†ïÏú†ÌöåÏÇ¨", "Í∏àÏúµÍ∂å Ïï†ÎÑêÎ¶¨Ïä§Ìä∏"), key="first_job")
            skill_dev = st.radio("ÌïµÏã¨ Ïó≠Îüâ Í∞úÎ∞ú:", ("ÌÅ¥ÎùºÏö∞Îìú Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù", "Ï†ÑÌÜµ Í≥µÏ†ï Í¥ÄÎ¶¨", "Ïû¨Î¨¥ Î∂ÑÏÑù Î∞è Ìà¨Ïûê"), key="skill_dev")
            
            submitted = st.form_submit_button("üöÄ ÎÇòÏùò ÎØ∏Îûò ÌôïÏù∏ÌïòÍ∏∞")

        if submitted:
            career_score, green_score = 0, 0
            skills = {"Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù":0, "Ï†ïÏ±Ö/Í≤ΩÏòÅ":0, "ÏóîÏßÄÎãàÏñ¥ÎßÅ":0, "Í∏àÏúµ/Í≤ΩÏ†ú":0}

            if major == "Ïª¥Ìì®ÌÑ∞Í≥µÌïô (AI Ìä∏Îûô)": career_score += 20; green_score += 10; skills["Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù"] += 2
            elif major == "Í∏∞Í≥ÑÍ≥µÌïô": career_score += 10; skills["ÏóîÏßÄÎãàÏñ¥ÎßÅ"] += 2
            else: career_score += 15; green_score += 5; skills["Í∏àÏúµ/Í≤ΩÏ†ú"] += 2
            if project == "ÌÉÑÏÜå Î∞∞Ï∂úÎüâ ÏòàÏ∏° AI Î™®Îç∏": career_score += 15; green_score += 20; skills["Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù"] += 1; skills["Ï†ïÏ±Ö/Í≤ΩÏòÅ"] += 1
            elif project == "Í≥†Ìö®Ïú® ÎÇ¥Ïó∞Í∏∞Í¥Ä ÏÑ§Í≥Ñ": career_score += 5; green_score -= 10; skills["ÏóîÏßÄÎãàÏñ¥ÎßÅ"] += 1
            else: career_score += 10; green_score += 10; skills["Ï†ïÏ±Ö/Í≤ΩÏòÅ"] += 1; skills["Í∏àÏúµ/Í≤ΩÏ†ú"] += 1
            if first_job == "ÏóêÎÑàÏßÄ IT Ïä§ÌÉÄÌä∏ÏóÖ": career_score += 15; green_score += 20
            elif first_job == "ÎåÄÍ∏∞ÏóÖ Ï†ïÏú†ÌöåÏÇ¨": career_score += 20; green_score -= 10
            else: career_score += 15; green_score += 5
            if skill_dev == "ÌÅ¥ÎùºÏö∞Îìú Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù": career_score += 20; green_score += 10; skills["Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù"] += 2
            elif skill_dev == "Ï†ÑÌÜµ Í≥µÏ†ï Í¥ÄÎ¶¨": career_score += 10; green_score -= 5; skills["ÏóîÏßÄÎãàÏñ¥ÎßÅ"] += 1
            else: career_score += 15; skills["Í∏àÏúµ/Í≤ΩÏ†ú"] += 1
            
            if green_score >= 50 and career_score >= 70: job_title = "Í∏∞ÌõÑ Í∏∞Ïà† ÏµúÍ≥† Ï†ÑÎ¨∏Í∞Ä"
            elif green_score >= 30 and career_score >= 60: job_title = "Í∑∏Î¶∞ ÏóêÎÑàÏßÄ Ï†ÑÎûµÍ∞Ä"
            else: job_title = "ÎØ∏Îûò Ï§ÄÎπÑÌòï Ïù∏Ïû¨"

            st.markdown("##### üéâ ÏµúÏ¢Ö Í≤∞Í≥º: ÎãπÏã†Ïùò Ïª§Î¶¨Ïñ¥ Ïπ¥Îìú")
            res1, res2 = st.columns([0.6, 0.4])
            with res1:
                st.markdown(f"#### üíº **ÏßÅÏóÖ:** {job_title}")
                st.metric("üöÄ ÎØ∏Îûò Ï†ÑÎßù Ï†êÏàò", f"{career_score} / 100")
                st.metric("üå± ÌôòÍ≤Ω Í∏∞Ïó¨ÎèÑ Ï†êÏàò", f"{green_score} / 75")
            with res2:
                df_skills = pd.DataFrame(dict(r=list(skills.values()), theta=list(skills.keys())))
                fig = px.line_polar(df_skills, r='r', theta='theta', line_close=True, range_r=[0,5], title="ÎÇòÏùò Ïó≠Îüâ Î†àÏù¥Îçî Ï∞®Ìä∏")
                fig.update_layout(
                    polar=dict(
                        bgcolor = 'rgba(0,0,0,0)',
                        radialaxis=dict(visible=True, range=[0, 5], tickfont=dict(color='#EAEAEA')),
                        angularaxis=dict(tickfont=dict(size=12, color='#EAEAEA'))
                    ),
                    paper_bgcolor='rgba(0,0,0,0)',
                    margin=dict(l=60, r=60, t=80, b=60),
                    font_color='#EAEAEA'
                )
                st.plotly_chart(fig, use_container_width=True)

def display_memo_board_tab():
    st.subheader("‚úçÔ∏è ÎÇòÏùò Ïã§Ï≤ú Îã§Ïßê ÎÇ®Í∏∞Í∏∞ (Í≥µÏú† Î∞©Î™ÖÎ°ù)")
    st.markdown("Í∏∞ÌõÑ ÏúÑÍ∏∞ ÎåÄÏùëÏùÑ ÏúÑÌïú Ïó¨Îü¨Î∂ÑÏùò Îã§ÏßêÏùÑ ÎÇ®Í≤®Ï£ºÏÑ∏Ïöî! Î™®Îì† Î∞©Î¨∏ÏûêÏóêÍ≤å Í≥µÏú†Îê©ÎãàÎã§.")
    
    with st.form("memo_form"):
        cols = st.columns([0.7, 0.3])
        with cols[0]:
            name = st.text_input("ÎãâÎÑ§ÏûÑ", placeholder="ÏûêÏã†ÏùÑ ÌëúÌòÑÌïòÎäî Î©ãÏßÑ ÎãâÎÑ§ÏûÑÏùÑ Ï†ÅÏñ¥Ï£ºÏÑ∏Ïöî!", key="memo_name")
            memo = st.text_area("Ïã§Ï≤ú Îã§Ïßê", placeholder="Ïòà) ÌÖÄÎ∏îÎü¨ ÏÇ¨Ïö©ÌïòÍ∏∞, Í∞ÄÍπåÏö¥ Í±∞Î¶¨Îäî Í±∏Ïñ¥Îã§ÎãàÍ∏∞ Îì±", key="memo_text")
        with cols[1]:
            color = st.color_picker("Î©îÎ™®ÏßÄ ÏÉâÏÉÅ ÏÑ†ÌÉù", "#FFFACD", key="memo_color")
            submitted = st.form_submit_button("Îã§Ïßê ÎÇ®Í∏∞Í∏∞!", use_container_width=True)
            if submitted:
                if name and memo:
                    all_memos = load_memos()
                    all_memos.insert(0, {"name": name, "memo": memo, "color": color, "timestamp": str(datetime.datetime.now())})
                    save_memos(all_memos)
                    st.balloons()
                    st.success("ÏÜåÏ§ëÌïú Îã§ÏßêÏù¥ Î™®ÎëêÏóêÍ≤å Í≥µÏú†ÎêòÏóàÏäµÎãàÎã§!")
                else:
                    st.warning("ÎãâÎÑ§ÏûÑÍ≥º Îã§ÏßêÏùÑ Î™®Îëê ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî!")
    st.markdown("---")

    st.markdown("##### üí¨ Ïö∞Î¶¨Ïùò Îã§ÏßêÎì§")
    memos_list = load_memos()
    
    if not memos_list:
        st.info("ÏïÑÏßÅ ÏûëÏÑ±Îêú Îã§ÏßêÏù¥ ÏóÜÏñ¥Ïöî. Ï≤´ Î≤àÏß∏ Îã§ÏßêÏùÑ ÎÇ®Í≤®Ï£ºÏÑ∏Ïöî!")
    else:
        memo_cols = st.columns(3)
        for i, m in enumerate(memos_list):
            with memo_cols[i % 3]:
                st.markdown(f"""
                <div style="background-color:{m.get('color', '#FFFACD')}; border-left: 5px solid #FF6347; border-radius: 8px; padding: 15px; margin-bottom: 20px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); height: 180px;">
                    <p style="font-size: 1.1em; color: black; margin-bottom: 10px;">"{m.get('memo', '')}"</p>
                    <strong style="font-size: 0.9em; color: #555;">- {m.get('name', '')} -</strong>
                </div>
                """, unsafe_allow_html=True)

def display_survey_tab():
    st.subheader("üìù ÏÑ§Î¨∏ Î∞è ÏùòÍ≤¨")
    st.markdown("Í∏∞ÌõÑ Î≥ÄÌôîÏôÄ ÎØ∏Îûò ÏßÅÏóÖÏóê ÎåÄÌïú Ïó¨Îü¨Î∂ÑÏùò ÏÜåÏ§ëÌïú ÏùòÍ≤¨ÏùÑ Îì§Î†§Ï£ºÏÑ∏Ïöî!")

    with st.form("survey_form"):
        st.markdown("##### Í∞úÏù∏ Ïù∏Ïãù Î∞è ÌñâÎèô")
        q1 = st.radio("1Ô∏è‚É£ Í∏∞ÌõÑÎ≥ÄÌôîÍ∞Ä ÎÇòÏùò ÏßÅÏóÖ(ÎòêÎäî ÎØ∏Îûò ÏßÅÏóÖ)Ïóê ÏòÅÌñ•ÏùÑ Ï§Ñ Í≤ÉÏù¥Îùº ÏÉùÍ∞ÅÌïòÏãúÎÇòÏöî?", ["Îß§Ïö∞ Í∑∏Î†áÎã§", "Ï°∞Í∏à Í∑∏Î†áÎã§", "Î≥ÑÎ°ú ÏïÑÎãàÎã§", "Ï†ÑÌòÄ ÏïÑÎãàÎã§"])
        q2 = st.radio("2Ô∏è‚É£ Í∏∞ÌõÑÎ≥ÄÌôî ÏúÑÍ∏∞Ïùò Ïã¨Í∞ÅÏÑ±ÏùÑ Ïñ¥Îäê Ï†ïÎèÑÎ°ú ÎäêÎÅºÏãúÎÇòÏöî?", ["Îß§Ïö∞ Ïã¨Í∞ÅÌïòÎã§", "Ïñ¥Îäê Ï†ïÎèÑ Ïã¨Í∞ÅÌïòÎã§", "Î≥¥ÌÜµÏù¥Îã§", "Ïã¨Í∞ÅÌïòÏßÄ ÏïäÎã§"])
        q3 = st.multiselect("3Ô∏è‚É£ ÌèâÏÜåÏóê Ïã§Ï≤úÌïòÍ≥† ÏûàÎäî ÏπúÌôòÍ≤Ω ÌôúÎèôÏù¥ ÏûàÎã§Î©¥ Î™®Îëê ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî.", ["Î∂ÑÎ¶¨ÏàòÍ±∞ Ï≤†Ï†ÄÌûà ÌïòÍ∏∞", "ÎåÄÏ§ëÍµêÌÜµ/ÏûêÏ†ÑÍ±∞ Ïù¥Ïö©", "ÏùºÌöåÏö©Ìíà ÏÇ¨Ïö© Ï§ÑÏù¥Í∏∞", "ÏóêÎÑàÏßÄ Ï†àÏïΩ(ÏΩòÏÑºÌä∏ ÎΩëÍ∏∞ Îì±)", "Ï±ÑÏãù/Ïú°Î•ò ÏÜåÎπÑ Ï§ÑÏù¥Í∏∞", "ÏóÜÏùå"])

        st.markdown("##### ÏßÅÏóÖ Î∞è ÍµêÏú°")
        q4 = st.selectbox("4Ô∏è‚É£ Í∞ÄÏû• Ïú†ÎßùÌïòÎã§Í≥† ÏÉùÍ∞ÅÌïòÎäî ÎÖπÏÉâ ÏùºÏûêÎ¶¨ Î∂ÑÏïºÎäî Î¨¥ÏóáÏù∏Í∞ÄÏöî?", ["Ïã†Ïû¨ÏÉùÏóêÎÑàÏßÄ", "ESG Ïª®ÏÑ§ÌåÖ", "ÏπúÌôòÍ≤Ω ÏÜåÏû¨ Í∞úÎ∞ú", "Í∏∞ÌõÑ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù", "Ï†ÑÍ∏∞/ÏàòÏÜåÏ∞®"])
        q5 = st.slider("5Ô∏è‚É£ ÎØ∏Îûò ÏßÅÏóÖÏùÑ ÏúÑÌï¥ Í∏∞ÌõÑÎ≥ÄÌôî Í¥ÄÎ†® Ïó≠ÎüâÏùÑ ÌÇ§Ïö∏ ÏùòÌñ•Ïù¥ Ïñ¥Îäê Ï†ïÎèÑÏù∏Í∞ÄÏöî? (0~10Ï†ê)", 0, 10, 7)
        q6 = st.multiselect("6Ô∏è‚É£ ÎÖπÏÉâ ÏùºÏûêÎ¶¨ Ï†ÑÌôòÏùÑ ÏúÑÌï¥ Í∞ÄÏû• ÌïÑÏöîÌïòÎã§Í≥† ÏÉùÍ∞ÅÌïòÎäî ÏßÄÏõêÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? (Ï§ëÎ≥µ ÏÑ†ÌÉù Í∞ÄÎä•)", ["Ï†ÑÎ¨∏ Ïû¨ÍµêÏú° ÌîÑÎ°úÍ∑∏Îû®", "Ï†ïÎ∂ÄÏùò Ïû¨Ï†ï ÏßÄÏõê", "Í∏∞ÏóÖÏùò Ï±ÑÏö© Ïó∞Í≥Ñ", "ÏßÑÎ°ú Î©òÌÜ†ÎßÅ Î∞è ÏÉÅÎã¥"])

        st.markdown("##### Í∏∞ÏóÖ Î∞è ÏÇ¨Ìöå Ï†ïÏ±Ö")
        q7 = st.radio("7Ô∏è‚É£ Í∏∞ÌõÑÎ≥ÄÌôî ÎåÄÏùëÏùÑ ÏúÑÌï¥ Í∏∞ÏóÖÏùò Ïó≠Ìï†Ïù¥ ÏñºÎßàÎÇò Ï§ëÏöîÌïòÎã§Í≥† ÏÉùÍ∞ÅÌïòÏãúÎÇòÏöî?", ["Îß§Ïö∞ Ï§ëÏöîÌïòÎã§", "Ï§ëÏöîÌïòÎã§", "Î≥¥ÌÜµÏù¥Îã§", "Ï§ëÏöîÌïòÏßÄ ÏïäÎã§"])
        q8 = st.radio("8Ô∏è‚É£ Í∏∞ÌõÑÎ≥ÄÌôî ÎåÄÏùëÏùÑ ÏúÑÌïú ÏÑ∏Í∏à(ÌÉÑÏÜåÏÑ∏ Îì±) Ï∂îÍ∞Ä Î∂ÄÎã¥Ïóê ÎèôÏùòÌïòÏãúÎÇòÏöî?", ["Ï†ÅÍ∑π Ï∞¨ÏÑ±", "Ï∞¨ÏÑ±ÌïòÎäî Ìé∏", "Î∞òÎåÄÌïòÎäî Ìé∏", "Ï†ÅÍ∑π Î∞òÎåÄ"])
        
        submitted = st.form_submit_button("ÏÑ§Î¨∏ Ï†úÏ∂úÌïòÍ∏∞")

    if submitted:
        st.success("‚úÖ ÏÑ§Î¨∏Ïóê Ï∞∏Ïó¨Ìï¥Ï£ºÏÖîÏÑú Í∞êÏÇ¨Ìï©ÎãàÎã§! ÏïÑÎûòÎäî ÎÇòÏùò ÏùëÎãµ ÏöîÏïΩÏûÖÎãàÎã§.")
        st.markdown("##### üìã ÎÇòÏùò ÏùëÎãµ ÏöîÏïΩ")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ÏßÅÏóÖ ÏòÅÌñ• Ïù∏Ïãù:** {q1}")
            st.write(f"**ÏúÑÍ∏∞ Ïã¨Í∞ÅÏÑ± Ïù∏Ïãù:** {q2}")
            st.write(f"**Ïú†Îßù ÎÖπÏÉâ ÏùºÏûêÎ¶¨:** {q4}")
            st.write(f"**Í∏∞ÏóÖ Ïó≠Ìï† Ï§ëÏöîÎèÑ:** {q7}")
            st.write(f"**ÌÉÑÏÜåÏÑ∏ ÎèôÏùò:** {q8}")
        with col2:
            fig = go.Figure(go.Indicator(
                mode = "gauge+number", value = q5,
                title = {'text': "ÎÇòÏùò Ïó≠Îüâ Í∞úÎ∞ú ÏùòÏßÄ Ï†êÏàò"},
                gauge = {'axis': {'range': [None, 10]}, 'bar': {'color': "#2ca02c"}}))
            fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA')
            st.plotly_chart(fig, use_container_width=True)

def display_learn_more_tab():
    st.subheader("üìö Îçî ÏïåÏïÑÎ≥¥Í∏∞: Í¥ÄÎ†® Ï†ïÎ≥¥ Î∞è ÏÇ¨Ïù¥Ìä∏")
    
    st.markdown("##### üíº ÎÖπÏÉâ ÏùºÏûêÎ¶¨ Ï±ÑÏö© Ï†ïÎ≥¥")
    st.markdown("""
    - [ÏõåÌÅ¨ÎÑ∑ - ÎÖπÏÉâ ÏùºÏûêÎ¶¨](https://www.work.go.kr/greenWork/main.do)
    - [ÌôòÍ≤ΩÎ∂Ä ÌôòÍ≤ΩÏÇ∞ÏóÖÍ∏∞Ïà†Ïõê - ÌôòÍ≤ΩÏùºÏûêÎ¶¨](https://www.job.keiti.re.kr/)
    - [Ïù∏ÌÅ¨Î£®Ìä∏ - ÎÖπÏÉâÍ∏àÏúµ/ÏÇ∞ÏóÖ Ï±ÑÏö©Í¥Ä](https://green.incruit.com/)
    """)
    st.markdown("---")

    st.markdown("##### üéì ÍµêÏú° Î∞è ÌïôÏäµ ÏûêÎ£å")
    st.markdown("""
    - [K-MOOC - Í∏∞ÌõÑÎ≥ÄÌôî Í¥ÄÎ†® Í∞ïÏ¢å](http://www.kmooc.kr/search?query=%EA%B8%B0%ED%9B%84%EB%B3%80%ED%99%94)
    - [ÌôòÍ≤ΩÍµêÏú°Ìè¨ÌÑ∏](https://www.keep.go.kr/portal/1)
    """)
    st.markdown("---")

    st.markdown("##### üìä Îç∞Ïù¥ÌÑ∞ Î∞è Î≥¥Í≥†ÏÑú Ï∂úÏ≤ò")
    st.markdown("""
    - [NASA: GISS Surface Temperature Analysis](https://data.giss.nasa.gov/gistemp/)
    - [NOAA: Global Monitoring Laboratory - CO‚ÇÇ Data](https://gml.noaa.gov/ccgg/trends/)
    - [The World Bank: Data](https://data.worldbank.org/)
    - [e-ÎÇòÎùºÏßÄÌëú](https://www.index.go.kr/)
    """)

# ==============================================================================
# 3. MAIN APPLICATION LOGIC
# ==============================================================================
def main():
    if 'data_loaded' not in st.session_state:
        st.session_state.data_status = {}
        st.session_state.api_errors = []

        with st.spinner("Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞Î•º Î≥ëÎ†¨Î°ú Îπ†Î•¥Í≤å Î∂àÎü¨Ïò§Îäî Ï§ëÏûÖÎãàÎã§..."):
            with ThreadPoolExecutor(max_workers=3) as executor:
                future_climate = executor.submit(fetch_gistemp_csv)
                future_co2 = executor.submit(fetch_noaa_co2_data)
                future_employment = executor.submit(fetch_worldbank_employment)

                climate_raw = future_climate.result()
                co2_raw = future_co2.result()
                wb_employment_raw = future_employment.result()
            
            st.session_state.data_status['climate'] = 'Live' if climate_raw is not None and not climate_raw.empty else 'Sample'
            st.session_state.climate_df = preprocess_dataframe(climate_raw if st.session_state.data_status['climate'] == 'Live' else get_sample_climate_data())

            st.session_state.data_status['co2'] = 'Live' if co2_raw is not None and not co2_raw.empty else 'Sample'
            st.session_state.co2_df = preprocess_dataframe(co2_raw if st.session_state.data_status['co2'] == 'Live' else get_sample_co2_data())

            st.session_state.data_status['employment'] = 'Live' if wb_employment_raw is not None and not wb_employment_raw.empty else 'Sample'
            st.session_state.employment_df = preprocess_dataframe(wb_employment_raw if st.session_state.data_status['employment'] == 'Live' else get_sample_employment_data())
            
            st.session_state.data_loaded = True
            time.sleep(0.5)
            st.rerun()
    
    # --- UI Display ---
    tabs = st.tabs(["üè† Ìôà", "üìä Í∏ÄÎ°úÎ≤å ÎèôÌñ•", "üîç Ïã¨Ï∏µ Î∂ÑÏÑù", "‚öñÔ∏è ÏßÅÎ¨¥ ÏòÅÌñ• Î∂ÑÏÑù", "üöÄ ÎÇòÏùò ÎØ∏Îûò ÏÑ§Í≥ÑÌïòÍ∏∞", "‚úçÔ∏è Îã§Ïßê Í≥µÏú†ÌïòÍ∏∞", "üìù ÏÑ§Î¨∏ Î∞è ÏùòÍ≤¨", "üìö Îçî ÏïåÏïÑÎ≥¥Í∏∞"])
    
    with tabs[0]:
        display_home_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tabs[1]:
        display_global_trends_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tabs[2]:
        display_analysis_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tabs[3]:
        display_job_impact_tab()
    with tabs[4]:
        display_career_game_tab()
    with tabs[5]:
        display_memo_board_tab()
    with tabs[6]:
        display_survey_tab()
    with tabs[7]:
        display_learn_more_tab()

if __name__ == "__main__":
    main()

