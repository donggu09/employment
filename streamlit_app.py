"""
Streamlit Dashboard (Korean) - V24 (Optimized Loading)
This version optimizes the initial data loading process by fetching all external APIs concurrently, significantly reducing the startup time of the application.

- Core Topic: 'The Impact of Climate Change on Employment'
- Key Upgrades:
  1) **Concurrent API Calls**: Implemented `concurrent.futures.ThreadPoolExecutor` to fetch the three main data sources (NASA, NOAA, World Bank) in parallel instead of sequentially.
  2) **Reduced Timeout**: The default timeout for individual API requests in the `retry_get` function has been reduced from 30 to 15 seconds to fail faster on unresponsive servers.
  3) **Improved User Experience**: The initial loading spinner now reflects the parallel fetching process, and the overall time to see the dashboard is much shorter.
"""

import io
import time
import datetime
import os
import json
from typing import Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor

import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.graph_objects as go
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from streamlit_lottie import st_lottie
import openpyxl # For Excel file handling

# = a============================================================================
# 0. CONFIGURATION & INITIAL SETUP
# ==============================================================================
st.set_page_config(
    page_title="ê¸°í›„ ìœ„ê¸°ëŠ” í™˜ê²½ì„ ë„˜ì–´ ì·¨ì—…ê¹Œì§€ í”ë“ ë‹¤",
    page_icon="ğŸŒ",
    layout="wide"
)

# --- Custom CSS for Dark Mode UI ---
st.markdown("""
<style>
    /* Main background color set to dark */
    .stApp {
        background-color: #1E1E1E;
        color: #EAEAEA;
    }
    /* Headers color */
    h1, h2, h3, h4, h5, h6 {
        color: #FFFFFF;
    }
    /* Tab styles for dark mode */
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #1E1E1E; /* Match main background to remove box effect */
        border-radius: 4px 4px 0px 0px;
        border-bottom: 2px solid transparent;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
        color: #A0A0A0;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1E1E1E;
        border-bottom: 2px solid #0078F2; /* Bright blue highlight for active tab */
        color: #FFFFFF;
    }
    /* Metric styling for dark mode */
    div[data-testid="stMetricLabel"] {
        display: flex;
        align-items: center;
        color: #A0A0A0; /* Lighter gray for labels */
    }
    div[data-testid="stMetricValue"] {
        color: #FFFFFF; /* White for values */
    }
    /* Ensure Streamlit widgets have light text */
    .st-emotion-cache-1r6slb0, .st-emotion-cache-1y4p8pa {
        color: #EAEAEA;
    }
</style>
""", unsafe_allow_html=True)


# --- App constants ---
TODAY = datetime.datetime.now().date()
CONFIG = {
    "nasa_gistemp_url": "https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv",
    "worldbank_api_url": "https://api.worldbank.org/v2/country/all/indicator/SL.IND.EMPL.ZS",
    "noaa_co2_url": "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt",
    "lottie_home_url": "https://lottie.host/175b5a27-63f5-4220-8374-e32a13f789e9/5N7sBfSbB6.json",
    "lottie_career_game_url": "https://lottie.host/7e05e830-7456-4c31-b844-93b5a1b55909/Rk4yQO6fS3.json"
}
MEMO_FILE = "memos.json"

# --- Global Session with Retry Strategy ---
_SESSION = requests.Session()
_retry_strategy = Retry(
    total=5,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods=["HEAD", "GET", "OPTIONS"],
    backoff_factor=1
)
_adapter = HTTPAdapter(max_retries=_retry_strategy, pool_maxsize=10)
_SESSION.mount("https://", _adapter)
_SESSION.mount("http://", _adapter)


# ==============================================================================
# 1. UTILITY & DATA FUNCTIONS
# ==============================================================================
def retry_get(url: str, params: Optional[Dict] = None, **kwargs: Any) -> Optional[requests.Response]:
    headers = {'User-Agent': 'Mozilla/5.0 (compatible; StreamlitApp/1.0)'}
    error_message = ""
    try:
        resp = _SESSION.get(url, params=params, headers=headers, timeout=kwargs.get('timeout', 15), allow_redirects=True, verify=True)
        resp.raise_for_status()
        return resp
    except requests.exceptions.ConnectTimeout:
        error_message = f"**API(`{url.split('//')[1].split('/')[0]}`) ì—°ê²° ì‹œê°„ ì´ˆê³¼:** 15ì´ˆ ë‚´ì— ì„œë²„ë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì¼ì‹œì ìœ¼ë¡œ ëŠë¦¬ê±°ë‚˜, ë„¤íŠ¸ì›Œí¬ ì œì•½ ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    except requests.exceptions.HTTPError as e:
        error_message = f"**API(`{url.split('//')[1].split('/')[0]}`) ì„œë²„ ì˜¤ë¥˜:** ì„œë²„ì—ì„œ `{e.response.status_code}` ì˜¤ë¥˜ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
    except requests.exceptions.RequestException as e:
        error_message = f"**API(`{url.split('//')[1].split('/')[0]}`) ìš”ì²­ ì‹¤íŒ¨:** ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”. ({e.__class__.__name__})"
    
    if error_message:
        if 'api_errors' not in st.session_state:
            st.session_state.api_errors = []
        if error_message not in st.session_state.api_errors:
            st.session_state.api_errors.append(error_message)
    return None

@st.cache_data(ttl=3600)
def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return pd.DataFrame()
    d = df.copy()
    if 'date' in d.columns:
        d['date'] = pd.to_datetime(d['date'], errors='coerce')
        d = d.dropna(subset=['date'])
        d = d[d['date'].dt.date <= TODAY]
    else:
        return pd.DataFrame()

    d['value'] = pd.to_numeric(d['value'], errors='coerce')
    subset_cols = ['date', 'group'] if 'group' in d.columns else ['date']
    d = d.drop_duplicates(subset=subset_cols)
    sort_cols = ['group', 'date'] if 'group' in d.columns else ['date']
    d = d.sort_values(sort_cols).reset_index(drop=True)
    if 'group' in d.columns:
        d['value'] = d.groupby('group')['value'].transform(lambda s: s.interpolate(method='linear', limit_direction='both'))
    else:
        d['value'] = d['value'].interpolate(method='linear', limit_direction='both')
    return d.dropna(subset=['value']).reset_index(drop=True)

# --- Data Fetching ---
@st.cache_data(ttl=3600)
def fetch_gistemp_csv() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["nasa_gistemp_url"])
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8', errors='replace')
        lines = content.split('\n')
        data_start_index = next((i for i, line in enumerate(lines) if line.strip().startswith('Year,')), -1)
        if data_start_index == -1: raise ValueError("CSV Header 'Year,' not found.")
        df = pd.read_csv(io.StringIO("\n".join(lines[data_start_index:])))
        df.columns = [c.strip() for c in df.columns]
        df_long = df.melt(id_vars=['Year'], value_vars=[m for m in ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'] if m in df.columns], var_name='Month', value_name='Anomaly')
        month_map = {name: num for num, name in enumerate(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], 1)}
        df_long['date'] = pd.to_datetime(df_long['Year'].astype(str) + '-' + df_long['Month'].map(month_map).astype(str), errors='coerce')
        df_final = df_long[['date']].copy()
        df_final['value'] = pd.to_numeric(df_long['Anomaly'], errors='coerce')
        df_final['group'] = 'ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ)'
        return df_final.dropna(subset=['date', 'value'])
    except Exception as e:
        if 'api_errors' not in st.session_state: st.session_state.api_errors = []
        if f"**NASA GISTEMP Parsing Error:** `{e}`" not in st.session_state.api_errors: st.session_state.api_errors.append(f"**NASA GISTEMP ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜:** `{e}`")
        return None

@st.cache_data(ttl=3600)
def fetch_noaa_co2_data() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["noaa_co2_url"])
    if resp is None: return None
    try:
        df = pd.read_csv(io.StringIO(resp.content.decode('utf-8')), comment='#', delim_whitespace=True, header=None, names=['year', 'month', 'decimal_date', 'average', 'interpolated', 'trend', 'days', 'uncertainty'])
        df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01')
        df_final = df[['date', 'interpolated']].rename(columns={'interpolated': 'value'})
        df_final['group'] = 'ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm)'
        return df_final[df_final['value'] > 0]
    except Exception as e:
        if 'api_errors' not in st.session_state: st.session_state.api_errors = []
        if f"**NOAA COâ‚‚ Parsing Error:** `{e}`" not in st.session_state.api_errors: st.session_state.api_errors.append(f"**NOAA COâ‚‚ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜:** `{e}`")
        return None

@st.cache_data(ttl=3600)
def fetch_worldbank_employment() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["worldbank_api_url"], params={'format': 'json', 'per_page': '20000'})
    if resp is None: return None
    try:
        data = resp.json()
        if not isinstance(data, list) or len(data) < 2 or not data[1]: return None
        df = pd.json_normalize(data[1])
        df = df[['country.value', 'countryiso3code', 'date', 'value']]
        df.columns = ['group', 'iso_code', 'year', 'value']
        df['date'] = pd.to_datetime(df['year'] + '-01-01', errors='coerce')
        return df[['date', 'group', 'iso_code', 'value']].dropna()
    except Exception as e:
        if 'api_errors' not in st.session_state: st.session_state.api_errors = []
        if f"**World Bank Parsing Error:** `{e}`" not in st.session_state.api_errors: st.session_state.api_errors.append(f"**World Bank ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜:** `{e}`")
        return None

# --- Embedded Sample Data ---
@st.cache_data
def get_sample_climate_data() -> pd.DataFrame:
    csv_data = """date,value,group
2018-01-01,0.85,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2019-01-01,0.98,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2020-01-01,1.16,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2021-01-01,0.86,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2022-01-01,0.91,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2023-01-01,1.08,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2024-01-01,1.35,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
"""
    return pd.read_csv(io.StringIO(csv_data))

@st.cache_data
def get_sample_co2_data() -> pd.DataFrame:
    csv_data = """date,value,group
2018-01-01,408.21,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2019-01-01,410.92,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2020-01-01,413.4,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2021-01-01,415.4,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2022-01-01,418.28,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2023-01-01,420.51,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2024-01-01,423.01,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
"""
    return pd.read_csv(io.StringIO(csv_data))

@st.cache_data
def get_sample_employment_data() -> pd.DataFrame:
    csv_data = """date,group,iso_code,value
2018-01-01,World (ì˜ˆì‹œ),WLD,20.21
2020-01-01,World (ì˜ˆì‹œ),WLD,20.53
2022-01-01,World (ì˜ˆì‹œ),WLD,21.0
2024-01-01,World (ì˜ˆì‹œ),WLD,21.4
2018-01-01,Korea (ì˜ˆì‹œ),KOR,22.8
2020-01-01,Korea (ì˜ˆì‹œ),KOR,23.2
2022-01-01,Korea (ì˜ˆì‹œ),KOR,23.7
2024-01-01,Korea (ì˜ˆì‹œ),KOR,24.1
"""
    return pd.read_csv(io.StringIO(csv_data))

@st.cache_data
def get_sample_korea_employment_data() -> pd.DataFrame:
    csv_data = """ì—°ë„,ì·¨ì—…ì ìˆ˜ (ë§Œ ëª…),ì‹¤ì—…ë¥  (%)
2019,2712.3,3.8
2020,2690.4,4.0
2021,2727.3,3.7
2022,2808.9,2.9
2023,2841.6,2.8
2024,2869.8,2.8
"""
    return pd.read_csv(io.StringIO(csv_data))

# --- Helper Functions ---
@st.cache_data
def load_lottie_data(url: str):
    try:
        r = requests.get(url, timeout=15)
        if r.status_code == 200:
            return r.json()
    except requests.exceptions.RequestException:
        return None
    return None

def load_memos():
    try:
        if not os.path.exists(MEMO_FILE):
            with open(MEMO_FILE, "w", encoding="utf-8") as f:
                json.dump([], f)
        with open(MEMO_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

def save_memos(memos):
    with open(MEMO_FILE, "w", encoding="utf-8") as f:
        json.dump(memos, f, ensure_ascii=False, indent=4)

# ==============================================================================
# 2. UI RENDERING FUNCTIONS FOR TABS
# ==============================================================================
def display_home_tab(climate_df, co2_df, employment_df):
    col1, col2 = st.columns([0.6, 0.4])
    with col1:
        st.markdown("<h1 style='text-align: left;'>ğŸŒ ê¸°í›„ ìœ„ê¸°ëŠ”<br>í™˜ê²½ì„ ë„˜ì–´, ì·¨ì—…ê¹Œì§€ í”ë“ ë‹¤</h1>", unsafe_allow_html=True)
        st.markdown("#### 1403 ê¶Œì´ˆí˜„, 1405 ê¹€ë™í˜„, 1410 ì‹ ìˆ˜ì•„, 1416 ì¡°ì •ëª¨")
        st.markdown("""
        ê¸°í›„ë³€í™”ëŠ” ë” ì´ìƒ ë¨¼ ë¯¸ë˜ì˜ ì´ì•¼ê¸°ê°€ ì•„ë‹™ë‹ˆë‹¤. 
        ìš°ë¦¬ì˜ **ë¯¸ë˜ ì‚°ì—… êµ¬ì¡°**ì™€ **ì»¤ë¦¬ì–´**ë¥¼ ê²°ì •ì§“ëŠ” í•µì‹¬ ë³€ìˆ˜ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.
        
        ì´ ëŒ€ì‹œë³´ë“œëŠ” ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ í†µí•´ ê¸°í›„ ë³€í™”ê°€ ì§ì—… ì„¸ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ê³ ,
        ë¯¸ë˜ë¥¼ ì¤€ë¹„í•˜ëŠ” ì²­ì†Œë…„ë“¤ì—ê²Œ í•„ìš”í•œ ì¸ì‚¬ì´íŠ¸ì™€ ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.
        """)
    with col2:
        lottie_home = load_lottie_data(CONFIG['lottie_home_url'])
        if lottie_home:
            st_lottie(lottie_home, height=300, key="home_lottie")
    
    st.markdown("---")
    st.subheader("ğŸ“Š ëŒ€ì‹œë³´ë“œ í•µì‹¬ ì§€í‘œ")
    
    mcol1, mcol2, mcol3 = st.columns(3)
    if not all(df.empty for df in [climate_df, co2_df, employment_df]):
        try:
            latest_climate = climate_df.sort_values('date', ascending=False).iloc[0]
            latest_co2 = co2_df.sort_values('date', ascending=False).iloc[0]
            mcol1.metric(label="ğŸŒ¡ï¸ ìµœì‹  ì˜¨ë„ ì´ìƒì¹˜", value=f"{latest_climate['value']:.2f} â„ƒ", help=f"ê¸°ì¤€ì¼: {latest_climate['date']:%Y-%m}")
            mcol2.metric(label="â˜ï¸ ìµœì‹  COâ‚‚ ë†ë„", value=f"{latest_co2['value']:.2f} ppm", help=f"ê¸°ì¤€ì¼: {latest_co2['date']:%Y-%m}")
            mcol3.metric(label="ğŸ’¼ ê³ ìš© ë°ì´í„° êµ­ê°€ ìˆ˜", value=f"{employment_df['group'].nunique()} ê°œ")
        except (IndexError, ValueError, TypeError):
            st.info("í•µì‹¬ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        st.info("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì´ê±°ë‚˜ API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("ğŸš€ ì£¼ìš” ê¸°ëŠ¥ ë°”ë¡œê°€ê¸°")
    
    qcol1, qcol2, qcol3 = st.columns(3)
    with qcol1:
        st.markdown("##### ğŸ“Š ê¸€ë¡œë²Œ ë™í–¥ ë¶„ì„")
        st.write("ì‹¤ì‹œê°„ ë°ì´í„°ë¡œ ê¸°í›„ì™€ ê³ ìš©ì˜ í° ê·¸ë¦¼ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
    with qcol2:
        st.markdown("##### ğŸš€ ë‚˜ì˜ ë¯¸ë˜ ì„¤ê³„")
        st.write("ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ë‚˜ì˜ ì„ íƒì´ ë¯¸ë˜ì— ë¯¸ì¹  ì˜í–¥ì„ ì˜ˆì¸¡í•´ë³´ì„¸ìš”.")
    with qcol3:
        st.markdown("##### âœï¸ ë‹¤ì§ ê³µìœ í•˜ê¸°")
        st.write("ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ë‹¹ì‹ ì˜ ì‘ì€ ì‹¤ì²œì„ ëª¨ë‘ì™€ ê³µìœ í•´ë³´ì„¸ìš”.")

    st.markdown("---")
    display_data_status()
    display_api_errors()

def display_data_status():
    st.subheader("ë°ì´í„° ì¶œì²˜ í˜„í™©")
    status = st.session_state.get('data_status', {})
    cols = st.columns(3)
    status_map = {'Live': 'ğŸŸ¢ ì‹¤ì‹œê°„', 'Sample': 'ğŸŸ¡ ì˜ˆì‹œ'}
    cols[0].markdown(f"**NASA GISTEMP (ê¸°ì˜¨)**: {status_map.get(status.get('climate'), 'N/A')}")
    cols[1].markdown(f"**NOAA COâ‚‚ (ì´ì‚°í™”íƒ„ì†Œ)**: {status_map.get(status.get('co2'), 'N/A')}")
    cols[2].markdown(f"**World Bank (ê³ ìš©)**: {status_map.get(status.get('employment'), 'N/A')}")

def display_api_errors():
    if st.session_state.get('api_errors'):
        st.warning("âš ï¸ í•˜ë‚˜ ì´ìƒì˜ ì‹¤ì‹œê°„ ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í•˜ì—¬ ì˜ˆì‹œ ë°ì´í„°ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ“¡")
        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ ë³´ê¸°"):
            for error in st.session_state.api_errors:
                st.error(error, icon="ğŸ”¥")

def display_global_trends_tab(climate_df, co2_df, employment_df):
    st.subheader("ğŸ“ˆ ê¸€ë¡œë²Œ ë™í–¥: ìˆ«ìê°€ ë§í•˜ëŠ” ê¸°í›„ì™€ ì¼ìë¦¬ ë³€í™”")
    
    col1, col2, col3 = st.columns(3)
    if not all(df.empty for df in [climate_df, co2_df, employment_df]):
        try:
            latest_climate = climate_df.sort_values('date', ascending=False).iloc[0]
            latest_co2 = co2_df.sort_values('date', ascending=False).iloc[0]
            col1.metric(label="ğŸŒ¡ï¸ ìµœì‹  ì˜¨ë„ ì´ìƒì¹˜", value=f"{latest_climate['value']:.2f} â„ƒ", help=f"ê¸°ì¤€ì¼: {latest_climate['date']:%Y-%m}")
            col2.metric(label="â˜ï¸ ìµœì‹  COâ‚‚ ë†ë„", value=f"{latest_co2['value']:.2f} ppm", help=f"ê¸°ì¤€ì¼: {latest_co2['date']:%Y-%m}")
            col3.metric(label="ğŸ’¼ ê³ ìš© ë°ì´í„° êµ­ê°€ ìˆ˜", value=f"{employment_df['group'].nunique()} ê°œ")
        except (IndexError, ValueError, TypeError):
            st.info("í•µì‹¬ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        st.info("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì´ê±°ë‚˜ API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    st.markdown("---")

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("##### ğŸŒ¡ï¸ ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜")
        if not climate_df.empty:
            fig = px.line(climate_df, x='date', y='value', labels={'date': '', 'value': 'ì˜¨ë„ ì´ìƒì¹˜ (Â°C)'}, color_discrete_sequence=['#d62728'])
            fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA')
            st.plotly_chart(fig, use_container_width=True)
    with c2:
        st.markdown("##### ğŸ’¨ ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ë§ˆìš°ë‚˜ë¡œì•„)")
        if not co2_df.empty:
            fig = px.line(co2_df, x='date', y='value', labels={'date': '', 'value': 'COâ‚‚ (ppm)'}, color_discrete_sequence=['#1f77b4'])
            fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA')
            st.plotly_chart(fig, use_container_width=True)
    st.markdown("---")
    
    st.markdown("##### ğŸ­ ì‚°ì—…ë³„ ê³ ìš© ë¹„ìœ¨ ë³€í™”")
    if not employment_df.empty:
        employment_df['year'] = pd.to_datetime(employment_df['date']).dt.year
        min_year, max_year = int(employment_df['year'].min()), int(employment_df['year'].max())
        selected_year = st.slider("ì—°ë„ ì„ íƒ:", min_year, max_year, max_year, key="map_year_slider")
        
        map_df = employment_df[employment_df['year'] == selected_year]
        if not map_df.empty:
            fig_map = px.choropleth(map_df, locations="iso_code", color="value", hover_name="group", color_continuous_scale=px.colors.sequential.Plasma, labels={'value': 'ê³ ìš© ë¹„ìœ¨ (%)'}, title=f"{selected_year}ë…„ ì „ ì„¸ê³„ ì‚°ì—… ê³ ìš© ë¹„ìœ¨")
            fig_map.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', geo=dict(bgcolor='rgba(0,0,0,0)'), font_color='#EAEAEA')
            st.plotly_chart(fig_map, use_container_width=True)

        all_countries = sorted(employment_df['group'].unique())
        default_countries = [c for c in ['World', 'Korea, Rep.', 'World (ì˜ˆì‹œ)', 'Korea (ì˜ˆì‹œ)'] if c in all_countries] or all_countries[:2]
        selected_countries = st.multiselect("êµ­ê°€ë³„ ì¶”ì´ ë¹„êµ:", all_countries, default=default_countries)
        if selected_countries:
            comp_df = employment_df[employment_df['group'].isin(selected_countries)]
            fig_comp = px.line(comp_df, x='year', y='value', color='group', labels={'year':'ì—°ë„', 'value':'ì‚°ì—… ê³ ìš© ë¹„ìœ¨(%)', 'group':'êµ­ê°€'})
            fig_comp.update_layout(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA', legend=dict(font=dict(color='#EAEAEA')))
            st.plotly_chart(fig_comp, use_container_width=True)

def display_analysis_tab(climate_df, co2_df, employment_df):
    st.subheader("ğŸ” ì‹¬ì¸µ ë¶„ì„: ë°ì´í„°ë¡œ ê´€ê³„ ë“¤ì—¬ë‹¤ë³´ê¸°")
    
    st.markdown("##### ğŸ”„ ê¸°í›„ ì§€í‘œ vs. ê¸€ë¡œë²Œ ì‚°ì—… ê³ ìš© ìƒê´€ê´€ê³„")
    if any(df.empty for df in [climate_df, co2_df, employment_df]):
        st.warning("ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        try:
            climate_df['year'] = pd.to_datetime(climate_df['date']).dt.year
            c_ann_agg = climate_df.groupby('year')['value'].mean().reset_index().rename(columns={'value':'temp_anomaly'})
            co2_df['year'] = pd.to_datetime(co2_df['date']).dt.year
            co2_ann_agg = co2_df.groupby('year')['value'].mean().reset_index().rename(columns={'value':'co2_ppm'})
            employment_df['year'] = pd.to_datetime(employment_df['date']).dt.year
            e_ann_agg = employment_df.groupby(['year'])['value'].median().reset_index().rename(columns={'value':'employment_median'})
            
            merged = pd.merge(c_ann_agg, e_ann_agg, on='year', how='inner')
            merged = pd.merge(merged, co2_ann_agg, on='year', how='inner')

            if len(merged) < 2:
                st.warning("ë°ì´í„° ê¸°ê°„ì´ ì§§ì•„ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                corr_col1, corr_col2 = st.columns(2)
                corr_choice = corr_col1.selectbox("ë¹„êµí•  ê¸°í›„ ì§€í‘œ:", ('ì˜¨ë„ ì´ìƒì¹˜', 'COâ‚‚ ë†ë„'))
                normalize = corr_col2.checkbox("ë°ì´í„° ì •ê·œí™” (ì¶”ì„¸ ë¹„êµ)", help="ë‹¨ìœ„ê°€ ë‹¤ë¥¸ ë‘ ë°ì´í„°ë¥¼ 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ì„¸ ë¹„êµë¥¼ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.")
                
                x_var = 'temp_anomaly' if corr_choice == 'ì˜¨ë„ ì´ìƒì¹˜' else 'co2_ppm'
                y_var = 'employment_median'
                
                plot_df = merged[['year', x_var, y_var]].copy()
                correlation = plot_df[x_var].corr(plot_df[y_var])
                st.metric(f"{corr_choice} vs. ê³ ìš© ë¹„ìœ¨ ìƒê´€ê³„ìˆ˜", f"{correlation:.3f}")

                if normalize:
                    plot_df[x_var] = (plot_df[x_var] - plot_df[x_var].min()) / (plot_df[x_var].max() - plot_df[x_var].min())
                    plot_df[y_var] = (plot_df[y_var] - plot_df[y_var].min()) / (plot_df[y_var].max() - plot_df[y_var].min())
                
                fig_corr = go.Figure()
                fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[x_var], name=corr_choice, line=dict(color='#d62728')))
                fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[y_var], name='ì‚°ì—… ê³ ìš©(ì „ì„¸ê³„ ì¤‘ì•™ê°’)', yaxis='y2', line=dict(color='#1f77b4')))
                fig_corr.update_layout(xaxis_title="ì—°ë„", yaxis_title=f"{corr_choice}" if not normalize else "ì •ê·œí™”ëœ ê°’", yaxis2=dict(title="ì‚°ì—… ê³ ìš© ë¹„ìœ¨ (%)" if not normalize else "ì •ê·œí™”ëœ ê°’", overlaying="y", side="right"), legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01),
                                     plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA', legend_font_color='#EAEAEA')
                st.plotly_chart(fig_corr, use_container_width=True)
        except Exception as e:
            st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.markdown("---")

    st.markdown("##### ğŸ‡°ğŸ‡· êµ­ë‚´ ë°ì´í„° ì‹¬ì¸µ ë¶„ì„ (e-ë‚˜ë¼ì§€í‘œ ìƒ˜í”Œ)")
    st.info("e-ë‚˜ë¼ì§€í‘œì˜ 'ì·¨ì—…ì ë° ì‹¤ì—…ì' í†µê³„ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ êµ­ë‚´ ì·¨ì—… ë°ì´í„°ì™€ ê¸°í›„ ë³€í™”ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    korea_df = get_sample_korea_employment_data()
    
    temp_yearly = climate_df.groupby('year')['value'].mean().reset_index().rename(columns={'value':'temp_anomaly'})
    merged_korea = pd.merge(korea_df, temp_yearly, left_on='ì—°ë„', right_on='year', how='inner')
    
    if len(merged_korea) > 1:
        fig_korea = go.Figure()
        fig_korea.add_trace(go.Scatter(x=merged_korea['ì—°ë„'], y=merged_korea['ì‹¤ì—…ë¥  (%)'], name='í•œêµ­ ì‹¤ì—…ë¥  (%)', line=dict(color='#ff7f0e')))
        fig_korea.add_trace(go.Scatter(x=merged_korea['ì—°ë„'], y=merged_korea['temp_anomaly'], name='ì§€êµ¬ ì˜¨ë„ ì´ìƒì¹˜ (â„ƒ)', yaxis='y2', line=dict(color='#d62728')))
        fig_korea.update_layout(title="í•œêµ­ ì‹¤ì—…ë¥ ê³¼ ì§€êµ¬ ì˜¨ë„ ì´ìƒì¹˜ ë¹„êµ", xaxis_title="ì—°ë„", yaxis_title="ì‹¤ì—…ë¥  (%)", yaxis2=dict(title="ì˜¨ë„ ì´ìƒì¹˜ (â„ƒ)", overlaying="y", side="right"),
                              plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA', legend_font_color='#EAEAEA')
        st.plotly_chart(fig_korea, use_container_width=True)
    else:
        st.warning("ìƒ˜í”Œ ë°ì´í„°ì™€ ê¸°í›„ ë°ì´í„°ì˜ ê³µí†µ ì—°ë„ê°€ ë¶€ì¡±í•˜ì—¬ ë¹„êµ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def display_job_impact_tab():
    st.subheader("âš–ï¸ ì§ë¬´ ì˜í–¥ ë¶„ì„: ê¸°íšŒì™€ ìœ„í—˜")
    st.markdown("""
    í•µì‹¬ ì›ì¸ì€ **'ë…¹ìƒ‰ ì „í™˜(Green Transition)'**ì…ë‹ˆë‹¤. ê¸°í›„ ëŒ€ì‘ì„ ìœ„í•´ ì‚¬íšŒ ì „ë°˜ì´ ì¹œí™˜ê²½ ê¸°ìˆ ì„ ë„ì…í•˜ë©´ì„œ ìƒˆë¡œìš´ ì§ë¬´ê°€ ìƒê²¨ë‚˜ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. 
    ì•„ë˜ 'ì§ë¬´ ì „í™˜ íƒìƒ‰ê¸°'ë¥¼ í†µí•´ ê¸°ì¡´ ì§ë¬´ê°€ ì–´ë–¤ ê¸°íšŒë¥¼ ë§ì´í•  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³´ì„¸ìš”.
    """)

    job_data = {
        'í™”ë ¥ ë°œì „ì†Œ ê¸°ìˆ ì': {
            'risk': 'ë§¤ìš° ë†’ìŒ', 'icon': 'ğŸ”´',
            'skills': ['ë°œì „ ì„¤ë¹„ ìš´ì˜', 'ê³ ì•• ì „ê¸° ê´€ë¦¬', 'ê¸°ê³„ ìœ ì§€ë³´ìˆ˜'],
            'transitions': {
                'ì‹ ì¬ìƒì—ë„ˆì§€ ë°œì „ ì „ë¬¸ê°€': ['íƒœì–‘ê´‘/í’ë ¥ ì‹œìŠ¤í…œ ì´í•´', 'ì—ë„ˆì§€ ì €ì¥ ì‹œìŠ¤í…œ(ESS)'],
                'ìŠ¤ë§ˆíŠ¸ ê·¸ë¦¬ë“œ ì „ë¬¸ê°€': ['ì „ë ¥ë§ ìµœì í™”', 'ë°ì´í„° ë¶„ì„']
            }
        },
        'ìë™ì°¨ ë‚´ì—°ê¸°ê´€ ì—”ì§€ë‹ˆì–´': {
            'risk': 'ë†’ìŒ', 'icon': 'ğŸŸ ',
            'skills': ['ì—”ì§„ ì„¤ê³„', 'ì—´ì—­í•™', 'ê¸°ê³„ ê³µí•™'],
            'transitions': {
                'ì „ê¸°ì°¨ ë°°í„°ë¦¬ ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´': ['ë°°í„°ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ(BMS)', 'ì „ë ¥ ì „ì'],
                'ìˆ˜ì†Œì—°ë£Œì „ì§€ ê°œë°œì': ['ì—°ë£Œì „ì§€ ìŠ¤íƒ ì„¤ê³„', 'ê³ ì•• ìˆ˜ì†Œ ì œì–´']
            }
        },
        'ì„íƒ„ ê´‘ë¶€': {
            'risk': 'ë§¤ìš° ë†’ìŒ', 'icon': 'ğŸ”´',
            'skills': ['ì±„êµ´ ê¸°ìˆ ', 'ì¤‘ì¥ë¹„ ìš´ìš©', 'ì•ˆì „ ê´€ë¦¬'],
            'transitions': {
                'ì§€ì—´ ì—ë„ˆì§€ ê¸°ìˆ ì': ['ì‹œì¶” ê¸°ìˆ ', 'í”ŒëœíŠ¸ ìš´ì˜'],
                'íƒœì–‘ê´‘/í’ë ¥ ë‹¨ì§€ ê±´ì„¤ ë° ìœ ì§€ë³´ìˆ˜': ['ë¶€ì§€ ê´€ë¦¬', 'ê±´ì„¤ ê¸°ìˆ ']
            }
        },
        'ì „í†µ ë†ì—… ì¢…ì‚¬ì (ëŒ€ê·œëª¨ ë‹¨ì¼ ì‘ë¬¼)': {
            'risk': 'ë³´í†µ', 'icon': 'ğŸŸ¡',
            'skills': ['ê²½ì‘ ê¸°ìˆ ', 'ë³‘ì¶©í•´ ê´€ë¦¬', 'ë†ê¸°ê³„ ìš´ìš©'],
            'transitions': {
                'ìŠ¤ë§ˆíŠ¸íŒœ ìš´ì˜ì': ['ë°ì´í„° ë¶„ì„', 'ìë™í™” ì‹œìŠ¤í…œ ì œì–´', 'IoT ì„¼ì„œ í™œìš©'],
                'ì •ë°€ ë†ì—… ì»¨ì„¤í„´íŠ¸': ['GIS/ë“œë¡  í™œìš©', 'í† ì–‘ ë°ì´í„° ë¶„ì„']
            }
        },
        'ì„ìœ í™”í•™ ê³µì¥ ìš´ì˜ì›': {
            'risk': 'ë†’ìŒ', 'icon': 'ğŸŸ ',
            'skills': ['í™”í•™ ê³µì • ê´€ë¦¬', 'ì•ˆì „ ê´€ë¦¬', 'ìƒì‚° ìµœì í™”'],
            'transitions': {
                'ë°”ì´ì˜¤í”Œë¼ìŠ¤í‹± ì—°êµ¬ì›': ['ìƒë¶„í•´ì„± ê³ ë¶„ì', 'ë°”ì´ì˜¤ë§¤ìŠ¤ ì²˜ë¦¬'],
                'íƒ„ì†Œ í¬ì§‘/í™œìš©(CCUS) ì „ë¬¸ê°€': ['í™”í•™ í¡ìˆ˜ë²•', 'ë¶„ë¦¬ë§‰ ê¸°ìˆ ']
            }
        }
    }

    selected_job = st.selectbox("ì „í™˜ ê°€ëŠ¥ì„±ì„ íƒìƒ‰í•  ì§ë¬´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", list(job_data.keys()))

    if selected_job:
        data = job_data[selected_job]
        st.markdown(f"### {selected_job}")
        
        c1, c2, c3 = st.columns(3)
        c1.markdown(f"**ì „í™˜ ìœ„í—˜ë„**\n\n## {data['icon']} {data['risk']}")
        
        with c2:
            st.markdown("**ë³´ìœ  í•µì‹¬ ì—­ëŸ‰**")
            for skill in data['skills']:
                st.markdown(f"- {skill}")
        with c3:
            st.markdown("**ë¯¸ë˜ ì „í™˜ ì¶”ì²œ ì§ë¬´**")
            for job, skills in data['transitions'].items():
                st.markdown(f"**- {job}**")
                st.markdown(f"<small> (í•„ìš” ì—­ëŸ‰: {', '.join(skills)})</small>", unsafe_allow_html=True)


def display_career_game_tab():
    st.subheader("ğŸš€ ë‚˜ì˜ ë¯¸ë˜ ì„¤ê³„í•˜ê¸° (ì»¤ë¦¬ì–´ ì‹œë®¬ë ˆì´ì…˜)")
    st.info("ë‹¹ì‹ ì˜ ì„ íƒì´ 10ë…„ í›„ ì»¤ë¦¬ì–´ì™€ í™˜ê²½ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜ í•´ë³´ì„¸ìš”!")
    
    game_col, form_col = st.columns([0.4, 0.6])

    with game_col:
        lottie_career = load_lottie_data(CONFIG['lottie_career_game_url'])
        if lottie_career:
            st_lottie(lottie_career, height=400, key="career_lottie")
        
        st.markdown("""
        ##### ğŸ’¡ ê¸°í›„ ìœ„ê¸°ë¥¼ ê¸°íšŒë¡œ ë°”ê¾¸ëŠ” ì „ëµ
        - **ë°ì´í„° íƒêµ¬:** ê¸°í›„ì™€ ì‚°ì—… í†µê³„ë¥¼ ë¶„ì„í•˜ë©° ë³€í™”ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        - **ìœµí•© í”„ë¡œì íŠ¸:** ìì‹ ì˜ ì „ê³µê³¼ ê¸°í›„ ìœ„ê¸° ë¬¸ì œë¥¼ ì—°ê²°í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        - **ëª©ì†Œë¦¬ ë‚´ê¸°:** ê¸°í›„ ëŒ€ì‘ê³¼ ì²­ë…„ ê³ ìš© ì°½ì¶œì„ ì—°ê²°í•˜ì—¬ ì •ì±…ì„ ì œì•ˆí•©ë‹ˆë‹¤.
        """)

    with form_col:
        with st.form("career_game_form"):
            st.markdown("##### ğŸ“ 1ë‹¨ê³„: ëŒ€í•™ìƒ")
            major = st.radio("ì£¼ìš” ì „ê³µ:", ("ì»´í“¨í„°ê³µí•™ (AI íŠ¸ë™)", "ê¸°ê³„ê³µí•™", "ê²½ì œí•™"), key="major", horizontal=True)
            project = st.radio("ì¡¸ì—… í”„ë¡œì íŠ¸:", ("íƒ„ì†Œ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ AI ëª¨ë¸", "ê³ íš¨ìœ¨ ë‚´ì—°ê¸°ê´€ ì„¤ê³„", "ESG ê²½ì˜ì‚¬ë¡€ ë¶„ì„"), key="project")

            st.markdown("##### ğŸ’¼ 2ë‹¨ê³„: ì‚¬íšŒì´ˆë…„ìƒ")
            first_job = st.radio("ì²« ì§ì¥:", ("ì—ë„ˆì§€ IT ìŠ¤íƒ€íŠ¸ì—…", "ëŒ€ê¸°ì—… ì •ìœ íšŒì‚¬", "ê¸ˆìœµê¶Œ ì• ë„ë¦¬ìŠ¤íŠ¸"), key="first_job")
            skill_dev = st.radio("í•µì‹¬ ì—­ëŸ‰ ê°œë°œ:", ("í´ë¼ìš°ë“œ ê¸°ë°˜ ë°ì´í„° ë¶„ì„", "ì „í†µ ê³µì • ê´€ë¦¬", "ì¬ë¬´ ë¶„ì„ ë° íˆ¬ì"), key="skill_dev")
            
            submitted = st.form_submit_button("ğŸš€ ë‚˜ì˜ ë¯¸ë˜ í™•ì¸í•˜ê¸°")

        if submitted:
            career_score, green_score = 0, 0
            skills = {"ë°ì´í„° ë¶„ì„":0, "ì •ì±…/ê²½ì˜":0, "ì—”ì§€ë‹ˆì–´ë§":0, "ê¸ˆìœµ/ê²½ì œ":0}

            if major == "ì»´í“¨í„°ê³µí•™ (AI íŠ¸ë™)": career_score += 20; green_score += 10; skills["ë°ì´í„° ë¶„ì„"] += 2
            elif major == "ê¸°ê³„ê³µí•™": career_score += 10; skills["ì—”ì§€ë‹ˆì–´ë§"] += 2
            else: career_score += 15; green_score += 5; skills["ê¸ˆìœµ/ê²½ì œ"] += 2
            if project == "íƒ„ì†Œ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ AI ëª¨ë¸": career_score += 15; green_score += 20; skills["ë°ì´í„° ë¶„ì„"] += 1; skills["ì •ì±…/ê²½ì˜"] += 1
            elif project == "ê³ íš¨ìœ¨ ë‚´ì—°ê¸°ê´€ ì„¤ê³„": career_score += 5; green_score -= 10; skills["ì—”ì§€ë‹ˆì–´ë§"] += 1
            else: career_score += 10; green_score += 10; skills["ì •ì±…/ê²½ì˜"] += 1; skills["ê¸ˆìœµ/ê²½ì œ"] += 1
            if first_job == "ì—ë„ˆì§€ IT ìŠ¤íƒ€íŠ¸ì—…": career_score += 15; green_score += 20
            elif first_job == "ëŒ€ê¸°ì—… ì •ìœ íšŒì‚¬": career_score += 20; green_score -= 10
            else: career_score += 15; green_score += 5
            if skill_dev == "í´ë¼ìš°ë“œ ê¸°ë°˜ ë°ì´í„° ë¶„ì„": career_score += 20; green_score += 10; skills["ë°ì´í„° ë¶„ì„"] += 2
            elif skill_dev == "ì „í†µ ê³µì • ê´€ë¦¬": career_score += 10; green_score -= 5; skills["ì—”ì§€ë‹ˆì–´ë§"] += 1
            else: career_score += 15; skills["ê¸ˆìœµ/ê²½ì œ"] += 1
            
            if green_score >= 50 and career_score >= 70: job_title = "ê¸°í›„ ê¸°ìˆ  ìµœê³  ì „ë¬¸ê°€"
            elif green_score >= 30 and career_score >= 60: job_title = "ê·¸ë¦° ì—ë„ˆì§€ ì „ëµê°€"
            else: job_title = "ë¯¸ë˜ ì¤€ë¹„í˜• ì¸ì¬"

            st.markdown("##### ğŸ‰ ìµœì¢… ê²°ê³¼: ë‹¹ì‹ ì˜ ì»¤ë¦¬ì–´ ì¹´ë“œ")
            res1, res2 = st.columns([0.6, 0.4])
            with res1:
                st.markdown(f"#### ğŸ’¼ **ì§ì—…:** {job_title}")
                st.metric("ğŸš€ ë¯¸ë˜ ì „ë§ ì ìˆ˜", f"{career_score} / 100")
                st.metric("ğŸŒ± í™˜ê²½ ê¸°ì—¬ë„ ì ìˆ˜", f"{green_score} / 75")
            with res2:
                df_skills = pd.DataFrame(dict(r=list(skills.values()), theta=list(skills.keys())))
                fig = px.line_polar(df_skills, r='r', theta='theta', line_close=True, range_r=[0,5], title="ë‚˜ì˜ ì—­ëŸ‰ ë ˆì´ë” ì°¨íŠ¸")
                fig.update_layout(
                    polar=dict(
                        bgcolor = 'rgba(0,0,0,0)',
                        radialaxis=dict(visible=True, range=[0, 5], tickfont=dict(color='#EAEAEA')),
                        angularaxis=dict(tickfont=dict(size=12, color='#EAEAEA'))
                    ),
                    paper_bgcolor='rgba(0,0,0,0)',
                    margin=dict(l=60, r=60, t=80, b=60),
                    font_color='#EAEAEA'
                )
                st.plotly_chart(fig, use_container_width=True)

def display_memo_board_tab():
    st.subheader("âœï¸ ë‚˜ì˜ ì‹¤ì²œ ë‹¤ì§ ë‚¨ê¸°ê¸° (ê³µìœ  ë°©ëª…ë¡)")
    st.markdown("ê¸°í›„ ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ ì—¬ëŸ¬ë¶„ì˜ ë‹¤ì§ì„ ë‚¨ê²¨ì£¼ì„¸ìš”! ëª¨ë“  ë°©ë¬¸ìì—ê²Œ ê³µìœ ë©ë‹ˆë‹¤.")
    
    with st.form("memo_form"):
        cols = st.columns([0.7, 0.3])
        with cols[0]:
            name = st.text_input("ë‹‰ë„¤ì„", placeholder="ìì‹ ì„ í‘œí˜„í•˜ëŠ” ë©‹ì§„ ë‹‰ë„¤ì„ì„ ì ì–´ì£¼ì„¸ìš”!", key="memo_name")
            memo = st.text_area("ì‹¤ì²œ ë‹¤ì§", placeholder="ì˜ˆ) í…€ë¸”ëŸ¬ ì‚¬ìš©í•˜ê¸°, ê°€ê¹Œìš´ ê±°ë¦¬ëŠ” ê±¸ì–´ë‹¤ë‹ˆê¸° ë“±", key="memo_text")
        with cols[1]:
            color = st.color_picker("ë©”ëª¨ì§€ ìƒ‰ìƒ ì„ íƒ", "#FFFACD", key="memo_color")
            submitted = st.form_submit_button("ë‹¤ì§ ë‚¨ê¸°ê¸°!", use_container_width=True)
            if submitted:
                if name and memo:
                    all_memos = load_memos()
                    all_memos.insert(0, {"name": name, "memo": memo, "color": color, "timestamp": str(datetime.datetime.now())})
                    save_memos(all_memos)
                    st.balloons()
                    st.success("ì†Œì¤‘í•œ ë‹¤ì§ì´ ëª¨ë‘ì—ê²Œ ê³µìœ ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.warning("ë‹‰ë„¤ì„ê³¼ ë‹¤ì§ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    st.markdown("---")

    st.markdown("##### ğŸ’¬ ìš°ë¦¬ì˜ ë‹¤ì§ë“¤")
    memos_list = load_memos()
    
    if not memos_list:
        st.info("ì•„ì§ ì‘ì„±ëœ ë‹¤ì§ì´ ì—†ì–´ìš”. ì²« ë²ˆì§¸ ë‹¤ì§ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!")
    else:
        memo_cols = st.columns(3)
        for i, m in enumerate(memos_list):
            with memo_cols[i % 3]:
                st.markdown(f"""
                <div style="background-color:{m.get('color', '#FFFACD')}; border-left: 5px solid #FF6347; border-radius: 8px; padding: 15px; margin-bottom: 20px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); height: 180px;">
                    <p style="font-size: 1.1em; color: black; margin-bottom: 10px;">"{m.get('memo', '')}"</p>
                    <strong style="font-size: 0.9em; color: #555;">- {m.get('name', '')} -</strong>
                </div>
                """, unsafe_allow_html=True)

def display_survey_tab():
    st.subheader("ğŸ“ ì„¤ë¬¸ ë° ì˜ê²¬")
    st.markdown("ê¸°í›„ ë³€í™”ì™€ ë¯¸ë˜ ì§ì—…ì— ëŒ€í•œ ì—¬ëŸ¬ë¶„ì˜ ì†Œì¤‘í•œ ì˜ê²¬ì„ ë“¤ë ¤ì£¼ì„¸ìš”!")

    with st.form("survey_form"):
        st.markdown("##### ê°œì¸ ì¸ì‹ ë° í–‰ë™")
        q1 = st.radio("1ï¸âƒ£ ê¸°í›„ë³€í™”ê°€ ë‚˜ì˜ ì§ì—…(ë˜ëŠ” ë¯¸ë˜ ì§ì—…)ì— ì˜í–¥ì„ ì¤„ ê²ƒì´ë¼ ìƒê°í•˜ì‹œë‚˜ìš”?", ["ë§¤ìš° ê·¸ë ‡ë‹¤", "ì¡°ê¸ˆ ê·¸ë ‡ë‹¤", "ë³„ë¡œ ì•„ë‹ˆë‹¤", "ì „í˜€ ì•„ë‹ˆë‹¤"])
        q2 = st.radio("2ï¸âƒ£ ê¸°í›„ë³€í™” ìœ„ê¸°ì˜ ì‹¬ê°ì„±ì„ ì–´ëŠ ì •ë„ë¡œ ëŠë¼ì‹œë‚˜ìš”?", ["ë§¤ìš° ì‹¬ê°í•˜ë‹¤", "ì–´ëŠ ì •ë„ ì‹¬ê°í•˜ë‹¤", "ë³´í†µì´ë‹¤", "ì‹¬ê°í•˜ì§€ ì•Šë‹¤"])
        q3 = st.multiselect("3ï¸âƒ£ í‰ì†Œì— ì‹¤ì²œí•˜ê³  ìˆëŠ” ì¹œí™˜ê²½ í™œë™ì´ ìˆë‹¤ë©´ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.", ["ë¶„ë¦¬ìˆ˜ê±° ì² ì €íˆ í•˜ê¸°", "ëŒ€ì¤‘êµí†µ/ìì „ê±° ì´ìš©", "ì¼íšŒìš©í’ˆ ì‚¬ìš© ì¤„ì´ê¸°", "ì—ë„ˆì§€ ì ˆì•½(ì½˜ì„¼íŠ¸ ë½‘ê¸° ë“±)", "ì±„ì‹/ìœ¡ë¥˜ ì†Œë¹„ ì¤„ì´ê¸°", "ì—†ìŒ"])

        st.markdown("##### ì§ì—… ë° êµìœ¡")
        q4 = st.selectbox("4ï¸âƒ£ ê°€ì¥ ìœ ë§í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ë…¹ìƒ‰ ì¼ìë¦¬ ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", ["ì‹ ì¬ìƒì—ë„ˆì§€", "ESG ì»¨ì„¤íŒ…", "ì¹œí™˜ê²½ ì†Œì¬ ê°œë°œ", "ê¸°í›„ ë°ì´í„° ë¶„ì„", "ì „ê¸°/ìˆ˜ì†Œì°¨"])
        q5 = st.slider("5ï¸âƒ£ ë¯¸ë˜ ì§ì—…ì„ ìœ„í•´ ê¸°í›„ë³€í™” ê´€ë ¨ ì—­ëŸ‰ì„ í‚¤ìš¸ ì˜í–¥ì´ ì–´ëŠ ì •ë„ì¸ê°€ìš”? (0~10ì )", 0, 10, 7)
        q6 = st.multiselect("6ï¸âƒ£ ë…¹ìƒ‰ ì¼ìë¦¬ ì „í™˜ì„ ìœ„í•´ ê°€ì¥ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ì§€ì›ì€ ë¬´ì—‡ì¸ê°€ìš”? (ì¤‘ë³µ ì„ íƒ ê°€ëŠ¥)", ["ì „ë¬¸ ì¬êµìœ¡ í”„ë¡œê·¸ë¨", "ì •ë¶€ì˜ ì¬ì • ì§€ì›", "ê¸°ì—…ì˜ ì±„ìš© ì—°ê³„", "ì§„ë¡œ ë©˜í† ë§ ë° ìƒë‹´"])

        st.markdown("##### ê¸°ì—… ë° ì‚¬íšŒ ì •ì±…")
        q7 = st.radio("7ï¸âƒ£ ê¸°í›„ë³€í™” ëŒ€ì‘ì„ ìœ„í•´ ê¸°ì—…ì˜ ì—­í• ì´ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”?", ["ë§¤ìš° ì¤‘ìš”í•˜ë‹¤", "ì¤‘ìš”í•˜ë‹¤", "ë³´í†µì´ë‹¤", "ì¤‘ìš”í•˜ì§€ ì•Šë‹¤"])
        q8 = st.radio("8ï¸âƒ£ ê¸°í›„ë³€í™” ëŒ€ì‘ì„ ìœ„í•œ ì„¸ê¸ˆ(íƒ„ì†Œì„¸ ë“±) ì¶”ê°€ ë¶€ë‹´ì— ë™ì˜í•˜ì‹œë‚˜ìš”?", ["ì ê·¹ ì°¬ì„±", "ì°¬ì„±í•˜ëŠ” í¸", "ë°˜ëŒ€í•˜ëŠ” í¸", "ì ê·¹ ë°˜ëŒ€"])
        
        submitted = st.form_submit_button("ì„¤ë¬¸ ì œì¶œí•˜ê¸°")

    if submitted:
        st.success("âœ… ì„¤ë¬¸ì— ì°¸ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì•„ë˜ëŠ” ë‚˜ì˜ ì‘ë‹µ ìš”ì•½ì…ë‹ˆë‹¤.")
        st.markdown("##### ğŸ“‹ ë‚˜ì˜ ì‘ë‹µ ìš”ì•½")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ì§ì—… ì˜í–¥ ì¸ì‹:** {q1}")
            st.write(f"**ìœ„ê¸° ì‹¬ê°ì„± ì¸ì‹:** {q2}")
            st.write(f"**ìœ ë§ ë…¹ìƒ‰ ì¼ìë¦¬:** {q4}")
            st.write(f"**ê¸°ì—… ì—­í•  ì¤‘ìš”ë„:** {q7}")
            st.write(f"**íƒ„ì†Œì„¸ ë™ì˜:** {q8}")
        with col2:
            fig = go.Figure(go.Indicator(
                mode = "gauge+number", value = q5,
                title = {'text': "ë‚˜ì˜ ì—­ëŸ‰ ê°œë°œ ì˜ì§€ ì ìˆ˜"},
                gauge = {'axis': {'range': [None, 10]}, 'bar': {'color': "#2ca02c"}}))
            fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', font_color='#EAEAEA')
            st.plotly_chart(fig, use_container_width=True)

def display_learn_more_tab():
    st.subheader("ğŸ“š ë” ì•Œì•„ë³´ê¸°: ê´€ë ¨ ì •ë³´ ë° ì‚¬ì´íŠ¸")
    
    st.markdown("##### ğŸ’¼ ë…¹ìƒ‰ ì¼ìë¦¬ ì±„ìš© ì •ë³´")
    st.markdown("""
    - [ì›Œí¬ë„· - ë…¹ìƒ‰ ì¼ìë¦¬](https://www.work.go.kr/greenWork/main.do)
    - [í™˜ê²½ë¶€ í™˜ê²½ì‚°ì—…ê¸°ìˆ ì› - í™˜ê²½ì¼ìë¦¬](https://www.job.keiti.re.kr/)
    - [ì¸í¬ë£¨íŠ¸ - ë…¹ìƒ‰ê¸ˆìœµ/ì‚°ì—… ì±„ìš©ê´€](https://green.incruit.com/)
    """)
    st.markdown("---")

    st.markdown("##### ğŸ“ êµìœ¡ ë° í•™ìŠµ ìë£Œ")
    st.markdown("""
    - [K-MOOC - ê¸°í›„ë³€í™” ê´€ë ¨ ê°•ì¢Œ](http://www.kmooc.kr/search?query=%EA%B8%B0%ED%9B%84%EB%B3%80%ED%99%94)
    - [í™˜ê²½êµìœ¡í¬í„¸](https://www.keep.go.kr/portal/1)
    """)
    st.markdown("---")

    st.markdown("##### ğŸ“Š ë°ì´í„° ë° ë³´ê³ ì„œ ì¶œì²˜")
    st.markdown("""
    - [NASA: GISS Surface Temperature Analysis](https://data.giss.nasa.gov/gistemp/)
    - [NOAA: Global Monitoring Laboratory - COâ‚‚ Data](https://gml.noaa.gov/ccgg/trends/)
    - [The World Bank: Data](https://data.worldbank.org/)
    - [e-ë‚˜ë¼ì§€í‘œ](https://www.index.go.kr/)
    """)

# ==============================================================================
# 3. MAIN APPLICATION LOGIC
# ==============================================================================
def main():
    if 'data_loaded' not in st.session_state:
        st.session_state.data_status = {}
        st.session_state.api_errors = []

        with st.spinner("ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ë¹ ë¥´ê²Œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            with ThreadPoolExecutor(max_workers=3) as executor:
                future_climate = executor.submit(fetch_gistemp_csv)
                future_co2 = executor.submit(fetch_noaa_co2_data)
                future_employment = executor.submit(fetch_worldbank_employment)

                climate_raw = future_climate.result()
                co2_raw = future_co2.result()
                wb_employment_raw = future_employment.result()
            
            st.session_state.data_status['climate'] = 'Live' if climate_raw is not None and not climate_raw.empty else 'Sample'
            st.session_state.climate_df = preprocess_dataframe(climate_raw if st.session_state.data_status['climate'] == 'Live' else get_sample_climate_data())

            st.session_state.data_status['co2'] = 'Live' if co2_raw is not None and not co2_raw.empty else 'Sample'
            st.session_state.co2_df = preprocess_dataframe(co2_raw if st.session_state.data_status['co2'] == 'Live' else get_sample_co2_data())

            st.session_state.data_status['employment'] = 'Live' if wb_employment_raw is not None and not wb_employment_raw.empty else 'Sample'
            st.session_state.employment_df = preprocess_dataframe(wb_employment_raw if st.session_state.data_status['employment'] == 'Live' else get_sample_employment_data())
            
            st.session_state.data_loaded = True
            time.sleep(0.5)
            st.rerun()
    
    # --- UI Display ---
    tabs = st.tabs(["ğŸ  í™ˆ", "ğŸ“Š ê¸€ë¡œë²Œ ë™í–¥", "ğŸ” ì‹¬ì¸µ ë¶„ì„", "âš–ï¸ ì§ë¬´ ì˜í–¥ ë¶„ì„", "ğŸš€ ë‚˜ì˜ ë¯¸ë˜ ì„¤ê³„í•˜ê¸°", "âœï¸ ë‹¤ì§ ê³µìœ í•˜ê¸°", "ğŸ“ ì„¤ë¬¸ ë° ì˜ê²¬", "ğŸ“š ë” ì•Œì•„ë³´ê¸°"])
    
    with tabs[0]:
        display_home_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tabs[1]:
        display_global_trends_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tabs[2]:
        display_analysis_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tabs[3]:
        display_job_impact_tab()
    with tabs[4]:
        display_career_game_tab()
    with tabs[5]:
        display_memo_board_tab()
    with tabs[6]:
        display_survey_tab()
    with tabs[7]:
        display_learn_more_tab()

if __name__ == "__main__":
    main()

