"""
Streamlit Dashboard (Korean) - ENHANCED V2
- Topic: 'The Impact of Climate Change on Employment'
- Features:
  1) Interactive dashboards with public data (NASA GISTEMP, World Bank, NOAA CO2).
  2) Interactive simulated dashboard based on a text prompt.
- Enhancements:
  - Added NOAA Mauna Loa CO2 data.
  - Enhanced correlation analysis with metric selection and correlation coefficient.
  - Made the scenario simulation interactive with sliders.
  - Improved UI by moving controls from sidebar into tabs.
  - Added more download buttons.
  - Removed sklearn dependency.
"""

import os
import io
import time
import datetime
from typing import Optional, Dict, Any

import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.graph_objects as go


# ==============================================================================
# 0. CONFIGURATION & INITIAL SETUP
# ==============================================================================
st.set_page_config(
    page_title="ê¸°í›„ì™€ ì·¨ì—…: ë°ì´í„° ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸŒ",
    layout="wide"
)

# --- App constants ---
TODAY = datetime.datetime.now().date()
CONFIG = {
    "nasa_gistemp_url": "https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv",
    "worldbank_api_url": "https://api.worldbank.org/v2/country/all/indicator/SL.IND.EMPL.ZS",
    "noaa_co2_url": "https://gml.noaa.gov/aftp/data/trace_gases/co2/in-situ/surface/mlo/co2_mlo_surface-insitu_1_ccgg_MonthlyData.txt",
    "font_path": "/fonts/Pretendard-Bold.ttf",
}

# ==============================================================================
# 1. UTILITY FUNCTIONS
# ==============================================================================
def retry_get(url: str, params: Optional[Dict] = None, **kwargs: Any) -> Optional[requests.Response]:
    """Robust GET request with retries and user-agent."""
    final_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    for attempt in range(kwargs.get('max_retries', 2) + 1):
        try:
            resp = requests.get(url, params=params, headers=final_headers, timeout=kwargs.get('timeout', 15))
            resp.raise_for_status()
            return resp
        except requests.exceptions.RequestException as e:
            if attempt < kwargs.get('max_retries', 2):
                time.sleep(kwargs.get('backoff', 1.0) * (attempt + 1))
                continue
            st.sidebar.warning(f"API ìš”ì²­ ì‹¤íŒ¨: {url.split('?')[0]} ({e})")
            return None

@st.cache_data(ttl=3600)
def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """Standardize and preprocess a dataframe."""
    if df is None or df.empty: return pd.DataFrame()
    d = df.copy()
    d['date'] = pd.to_datetime(d['date'], errors='coerce')
    d = d.dropna(subset=['date'])
    d = d[d['date'].dt.date <= TODAY]
    d['value'] = pd.to_numeric(d['value'], errors='coerce')
    subset_cols = ['date', 'group'] if 'group' in d.columns else ['date']
    d = d.drop_duplicates(subset=subset_cols)
    sort_cols = ['group', 'date'] if 'group' in d.columns else ['date']
    d = d.sort_values(sort_cols).reset_index(drop=True)
    if 'group' in d.columns:
        d['value'] = d.groupby('group')['value'].transform(lambda s: s.interpolate(method='linear', limit_direction='both', limit_area='inside'))
    else:
        d['value'] = d['value'].interpolate(method='linear', limit_direction='both', limit_area='inside')
    return d.dropna(subset=['value']).reset_index(drop=True)

def normalize_series(s: pd.Series) -> pd.Series:
    """Normalize a pandas Series to a 0-1 scale."""
    if s.max() == s.min(): return pd.Series(0.5, index=s.index)
    return (s - s.min()) / (s.max() - s.min())

# ==============================================================================
# 2. DATA LOADING & PROCESSING (with Caching)
# ==============================================================================
@st.cache_data(ttl=3600)
def fetch_gistemp_csv() -> Optional[pd.DataFrame]:
    """Fetch and parse NASA GISTEMP global monthly anomalies."""
    resp = retry_get(CONFIG["nasa_gistemp_url"], max_retries=1)
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8', errors='replace')
        lines = content.split('\n')
        data_start_index = next((i for i, line in enumerate(lines) if line.strip().startswith('Year,')), -1)
        if data_start_index == -1: return None
        df = pd.read_csv(io.StringIO("\n".join(lines[data_start_index:])))
        df.columns = [c.strip() for c in df.columns]
        months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
        present_months = [m for m in months if m in df.columns]
        df_long = df.melt(id_vars=['Year'], value_vars=present_months, var_name='Month', value_name='Anomaly')
        month_map = {name: num for num, name in enumerate(months, 1)}
        df_long['date'] = pd.to_datetime(df_long['Year'].astype(str) + '-' + df_long['Month'].map(month_map).astype(str), errors='coerce')
        df_final = df_long[['date']].copy()
        df_final['value'] = pd.to_numeric(df_long['Anomaly'], errors='coerce')
        df_final['group'] = 'ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ)'
        return df_final.dropna(subset=['date', 'value'])
    except Exception as e:
        st.sidebar.error(f"GISTEMP ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data(ttl=3600)
def fetch_noaa_co2_data() -> Optional[pd.DataFrame]:
    """Fetch and parse NOAA Mauna Loa CO2 data."""
    resp = retry_get(CONFIG["noaa_co2_url"], max_retries=1)
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8')
        lines = [line for line in content.split('\n') if not line.strip().startswith('#')]
        df = pd.read_csv(io.StringIO('\n'.join(lines)), delim_whitespace=True, header=None,
                         names=['site', 'year', 'month', 'day', 'hour', 'minute', 'second', 'value_unc', 'value_std_dev', 'value_n', 'latitude', 'longitude', 'altitude', 'elevation', 'intake_height', 'qcflag'])
        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])
        df_final = df[['date', 'value_unc']].rename(columns={'value_unc': 'value'})
        df_final['group'] = 'ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm)'
        return df_final[df_final['value'] > 0] # Remove placeholder values
    except Exception as e:
        st.sidebar.error(f"NOAA CO2 ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data(ttl=3600)
def fetch_worldbank_employment() -> Optional[pd.DataFrame]:
    """Fetch World Bank API for Employment in industry, including ISO codes."""
    params = {'format': 'json', 'per_page': '20000'}
    resp = retry_get(CONFIG["worldbank_api_url"], params=params, max_retries=1)
    if resp is None: return None
    try:
        data = resp.json()
        if not isinstance(data, list) or len(data) < 2 or not data[1]: return None
        df = pd.json_normalize(data[1])
        df = df[['country.value', 'countryiso3code', 'date', 'value']]
        df.columns = ['group', 'iso_code', 'year', 'value']
        df['date'] = pd.to_datetime(df['year'] + '-01-01', errors='coerce')
        return df[['date', 'group', 'iso_code', 'value']].dropna()
    except Exception as e:
        st.sidebar.error(f"World Bank ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def get_sample_climate_data() -> pd.DataFrame:
    """Generate sample climate data as a fallback."""
    dates = pd.date_range(end=TODAY, periods=14*12, freq='MS')
    values = np.round(np.linspace(0.4, 1.2, len(dates)) + np.random.normal(0, 0.05, len(dates)), 3)
    return pd.DataFrame({'date': dates, 'value': values, 'group': 'ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ)'})

def get_sample_co2_data() -> pd.DataFrame:
    """Generate sample CO2 data as a fallback."""
    dates = pd.date_range(end=TODAY, periods=14*12, freq='MS')
    values = np.round(np.linspace(380, 420, len(dates)) + np.random.normal(0, 0.5, len(dates)), 2)
    return pd.DataFrame({'date': dates, 'value': values, 'group': 'ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm)'})

def get_sample_employment_data() -> pd.DataFrame:
    """Generate sample employment data as a fallback."""
    years = pd.date_range(start=f"{TODAY.year-9}-01-01", end=f"{TODAY.year}-01-01", freq='AS')
    data = []
    countries = {'í•œêµ­(ì˜ˆì‹œ)': 'KOR', 'OECD í‰ê· (ì˜ˆì‹œ)': 'OED'}
    for country, code in countries.items():
        base_value = 24.0 if 'í•œêµ­' in country else 22.0
        for year in years:
            data.append({'date': year, 'group': country, 'iso_code': code, 'value': float(base_value + np.random.normal(0, 0.8))})
    return pd.DataFrame(data)

# ==============================================================================
# 3. UI RENDERING FUNCTIONS
# ==============================================================================
def display_public_data_tab(climate_df: pd.DataFrame, co2_df: pd.DataFrame, employment_df: pd.DataFrame):
    """Render the content for the public data dashboard tab."""
    st.header("ğŸ“ˆ ê³µì‹ ê³µê°œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„")
    st.markdown("NASA (ê¸°ì˜¨), NOAA (COâ‚‚), World Bank (ê³ ìš©)ì˜ ê³µê°œ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´ë©ë‹ˆë‹¤.")

    # --- Key Metrics ---
    try:
        latest_climate = climate_df.sort_values('date', ascending=False).iloc[0]
        latest_co2 = co2_df.sort_values('date', ascending=False).iloc[0]
        col1, col2, col3 = st.columns(3)
        col1.metric(f"ìµœì‹  ì˜¨ë„ ì´ìƒì¹˜ ({latest_climate['date']:%Y-%m})", f"{latest_climate['value']:.2f} â„ƒ")
        col2.metric(f"ìµœì‹  COâ‚‚ ë†ë„ ({latest_co2['date']:%Y-%m})", f"{latest_co2['value']:.2f} ppm")
        col3.metric("ê³ ìš© ë°ì´í„° êµ­ê°€ ìˆ˜", f"{employment_df['group'].nunique()} ê°œ")
    except (IndexError, ValueError):
        st.info("í•µì‹¬ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    st.markdown("---")

    # --- Climate & CO2 Charts ---
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("ğŸŒ¡ï¸ ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜")
        show_trendline = st.checkbox("5ë…„ ì´ë™í‰ê·  ì¶”ì„¸ì„ ", value=True, key="trend_cb")
        if not climate_df.empty:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=climate_df['date'], y=climate_df['value'], mode='lines', name='ì›”ë³„ ì´ìƒì¹˜', line=dict(width=1, color='lightblue')))
            if show_trendline:
                climate_df['trend'] = climate_df['value'].rolling(window=60, min_periods=12).mean()
                fig.add_trace(go.Scatter(x=climate_df['date'], y=climate_df['trend'], mode='lines', name='5ë…„ ì´ë™í‰ê· ', line=dict(width=3, color='royalblue')))
            st.plotly_chart(fig, use_container_width=True)
            st.download_button("ì˜¨ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", climate_df.to_csv(index=False, encoding='utf-8-sig'), "climate_data.csv", "text/csv", key="dl_climate")
    with c2:
        st.subheader("ğŸ’¨ ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„")
        st.markdown("<p style='font-size: smaller;'>í•˜ì™€ì´ ë§ˆìš°ë‚˜ë¡œì•„ ê´€ì¸¡ì†Œ ê¸°ì¤€</p>", unsafe_allow_html=True)
        if not co2_df.empty:
            fig = px.line(co2_df, x='date', y='value', labels={'date': 'ë‚ ì§œ', 'value': 'COâ‚‚ (ppm)'})
            st.plotly_chart(fig, use_container_width=True)
            st.download_button("COâ‚‚ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", co2_df.to_csv(index=False, encoding='utf-8-sig'), "co2_data.csv", "text/csv", key="dl_co2")
    st.markdown("---")

    # --- Employment Data Section ---
    st.subheader("ğŸ­ ì‚°ì—…ë³„ ê³ ìš© ë¹„ìœ¨ ë³€í™”")
    if not employment_df.empty:
        employment_df['year'] = employment_df['date'].dt.year
        min_year = int(employment_df['year'].min())
        max_year = int(employment_df['year'].max())

        # Add a slider to select the year for the map
        selected_year = st.slider("ì—°ë„ë¥¼ ì„ íƒí•˜ì—¬ ì§€ë„ë¥¼ ë³€ê²½í•˜ì„¸ìš”:", min_year, max_year, max_year)

        st.markdown(f"**{selected_year}ë…„ ê¸°ì¤€ ì „ ì„¸ê³„ ì‚°ì—… ê³ ìš© ë¹„ìœ¨ (Choropleth Map)**")
        map_df = employment_df[employment_df['year'] == selected_year]
        if not map_df.empty:
            fig_map = px.choropleth(map_df, locations="iso_code", color="value", hover_name="group", color_continuous_scale=px.colors.sequential.Plasma, labels={'value': 'ê³ ìš© ë¹„ìœ¨ (%)'})
            st.plotly_chart(fig_map, use_container_width=True)
        else:
            st.warning(f"{selected_year}ë…„ì—ëŠ” í‘œì‹œí•  ê³ ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("**êµ­ê°€ë³„ ì‚°ì—… ê³ ìš© ë¹„ìœ¨ ì¶”ì´ ë¹„êµ**")
        all_countries = sorted(employment_df['group'].unique())
        default_countries = [c for c in ['World', 'Korea, Rep.', 'China', 'United States', 'Germany'] if c in all_countries] or all_countries[:3]
        selected_countries = st.multiselect("ë¹„êµí•  êµ­ê°€ë¥¼ ì„ íƒí•˜ì„¸ìš”:", all_countries, default=default_countries)
        if selected_countries:
            comp_df = employment_df[employment_df['group'].isin(selected_countries)]
            fig_comp = px.line(comp_df, x='year', y='value', color='group', labels={'year':'ì—°ë„', 'value':'ì‚°ì—… ê³ ìš© ë¹„ìœ¨(%)', 'group':'êµ­ê°€'})
            st.plotly_chart(fig_comp, use_container_width=True)
            st.download_button("ì„ íƒ êµ­ê°€ ê³ ìš© ë°ì´í„° ë‹¤ìš´ë¡œë“œ", comp_df.to_csv(index=False, encoding='utf-8-sig'), "employment_selected.csv", "text/csv", key="dl_emp")
    st.markdown("---")

    # --- Correlation Section ---
    st.subheader("ğŸ”„ ê¸°í›„ ì§€í‘œ vs. ì‚°ì—… ê³ ìš© ìƒê´€ê´€ê³„ ë¶„ì„")
    try:
        # Prepare data
        c_ann = climate_df.copy(); c_ann['year'] = c_ann['date'].dt.year
        c_ann_agg = c_ann.groupby('year')['value'].mean().reset_index().rename(columns={'value':'temp_anomaly'})
        
        co2_ann = co2_df.copy(); co2_ann['year'] = co2_ann['date'].dt.year
        co2_ann_agg = co2_ann.groupby('year')['value'].mean().reset_index().rename(columns={'value':'co2_ppm'})

        e_ann = employment_df.copy(); e_ann['year'] = e_ann['date'].dt.year
        e_ann_agg = e_ann.groupby('year')['value'].median().reset_index().rename(columns={'value':'employment_median'})
        
        merged = pd.merge(c_ann_agg, e_ann_agg, on='year', how='inner')
        merged = pd.merge(merged, co2_ann_agg, on='year', how='inner')
        
        corr_col1, corr_col2 = st.columns(2)
        corr_choice = corr_col1.selectbox("ê³ ìš© ë°ì´í„°ì™€ ë¹„êµí•  ê¸°í›„ ì§€í‘œë¥¼ ì„ íƒí•˜ì„¸ìš”:", ('ì˜¨ë„ ì´ìƒì¹˜', 'COâ‚‚ ë†ë„'))
        normalize = corr_col2.checkbox("ë°ì´í„° ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼)", help="ë‹¨ìœ„ê°€ ë‹¤ë¥¸ ë‘ ë°ì´í„°ë¥¼ 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ì„¸ ë¹„êµë¥¼ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.")
        
        x_var = 'temp_anomaly' if corr_choice == 'ì˜¨ë„ ì´ìƒì¹˜' else 'co2_ppm'
        y_var = 'employment_median'
        
        plot_df = merged[['year', x_var, y_var]].copy()
        correlation = plot_df[x_var].corr(plot_df[y_var])
        st.metric(f"{corr_choice} vs. ê³ ìš© ë¹„ìœ¨ ìƒê´€ê³„ìˆ˜", f"{correlation:.3f}", help="Pearson ìƒê´€ê³„ìˆ˜. 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„, -1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.")

        if normalize:
            plot_df[x_var] = normalize_series(plot_df[x_var])
            plot_df[y_var] = normalize_series(plot_df[y_var])
            
        fig_corr = go.Figure()
        fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[x_var], name=corr_choice, yaxis='y1'))
        fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[y_var], name='ì‚°ì—… ê³ ìš©(ì „ì„¸ê³„ ì¤‘ì•™ê°’)', yaxis='y2'))
        fig_corr.update_layout(title_text=f"ì—°ë„ë³„ {corr_choice}ì™€ ì‚°ì—… ê³ ìš© ë¹„ìœ¨ ë¹„êµ", yaxis=dict(title=f"{corr_choice} (ì •ê·œí™”)" if normalize else ('â„ƒ' if x_var=='temp_anomaly' else 'ppm')), yaxis2=dict(title="ì‚°ì—… ê³ ìš© ë¹„ìœ¨ (ì •ê·œí™”)" if normalize else "%", overlaying='y', side='right'))
        st.plotly_chart(fig_corr, use_container_width=True)
        st.download_button("ìƒê´€ê´€ê³„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", plot_df.to_csv(index=False, encoding='utf-8-sig'), "correlation_data.csv", "text/csv", key="dl_corr")
    except Exception as e:
        st.error(f"ìƒê´€ê´€ê³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def display_user_prompt_tab():
    """Render the content for the user prompt simulation tab."""
    st.header("ğŸ“„ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„")
    st.markdown("ì™¸ë¶€ ë¦¬í¬íŠ¸ì˜ ì˜ˆì¸¡ì„ ë°”íƒ•ìœ¼ë¡œ, **ì‚¬ìš©ìê°€ ì§ì ‘ ë³€ìˆ˜ë¥¼ ì¡°ì ˆ**í•˜ë©° ë¯¸ë˜ ì¼ìë¦¬ ë³€í™”ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # --- Interactive Controls ---
    col1, col2 = st.columns(2)
    green_growth_rate = col1.slider("ì—°ê°„ ë…¹ìƒ‰ ì¼ìë¦¬ ì„±ì¥ë¥  (%)", 1.0, 20.0, 10.0, 0.5) / 100
    fossil_decline_rate = col2.slider("ì—°ê°„ í™”ì„ì—°ë£Œ ì¼ìë¦¬ ê°ì†Œìœ¨ (%)", 1.0, 20.0, 8.0, 0.5) / 100
    
    # --- Generate Data Dynamically ---
    years = list(range(2024, 2041))
    green_jobs = [500] # Start with 500ë§Œ
    fossil_jobs = [1000] # Start with 1000ë§Œ
    for _ in range(1, len(years)):
        green_jobs.append(green_jobs[-1] * (1 + green_growth_rate))
        fossil_jobs.append(fossil_jobs[-1] * (1 - fossil_decline_rate))

    user_jobs_df = pd.DataFrame({
        'date': pd.to_datetime([datetime.date(y, 1, 1) for y in years] * 2),
        'group': ['ë…¹ìƒ‰ ì¼ìë¦¬(ë§Œ ê°œ)'] * len(years) + ['í™”ì„ì—°ë£Œ ì¼ìë¦¬(ë§Œ ê°œ)'] * len(years),
        'value': green_jobs + fossil_jobs
    })

    st.subheader(f"ğŸ’¼ {years[0]}ë…„ ~ {years[-1]}ë…„ ì¼ìë¦¬ ë³€í™” ì‹œë®¬ë ˆì´ì…˜")
    fig = px.line(user_jobs_df, x='date', y='value', color='group', labels={'date':'ì—°ë„', 'value':'ì´ ì¼ìë¦¬ ìˆ˜(ë§Œ ê°œ)', 'group':'êµ¬ë¶„'})
    st.plotly_chart(fig, use_container_width=True)
    
    # --- Summary Metrics ---
    st.markdown(f"**{years[-1]}ë…„ ì˜ˆì¸¡ ê²°ê³¼**")
    m1, m2, m3 = st.columns(3)
    final_green = user_jobs_df[user_jobs_df['group'] == 'ë…¹ìƒ‰ ì¼ìë¦¬(ë§Œ ê°œ)']['value'].iloc[-1]
    final_fossil = user_jobs_df[user_jobs_df['group'] == 'í™”ì„ì—°ë£Œ ì¼ìë¦¬(ë§Œ ê°œ)']['value'].iloc[-1]
    m1.metric("ë…¹ìƒ‰ ì¼ìë¦¬", f"{final_green:,.0f} ë§Œ ê°œ")
    m2.metric("í™”ì„ì—°ë£Œ ì¼ìë¦¬", f"{final_fossil:,.0f} ë§Œ ê°œ")
    m3.metric("ì´ ì¼ìë¦¬ ë³€í™”", f"{((final_green + final_fossil) - (green_jobs[0] + fossil_jobs[0])):,.0f} ë§Œ ê°œ", delta_color="off")
    st.download_button("ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", user_jobs_df.to_csv(index=False, encoding='utf-8-sig'), "scenario_data.csv", "text/csv", key="dl_scenario")

# ==============================================================================
# 4. MAIN APPLICATION LOGIC
# ==============================================================================
def main():
    """Main function to run the Streamlit app."""
    st.title("ê¸°í›„ ë³€í™”ì™€ ì·¨ì—… ë™í–¥ ëŒ€ì‹œë³´ë“œ")

    if 'data_loaded' not in st.session_state:
        st.sidebar.title("ë°ì´í„° ë¡œë“œ ìƒíƒœ")
        with st.spinner("ê³µì‹ ê³µê°œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            climate_raw = fetch_gistemp_csv()
            if climate_raw is None or climate_raw.empty:
                st.session_state.climate_df = preprocess_dataframe(get_sample_climate_data())
            else:
                st.session_state.climate_df = preprocess_dataframe(climate_raw)

            co2_raw = fetch_noaa_co2_data()
            if co2_raw is None or co2_raw.empty:
                st.session_state.co2_df = preprocess_dataframe(get_sample_co2_data())
            else:
                st.session_state.co2_df = preprocess_dataframe(co2_raw)

            employment_raw = fetch_worldbank_employment()
            if employment_raw is None or employment_raw.empty:
                st.session_state.employment_df = preprocess_dataframe(get_sample_employment_data())
            else:
                st.session_state.employment_df = preprocess_dataframe(employment_raw)

            st.session_state.data_loaded = True
            time.sleep(0.5)
            st.rerun() 
    
    tab1, tab2 = st.tabs(["ğŸŒ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ", "ğŸ“„ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„"])
    with tab1:
        display_public_data_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tab2:
        display_user_prompt_tab()

    with st.expander("ê°œë°œì ë° ì‹¤í–‰ í™˜ê²½ ì°¸ê³ ì‚¬í•­"):
        st.markdown("""
        - ì´ ì•±ì€ NASA/NOAA/WorldBank ê³µê°œ APIë¥¼ ìš°ì„ ì ìœ¼ë¡œ í˜¸ì¶œí•˜ë©°, ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨ ì‹œ ë‚´ì¥ëœ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ì „í™˜ë©ë‹ˆë‹¤.
        - **Kaggle ë°ì´í„° ì—°ë™ ë°©ë²•**: `pip install kaggle` í›„ Kaggle ê³„ì • ì„¤ì •ì—ì„œ API í† í°(`kaggle.json`)ì„ ë‹¤ìš´ë°›ì•„ `~/.kaggle/` í´ë”ì— ì €ì¥í•˜ì„¸ìš”.
        """)

if __name__ == "__main__":
    try:
        if os.path.exists(CONFIG["font_path"]):
            st.markdown(f"""
            <style>
            @font-face {{ font-family: 'PretendardCustom'; src: url('{CONFIG["font_path"]}') format('truetype'); }}
            html, body, [class*="css"] {{ font-family: 'PretendardCustom', Pretard, sans-serif; }}
            </style>""", unsafe_allow_html=True)
    except Exception: pass
    main()


