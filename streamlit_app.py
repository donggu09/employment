"""
Streamlit Dashboard (Korean) - V10.2 (Timeout Fix)
This version addresses potential `ConnectTimeoutError` issues by increasing the request timeout from 15 to 30 seconds. This makes the application more resilient to slow server responses, particularly from the NASA GISTEMP data source.
- Topic: 'The Impact of Climate Change on Employment'
- Core Features:
  1) Live public data dashboards via API calls with guaranteed fallbacks.
  2) In-depth analysis tab with correlation and job scenario simulator.
  3) A "Job Impact" section comparing green vs. at-risk jobs.
- UI/UX Enhancements:
  - **V10.2 Definitive Fix**:
    - **Increased Timeout**: Modified the `retry_get` function to use a 30-second timeout, reducing the likelihood of connection errors with slow-responding APIs.
    - **Corrected CO2 Parser**: Retained the fix for the NOAA CO2 data parser.
    - **Expanded Sample Data**: Retained the multi-year sample data.
    - **Robust Networking**: Retained the professional-grade requests.Session with a Retry adapter.
"""

import io
import time
import datetime
from typing import Optional, Dict, Any

import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.graph_objects as go
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ==============================================================================
# 0. CONFIGURATION & INITIAL SETUP
# ==============================================================================
st.set_page_config(
    page_title="ê¸°í›„ ë³€í™”ì™€ ë¯¸ë˜ ì»¤ë¦¬ì–´ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸŒ",
    layout="wide"
)

# --- App constants ---
TODAY = datetime.datetime.now().date()
CONFIG = {
    "nasa_gistemp_url": "https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv",
    "worldbank_api_url": "https://api.worldbank.org/v2/country/all/indicator/SL.IND.EMPL.ZS",
    "noaa_co2_url": "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt",
}

# --- Global Session with Retry Strategy ---
_SESSION = requests.Session()
_retry_strategy = Retry(
    total=5,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods=["HEAD", "GET", "OPTIONS"],
    backoff_factor=1
)
_adapter = HTTPAdapter(max_retries=_retry_strategy, pool_maxsize=10)
_SESSION.mount("https://", _adapter)
_SESSION.mount("http://", _adapter)


# ==============================================================================
# 1. UTILITY & DATA FUNCTIONS
# ==============================================================================
def retry_get(url: str, params: Optional[Dict] = None, **kwargs: Any) -> Optional[requests.Response]:
    """
    Robust GET request using the global session with a retry adapter.
    Upon final failure, it logs the error to the session state for UI display.
    """
    headers = {'User-Agent': 'Mozilla/5.0 (compatible; StreamlitApp/1.0)'}
    try:
        # [FIXED] Increased timeout from 15 to 30 seconds to handle slow server responses.
        resp = _SESSION.get(url, params=params, headers=headers, timeout=kwargs.get('timeout', 30), allow_redirects=True, verify=True)
        resp.raise_for_status()
        return resp
    except requests.exceptions.RequestException as e:
        # Reformat the error message to be more user-friendly
        error_message = f"**API(`{url.split('//')[1].split('/')[0]}`) ìš”ì²­ ì‹¤íŒ¨:** {e}"
        if 'api_errors' not in st.session_state:
            st.session_state.api_errors = []
        if error_message not in st.session_state.api_errors:
            st.session_state.api_errors.append(error_message)
        return None

@st.cache_data(ttl=3600)
def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return pd.DataFrame()
    d = df.copy()
    # Ensure 'date' column exists and convert it to datetime
    if 'date' in d.columns:
        d['date'] = pd.to_datetime(d['date'], errors='coerce')
        d = d.dropna(subset=['date'])
        d = d[d['date'].dt.date <= TODAY]
    else:
        return pd.DataFrame() # Return empty if no date column

    d['value'] = pd.to_numeric(d['value'], errors='coerce')
    subset_cols = ['date', 'group'] if 'group' in d.columns else ['date']
    d = d.drop_duplicates(subset=subset_cols)
    sort_cols = ['group', 'date'] if 'group' in d.columns else ['date']
    d = d.sort_values(sort_cols).reset_index(drop=True)
    if 'group' in d.columns:
        d['value'] = d.groupby('group')['value'].transform(lambda s: s.interpolate(method='linear', limit_direction='both'))
    else:
        d['value'] = d['value'].interpolate(method='linear', limit_direction='both')
    return d.dropna(subset=['value']).reset_index(drop=True)

# --- Data Fetching ---
@st.cache_data(ttl=3600)
def fetch_gistemp_csv() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["nasa_gistemp_url"])
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8', errors='replace')
        lines = content.split('\n')
        data_start_index = next((i for i, line in enumerate(lines) if line.strip().startswith('Year,')), -1)
        if data_start_index == -1: return None
        df = pd.read_csv(io.StringIO("\n".join(lines[data_start_index:])))
        df.columns = [c.strip() for c in df.columns]
        df_long = df.melt(id_vars=['Year'], value_vars=[m for m in ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'] if m in df.columns], var_name='Month', value_name='Anomaly')
        month_map = {name: num for num, name in enumerate(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], 1)}
        df_long['date'] = pd.to_datetime(df_long['Year'].astype(str) + '-' + df_long['Month'].map(month_map).astype(str), errors='coerce')
        df_final = df_long[['date']].copy()
        df_final['value'] = pd.to_numeric(df_long['Anomaly'], errors='coerce')
        df_final['group'] = 'ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ)'
        return df_final.dropna(subset=['date', 'value'])
    except Exception as e:
        if 'api_errors' not in st.session_state:
            st.session_state.api_errors = []
        st.session_state.api_errors.append(f"**NASA GISTEMP ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜:** `{e}`")
        return None

@st.cache_data(ttl=3600)
def fetch_noaa_co2_data() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["noaa_co2_url"])
    if resp is None: return None
    try:
        column_names = [
            'year', 'month', 'decimal_date', 'average', 'interpolated',
            'trend', 'days', 'uncertainty'
        ]
        df = pd.read_csv(
            io.StringIO(resp.content.decode('utf-8')),
            comment='#',
            delim_whitespace=True,
            header=None,
            names=column_names
        )
        df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01')
        df_final = df[['date', 'interpolated']].rename(columns={'interpolated': 'value'})
        df_final['group'] = 'ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm)'
        return df_final[df_final['value'] > 0]
    except Exception as e:
        if 'api_errors' not in st.session_state:
            st.session_state.api_errors = []
        st.session_state.api_errors.append(f"**NOAA COâ‚‚ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜:** `{e}`")
        return None

@st.cache_data(ttl=3600)
def fetch_worldbank_employment() -> Optional[pd.DataFrame]:
    resp = retry_get(CONFIG["worldbank_api_url"], params={'format': 'json', 'per_page': '20000'})
    if resp is None: return None
    try:
        data = resp.json()
        if not isinstance(data, list) or len(data) < 2 or not data[1]: return None
        df = pd.json_normalize(data[1])
        df = df[['country.value', 'countryiso3code', 'date', 'value']]
        df.columns = ['group', 'iso_code', 'year', 'value']
        df['date'] = pd.to_datetime(df['year'] + '-01-01', errors='coerce')
        return df[['date', 'group', 'iso_code', 'value']].dropna()
    except Exception as e:
        if 'api_errors' not in st.session_state:
            st.session_state.api_errors = []
        st.session_state.api_errors.append(f"**World Bank ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜:** `{e}`")
        return None

# --- [EXPANDED] Embedded Sample Data Fallbacks ---
@st.cache_data
def get_sample_climate_data() -> pd.DataFrame:
    csv_data = """date,value,group
2020-01-01,1.16,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2020-07-01,0.92,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2021-01-01,0.86,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2021-07-01,0.92,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2022-01-01,0.91,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2022-07-01,0.94,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2023-01-01,1.08,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
2023-07-01,1.24,"ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ) (ì˜ˆì‹œ)"
"""
    return pd.read_csv(io.StringIO(csv_data))

@st.cache_data
def get_sample_co2_data() -> pd.DataFrame:
    csv_data = """date,value,group
2020-01-01,413.4,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2020-07-01,414.72,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2021-01-01,415.4,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2021-07-01,416.96,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2022-01-01,418.28,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2022-07-01,418.91,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2023-01-01,420.51,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
2023-07-01,421.84,"ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm) (ì˜ˆì‹œ)"
"""
    return pd.read_csv(io.StringIO(csv_data))

@st.cache_data
def get_sample_employment_data() -> pd.DataFrame:
    csv_data = """date,group,iso_code,value
2020-01-01,World (ì˜ˆì‹œ),WLD,20.53
2021-01-01,World (ì˜ˆì‹œ),WLD,20.81
2022-01-01,World (ì˜ˆì‹œ),WLD,21.0
2023-01-01,World (ì˜ˆì‹œ),WLD,21.2
2020-01-01,Korea (ì˜ˆì‹œ),KOR,23.2
2021-01-01,Korea (ì˜ˆì‹œ),KOR,23.5
2022-01-01,Korea (ì˜ˆì‹œ),KOR,23.7
2023-01-01,Korea (ì˜ˆì‹œ),KOR,23.9
"""
    return pd.read_csv(io.StringIO(csv_data))

# ==============================================================================
# 3. UI RENDERING FUNCTIONS FOR TABS
# ==============================================================================
# --------------------------- Data Status UI -----------------------------
def display_data_status():
    st.subheader("ë°ì´í„° ì¶œì²˜ í˜„í™©")
    status = st.session_state.get('data_status', {})
    
    cols = st.columns(3)
    
    nasa_status = status.get('climate', 'N/A')
    noaa_status = status.get('co2', 'N/A')
    wb_status = status.get('employment', 'N/A')

    with cols[0]:
        st.markdown(f"**NASA GISTEMP (ê¸°ì˜¨)**: { 'ğŸŸ¢ ì‹¤ì‹œê°„' if nasa_status == 'Live' else 'ğŸŸ¡ ì˜ˆì‹œ'}")
    with cols[1]:
        st.markdown(f"**NOAA COâ‚‚ (ì´ì‚°í™”íƒ„ì†Œ)**: { 'ğŸŸ¢ ì‹¤ì‹œê°„' if noaa_status == 'Live' else 'ğŸŸ¡ ì˜ˆì‹œ'}")
    with cols[2]:
        st.markdown(f"**World Bank (ê³ ìš©)**: { 'ğŸŸ¢ ì‹¤ì‹œê°„' if wb_status == 'Live' else 'ğŸŸ¡ ì˜ˆì‹œ'}")
    st.markdown("---")

# --------------------------- API Error UI -----------------------------
def display_api_errors():
    """Displays any API errors that were collected during the data loading process."""
    if st.session_state.get('api_errors'):
        st.subheader("âš ï¸ API í˜¸ì¶œ ë˜ëŠ” ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜")
        for error in st.session_state.api_errors:
            st.error(error, icon="ğŸ”¥")
        st.markdown("---")


# --------------------------- TAB 1: Global Trends -----------------------------
def display_global_trends_tab(climate_df, co2_df, employment_df):
    st.header("ğŸ“ˆ ê¸€ë¡œë²Œ ê¸°í›„ ë° ê³ ìš© ë™í–¥")
    st.markdown("NASA, NOAA, World Bankì˜ ìµœì‹  ë°ì´í„°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
    
    col1, col2, col3 = st.columns(3)
    if not climate_df.empty and not co2_df.empty and not employment_df.empty:
        try:
            # Ensure date column is datetime before formatting
            climate_df['date'] = pd.to_datetime(climate_df['date'])
            co2_df['date'] = pd.to_datetime(co2_df['date'])

            latest_climate = climate_df.sort_values('date', ascending=False).iloc[0]
            latest_co2 = co2_df.sort_values('date', ascending=False).iloc[0]
            col1.metric(f"ìµœì‹  ì˜¨ë„ ì´ìƒì¹˜ ({latest_climate['date']:%Y-%m})", f"{latest_climate['value']:.2f} â„ƒ")
            col2.metric(f"ìµœì‹  COâ‚‚ ë†ë„ ({latest_co2['date']:%Y-%m})", f"{latest_co2['value']:.2f} ppm")
            col3.metric("ê³ ìš© ë°ì´í„° êµ­ê°€ ìˆ˜", f"{employment_df['group'].nunique()} ê°œ")
        except (IndexError, ValueError, TypeError): 
            st.info("í•µì‹¬ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        st.info("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì´ê±°ë‚˜ API í˜¸ì¶œì— ì‹¤íŒ¨í•˜ì—¬ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.markdown("---")

    c1, c2 = st.columns(2)
    with c1:
        st.subheader("ğŸŒ¡ï¸ ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜")
        if not climate_df.empty:
            fig = px.line(climate_df, x='date', y='value', labels={'date': '', 'value': 'ì˜¨ë„ ì´ìƒì¹˜ (Â°C)'}, color_discrete_sequence=['#d62728'])
            st.plotly_chart(fig, use_container_width=True)
    with c2:
        st.subheader("ğŸ’¨ ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ë§ˆìš°ë‚˜ë¡œì•„)")
        if not co2_df.empty:
            fig = px.line(co2_df, x='date', y='value', labels={'date': '', 'value': 'COâ‚‚ (ppm)'}, color_discrete_sequence=['#1f77b4'])
            st.plotly_chart(fig, use_container_width=True)
    st.markdown("---")

    st.subheader("ğŸ­ ì‚°ì—…ë³„ ê³ ìš© ë¹„ìœ¨ ë³€í™”")
    if not employment_df.empty:
        employment_df['year'] = pd.to_datetime(employment_df['date']).dt.year
        min_year, max_year = int(employment_df['year'].min()), int(employment_df['year'].max())
        selected_year = st.slider("ì—°ë„ ì„ íƒ:", min_year, max_year, max_year, key="map_year_slider")
        
        map_df = employment_df[employment_df['year'] == selected_year]
        if not map_df.empty:
            fig_map = px.choropleth(map_df, locations="iso_code", color="value", hover_name="group", color_continuous_scale=px.colors.sequential.Plasma, labels={'value': 'ê³ ìš© ë¹„ìœ¨ (%)'}, title=f"{selected_year}ë…„ ì „ ì„¸ê³„ ì‚°ì—… ê³ ìš© ë¹„ìœ¨")
            st.plotly_chart(fig_map, use_container_width=True)

        all_countries = sorted(employment_df['group'].unique())
        default_countries = [c for c in ['World', 'Korea, Rep.', 'World (ì˜ˆì‹œ)', 'Korea (ì˜ˆì‹œ)'] if c in all_countries] or all_countries[:2]
        selected_countries = st.multiselect("êµ­ê°€ë³„ ì¶”ì´ ë¹„êµ:", all_countries, default=default_countries)
        if selected_countries:
            comp_df = employment_df[employment_df['group'].isin(selected_countries)]
            fig_comp = px.line(comp_df, x='year', y='value', color='group', labels={'year':'ì—°ë„', 'value':'ì‚°ì—… ê³ ìš© ë¹„ìœ¨(%)', 'group':'êµ­ê°€'})
            st.plotly_chart(fig_comp, use_container_width=True)

# ------------------------- TAB 2: In-Depth Analysis ---------------------------
def display_analysis_tab(climate_df, co2_df, employment_df):
    st.header("ğŸ” ì‹¬ì¸µ ë¶„ì„: ìƒê´€ê´€ê³„ì™€ ë¯¸ë˜ ì‹œë®¬ë ˆì´ì…˜")
    
    with st.container(border=True):
        st.subheader("ğŸ”„ ê¸°í›„ ì§€í‘œ vs. ì‚°ì—… ê³ ìš© ìƒê´€ê´€ê³„")
        if climate_df.empty or co2_df.empty or employment_df.empty:
            st.warning("ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return

        try:
            climate_df['year'] = pd.to_datetime(climate_df['date']).dt.year
            c_ann_agg = climate_df.groupby('year')['value'].mean().reset_index().rename(columns={'value':'temp_anomaly'})
            
            co2_df['year'] = pd.to_datetime(co2_df['date']).dt.year
            co2_ann_agg = co2_df.groupby('year')['value'].mean().reset_index().rename(columns={'value':'co2_ppm'})
            
            employment_df['year'] = pd.to_datetime(employment_df['date']).dt.year
            e_ann_agg = employment_df.groupby(['year'])['value'].median().reset_index().rename(columns={'value':'employment_median'})
            
            merged = pd.merge(c_ann_agg, e_ann_agg, on='year', how='inner')
            merged = pd.merge(merged, co2_ann_agg, on='year', how='inner')

            if len(merged) < 2:
                st.warning("ë°ì´í„° ê¸°ê°„ì´ ì§§ì•„ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            corr_col1, corr_col2 = st.columns(2)
            corr_choice = corr_col1.selectbox("ë¹„êµí•  ê¸°í›„ ì§€í‘œ:", ('ì˜¨ë„ ì´ìƒì¹˜', 'COâ‚‚ ë†ë„'))
            normalize = corr_col2.checkbox("ë°ì´í„° ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼)", help="ë‹¨ìœ„ê°€ ë‹¤ë¥¸ ë‘ ë°ì´í„°ë¥¼ 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ì„¸ ë¹„êµë¥¼ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.")
            
            x_var = 'temp_anomaly' if corr_choice == 'ì˜¨ë„ ì´ìƒì¹˜' else 'co2_ppm'
            y_var = 'employment_median'
            
            plot_df = merged[['year', x_var, y_var]].copy()
            correlation = plot_df[x_var].corr(plot_df[y_var])
            st.metric(f"{corr_choice} vs. ê³ ìš© ë¹„ìœ¨ ìƒê´€ê³„ìˆ˜", f"{correlation:.3f}")

            if normalize:
                plot_df[x_var] = (plot_df[x_var] - plot_df[x_var].min()) / (plot_df[x_var].max() - plot_df[x_var].min())
                plot_df[y_var] = (plot_df[y_var] - plot_df[y_var].min()) / (plot_df[y_var].max() - plot_df[y_var].min())
            
            # Create a figure with a secondary y-axis
            fig_corr = go.Figure()
            fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[x_var], name=corr_choice,
                                          line=dict(color='#d62728')))
            fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[y_var], name='ì‚°ì—… ê³ ìš©(ì „ì„¸ê³„ ì¤‘ì•™ê°’)', yaxis='y2',
                                          line=dict(color='#1f77b4')))

            # Update layout for the secondary y-axis
            fig_corr.update_layout(
                xaxis_title="ì—°ë„",
                yaxis_title=f"{corr_choice} ({'â„ƒ' if x_var == 'temp_anomaly' else 'ppm'})" if not normalize else "ì •ê·œí™”ëœ ê°’",
                yaxis2=dict(
                    title="ì‚°ì—… ê³ ìš© ë¹„ìœ¨ (%)" if not normalize else "ì •ê·œí™”ëœ ê°’",
                    overlaying="y",
                    side="right"
                ),
                legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
            )
            st.plotly_chart(fig_corr, use_container_width=True)

        except Exception as e:
            st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    st.markdown("---")
    
    with st.container(border=True):
        st.subheader("ğŸ“„ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„")
        col1, col2 = st.columns(2)
        green_growth_rate = col1.slider("ì—°ê°„ ë…¹ìƒ‰ ì¼ìë¦¬ ì„±ì¥ë¥  (%)", 1.0, 20.0, 10.0, 0.5, key="sim_growth") / 100
        fossil_decline_rate = col2.slider("ì—°ê°„ í™”ì„ì—°ë£Œ ì¼ìë¦¬ ê°ì†Œìœ¨ (%)", 1.0, 20.0, 8.0, 0.5, key="sim_decline") / 100
        
        years = list(range(2025, 2041))
        green_jobs, fossil_jobs = [500], [1000]
        for _ in range(1, len(years)):
            green_jobs.append(green_jobs[-1] * (1 + green_growth_rate))
            fossil_jobs.append(fossil_jobs[-1] * (1 - fossil_decline_rate))

        user_jobs_df = pd.DataFrame({ 'date': pd.to_datetime([datetime.date(y, 1, 1) for y in years] * 2), 'group': ['ë…¹ìƒ‰ ì¼ìë¦¬(ë§Œ ê°œ)'] * len(years) + ['í™”ì„ì—°ë£Œ ì¼ìë¦¬(ë§Œ ê°œ)'] * len(years), 'value': green_jobs + fossil_jobs })
        fig = px.line(user_jobs_df, x='date', y='value', color='group', color_discrete_map={'ë…¹ìƒ‰ ì¼ìë¦¬(ë§Œ ê°œ)': '#2ca02c', 'í™”ì„ì—°ë£Œ ì¼ìë¦¬(ë§Œ ê°œ)': '#7f7f7f'})
        st.plotly_chart(fig, use_container_width=True)

# --------------------------- TAB 3: Job Impact --------------------------------
def display_job_impact_tab():
    st.header("âš–ï¸ ë…¹ìƒ‰ ì „í™˜: ê¸°íšŒì™€ ìœ„í—˜ ì§ë¬´ ë¹„êµ")
    df_op = pd.DataFrame({ 'ì§ë¬´': ['ê¸°í›„ ë°ì´í„° ë¶„ì„ê°€', 'íƒ„ì†Œë°°ì¶œê¶Œ ì „ë¬¸ê°€', 'ì‹ ì¬ìƒ ì—ë„ˆì§€ ê°œë°œì', 'ESG ì»¨ì„¤í„´íŠ¸', 'ìŠ¤ë§ˆíŠ¸íŒœ ì „ë¬¸ê°€'], 'ì„±ì¥ ê°€ëŠ¥ì„± (ì ìˆ˜)': [95, 90, 88, 85, 82] })
    df_r = pd.DataFrame({ 'ì§ë¬´': ['í™”ë ¥ ë°œì „ì†Œ ê¸°ìˆ ì', 'ìë™ì°¨ ë‚´ì—°ê¸°ê´€ ì—”ì§€ë‹ˆì–´', 'ì„ìœ í™”í•™ ê³µì¥ ìš´ì˜ì›', 'ë²Œëª©ì—… ì¢…ì‚¬ì'], 'ìœ„í—˜ë„ (ì ìˆ˜)': [90, 85, 80, 75] })
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ’¡ ì„±ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë…¹ìƒ‰ ì§ë¬´")
        fig_op = px.bar(df_op, x='ì„±ì¥ ê°€ëŠ¥ì„± (ì ìˆ˜)', y='ì§ë¬´', orientation='h', color='ì„±ì¥ ê°€ëŠ¥ì„± (ì ìˆ˜)', color_continuous_scale=px.colors.sequential.Greens)
        st.plotly_chart(fig_op, use_container_width=True)
    with col2:
        st.subheader("âš ï¸ ì „í™˜ì´ í•„ìš”í•œ ê¸°ì¡´ ì§ë¬´")
        fig_risk = px.bar(df_r, x='ìœ„í—˜ë„ (ì ìˆ˜)', y='ì§ë¬´', orientation='h', color='ìœ„í—˜ë„ (ì ìˆ˜)', color_continuous_scale=px.colors.sequential.Reds)
        st.plotly_chart(fig_risk, use_container_width=True)


# ----------------------- TAB 4: Career Simulation Game ------------------------
def display_career_game_tab():
    st.header("ğŸš€ ë‚˜ì˜ ë¯¸ë˜ ì„¤ê³„í•˜ê¸° (ì»¤ë¦¬ì–´ ì‹œë®¬ë ˆì´ì…˜)")
    st.info("ë‹¹ì‹ ì˜ ì„ íƒì´ 10ë…„ í›„ ì»¤ë¦¬ì–´ì™€ í™˜ê²½ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜ í•´ë³´ì„¸ìš”!")

    with st.form("career_game_form"):
        # --- Stage 1: University ---
        with st.expander("ğŸ“ 1ë‹¨ê³„: ëŒ€í•™ìƒ", expanded=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                major = st.radio("ì£¼ìš” ì „ê³µì„ ì„ íƒí•˜ì„¸ìš”:",
                                 ("ì»´í“¨í„°ê³µí•™ (AI íŠ¸ë™)", "ê¸°ê³„ê³µí•™", "ê²½ì œí•™"), key="major")
            with col2:
                club = st.radio("í•µì‹¬ ë™ì•„ë¦¬ í™œë™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                                ("ì‹ ì¬ìƒì—ë„ˆì§€ ì •ì±… í† ë¡ ", "ì½”ë”© ìŠ¤í„°ë””", "ë¬¸í•™ ë¹„í‰"), key="club")
            with col3:
                project = st.radio("ì¡¸ì—… í”„ë¡œì íŠ¸ ì£¼ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                                   ("íƒ„ì†Œ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ AI ëª¨ë¸", "ê³ íš¨ìœ¨ ë‚´ì—°ê¸°ê´€ ì„¤ê³„", "ESG ê²½ì˜ì‚¬ë¡€ ë¶„ì„"), key="project")

        # --- Stage 2: Early Career ---
        with st.expander("ğŸ’¼ 2ë‹¨ê³„: ì‚¬íšŒì´ˆë…„ìƒ", expanded=True):
            col4, col5, col6 = st.columns(3)
            with col4:
                first_job = st.radio("ì²« ì§ì¥ì„ ì„ íƒí•˜ì„¸ìš”:",
                                     ("ì—ë„ˆì§€ IT ìŠ¤íƒ€íŠ¸ì—…", "ëŒ€ê¸°ì—… ì •ìœ íšŒì‚¬", "ê¸ˆìœµê¶Œ ì• ë„ë¦¬ìŠ¤íŠ¸"), key="first_job")
            with col5:
                skill_dev = st.radio("ì–´ë–¤ ì—­ëŸ‰ì„ ì§‘ì¤‘ì ìœ¼ë¡œ í‚¤ìš¸ ê±´ê°€ìš”?",
                                     ("í´ë¼ìš°ë“œ ê¸°ë°˜ ë°ì´í„° ë¶„ì„", "ì „í†µ ê³µì • ê´€ë¦¬", "ì¬ë¬´ ë¶„ì„ ë° íˆ¬ì"), key="skill_dev")
            with col6:
                side_project = st.radio("ê°œì¸ì ìœ¼ë¡œ ì§„í–‰í•  í”„ë¡œì íŠ¸ëŠ”?",
                                        ("ì˜¤í”ˆì†ŒìŠ¤ ê¸°í›„ ë°ì´í„° ì‹œê°í™”", "ìë™ì°¨ ì—°ë¹„ ê°œì„  ì—°êµ¬", "ì£¼ì‹ íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬"), key="side_project")
        
        submitted = st.form_submit_button("ğŸš€ ë‚˜ì˜ ë¯¸ë˜ í™•ì¸í•˜ê¸°")

    if submitted:
        # --- Scoring Logic ---
        career_score, green_score = 0, 0
        skills = {"ë°ì´í„° ë¶„ì„":0, "ì •ì±…/ê²½ì˜":0, "ì—”ì§€ë‹ˆì–´ë§":0, "ê¸ˆìœµ/ê²½ì œ":0}

        # Stage 1 Scoring
        if major == "ì»´í“¨í„°ê³µí•™ (AI íŠ¸ë™)": career_score += 20; green_score += 10; skills["ë°ì´í„° ë¶„ì„"] += 2
        elif major == "ê¸°ê³„ê³µí•™": career_score += 10; green_score += 0; skills["ì—”ì§€ë‹ˆì–´ë§"] += 2
        else: career_score += 15; green_score += 5; skills["ê¸ˆìœµ/ê²½ì œ"] += 2

        if club == "ì‹ ì¬ìƒì—ë„ˆì§€ ì •ì±… í† ë¡ ": career_score += 10; green_score += 15; skills["ì •ì±…/ê²½ì˜"] += 1
        elif club == "ì½”ë”© ìŠ¤í„°ë””": career_score += 15; green_score += 5; skills["ë°ì´í„° ë¶„ì„"] += 1
        else: career_score += 5; green_score += 0

        if project == "íƒ„ì†Œ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ AI ëª¨ë¸": career_score += 15; green_score += 20; skills["ë°ì´í„° ë¶„ì„"] += 1; skills["ì •ì±…/ê²½ì˜"] += 1
        elif project == "ê³ íš¨ìœ¨ ë‚´ì—°ê¸°ê´€ ì„¤ê³„": career_score += 5; green_score -= 10; skills["ì—”ì§€ë‹ˆì–´ë§"] += 1
        else: career_score += 10; green_score += 10; skills["ì •ì±…/ê²½ì˜"] += 1; skills["ê¸ˆìœµ/ê²½ì œ"] += 1

        # Stage 2 Scoring
        if first_job == "ì—ë„ˆì§€ IT ìŠ¤íƒ€íŠ¸ì—…": career_score += 15; green_score += 20
        elif first_job == "ëŒ€ê¸°ì—… ì •ìœ íšŒì‚¬": career_score += 20; green_score -= 10
        else: career_score += 15; green_score += 5

        if skill_dev == "í´ë¼ìš°ë“œ ê¸°ë°˜ ë°ì´í„° ë¶„ì„": career_score += 20; green_score += 10; skills["ë°ì´í„° ë¶„ì„"] += 2
        elif skill_dev == "ì „í†µ ê³µì • ê´€ë¦¬": career_score += 10; green_score -= 5; skills["ì—”ì§€ë‹ˆì–´ë§"] += 1
        else: career_score += 15; green_score += 0; skills["ê¸ˆìœµ/ê²½ì œ"] += 1

        if side_project == "ì˜¤í”ˆì†ŒìŠ¤ ê¸°í›„ ë°ì´í„° ì‹œê°í™”": career_score += 10; green_score += 15; skills["ë°ì´í„° ë¶„ì„"] += 1
        elif side_project == "ìë™ì°¨ ì—°ë¹„ ê°œì„  ì—°êµ¬": career_score += 5; green_score -= 5; skills["ì—”ì§€ë‹ˆì–´ë§"] += 1
        else: career_score += 5; green_score += 0; skills["ê¸ˆìœµ/ê²½ì œ"] += 1
        
        # --- Determine Job Title ---
        if green_score >= 50 and career_score >= 70: job_title = "ê¸°í›„ ê¸°ìˆ  ìµœê³  ì „ë¬¸ê°€"
        elif green_score >= 30 and career_score >= 60: job_title = "ê·¸ë¦° ì—ë„ˆì§€ ì „ëµê°€"
        elif career_score >= 70: job_title = "ì‚°ì—… ì „ë¬¸ê°€"
        elif green_score >= 30: job_title = "í™˜ê²½ ì •ì±…ê°€"
        else: job_title = "ë¯¸ë˜ ì¤€ë¹„í˜• ì¸ì¬"

        st.subheader("ğŸ‰ ìµœì¢… ê²°ê³¼: ë‹¹ì‹ ì˜ ì»¤ë¦¬ì–´ ì¹´ë“œ")
        with st.container(border=True):
            res1, res2 = st.columns([0.6, 0.4])
            with res1:
                st.markdown(f"#### ğŸ’¼ ì§ì—…: {job_title}")
                st.metric("ğŸš€ ë¯¸ë˜ ì „ë§ ì ìˆ˜", f"{career_score} / 100")
                st.metric("ğŸŒ± í™˜ê²½ ê¸°ì—¬ë„ ì ìˆ˜", f"{green_score} / 75")

            with res2:
                df_skills = pd.DataFrame(dict(r=list(skills.values()), theta=list(skills.keys())))
                fig = px.line_polar(df_skills, r='r', theta='theta', line_close=True, range_r=[0,5])
                fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])))
                st.plotly_chart(fig, use_container_width=True)
                st.caption("ë‚˜ì˜ ì—­ëŸ‰ ë ˆì´ë” ì°¨íŠ¸")

# ----------------------- TAB 5: Survey & Feedback ------------------------
def display_survey_tab():
    st.header("ğŸ“ ì„¤ë¬¸ ë° ì˜ê²¬")
    st.markdown("ê¸°í›„ ë³€í™”ì™€ ë¯¸ë˜ ì§ì—…ì— ëŒ€í•œ ì—¬ëŸ¬ë¶„ì˜ ì†Œì¤‘í•œ ì˜ê²¬ì„ ë“¤ë ¤ì£¼ì„¸ìš”!")

    with st.form("survey_form"):
        st.subheader("ê°œì¸ ì¸ì‹")
        q1 = st.radio("1ï¸âƒ£ ê¸°í›„ë³€í™”ê°€ ë‚˜ì˜ ì§ì—…(ë˜ëŠ” ë¯¸ë˜ ì§ì—…)ì— ì˜í–¥ì„ ì¤„ ê²ƒì´ë¼ ìƒê°í•˜ì‹œë‚˜ìš”?", ["ë§¤ìš° ê·¸ë ‡ë‹¤", "ì¡°ê¸ˆ ê·¸ë ‡ë‹¤", "ë³„ë¡œ ì•„ë‹ˆë‹¤", "ì „í˜€ ì•„ë‹ˆë‹¤"])
        q2 = st.slider("2ï¸âƒ£ ê¸°í›„ë³€í™” ëŒ€ì‘ ì—­ëŸ‰ì„ í‚¤ìš°ê³  ì‹¶ì€ ì •ë„ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”? (0~10ì )", 0, 10, 5)
        
        st.subheader("ì§ì—… ì„ í˜¸ë„")
        q3 = st.selectbox("3ï¸âƒ£ ê°€ì¥ ê´€ì‹¬ ìˆëŠ” ë…¹ìƒ‰ ì¼ìë¦¬ ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", ["ì‹ ì¬ìƒì—ë„ˆì§€", "ESG ì»¨ì„¤íŒ…", "íƒ„ì†Œ ë°°ì¶œê¶Œ ê±°ë˜", "ê¸°í›„ ë°ì´í„° ë¶„ì„", "ìŠ¤ë§ˆíŠ¸íŒœ/ì¹œí™˜ê²½ ë†ì—…", "ê¸°íƒ€"])
        q4 = st.multiselect("4ï¸âƒ£ ë…¹ìƒ‰ ì¼ìë¦¬ ì „í™˜ ì‹œ ê°€ì¥ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ì§€ì›ì€ ë¬´ì—‡ì¸ê°€ìš”? (ì¤‘ë³µ ì„ íƒ ê°€ëŠ¥)", ["ì „ë¬¸ ì¬êµìœ¡ í”„ë¡œê·¸ë¨", "ì •ë¶€ì˜ ì¬ì • ì§€ì›", "ê¸°ì—…ì˜ ì±„ìš© ì—°ê³„", "ë©˜í† ë§ ë° ìƒë‹´"])
        
        st.subheader("ì •ì±… ë° ì‚¬íšŒ")
        q5 = st.radio("5ï¸âƒ£ ê¸°í›„ë³€í™” ëŒ€ì‘ì„ ìœ„í•´ ì„¸ê¸ˆ(íƒ„ì†Œì„¸ ë“±)ì„ ë” ë‚´ëŠ” ê²ƒì— ë™ì˜í•˜ì‹œë‚˜ìš”?", ["ì ê·¹ ì°¬ì„±", "ì°¬ì„±", "ë°˜ëŒ€", "ì ê·¹ ë°˜ëŒ€"])
        q6 = st.text_area("6ï¸âƒ£ ë…¹ìƒ‰ ì¼ìë¦¬ í™•ëŒ€ë¥¼ ìœ„í•´ ê°€ì¥ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ì •ì±…ì´ë‚˜ ì œì•ˆì´ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ ì ì–´ì£¼ì„¸ìš”.")
        
        submitted = st.form_submit_button("ì„¤ë¬¸ ì œì¶œí•˜ê¸°")

    if submitted:
        st.success("âœ… ì„¤ë¬¸ì— ì°¸ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì•„ë˜ëŠ” ë‚˜ì˜ ì‘ë‹µ ìš”ì•½ì…ë‹ˆë‹¤.")
        
        with st.container(border=True):
            st.subheader("ğŸ“‹ ë‚˜ì˜ ì‘ë‹µ ìš”ì•½")
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**ê¸°í›„ë³€í™” ì˜í–¥ ì¸ì‹:** {q1}")
                st.write(f"**ê´€ì‹¬ ë…¹ìƒ‰ ì¼ìë¦¬:** {q3}")
                st.write(f"**í•„ìš”í•œ ì§€ì›:** {', '.join(q4) if q4 else 'ì„ íƒ ì•ˆí•¨'}")
                st.write(f"**íƒ„ì†Œì„¸ ë™ì˜:** {q5}")
            
            with col2:
                fig = go.Figure(go.Indicator(
                    mode = "gauge+number", value = q2,
                    title = {'text': "ë‚˜ì˜ ì—­ëŸ‰ ê°œë°œ ì˜ì§€ ì ìˆ˜"},
                    gauge = {'axis': {'range': [None, 10]}, 'bar': {'color': "#2ca02c"}}))
                st.plotly_chart(fig, use_container_width=True)

# ==============================================================================
# 4. MAIN APPLICATION LOGIC
# ==============================================================================
def main():
    # [FIXED] Updated title to match version V10.2
    st.title("ê¸°í›„ ë³€í™”ì™€ ë¯¸ë˜ ì»¤ë¦¬ì–´ ëŒ€ì‹œë³´ë“œ V10.2 (íƒ€ì„ì•„ì›ƒ ìˆ˜ì •) ğŸŒğŸ’¼")

    # --- Data Loading ---
    if 'data_loaded' not in st.session_state:
        st.session_state.data_status = {}
        st.session_state.api_errors = [] # Initialize error list

        with st.spinner("ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            
            # --- Unified Data Pipeline ---
            
            # Climate Data
            climate_raw = fetch_gistemp_csv()
            if climate_raw is not None and not climate_raw.empty:
                st.session_state.data_status['climate'] = 'Live'
            else:
                climate_raw = get_sample_climate_data()
                st.session_state.data_status['climate'] = 'Sample'
            st.session_state.climate_df = preprocess_dataframe(climate_raw)

            # CO2 Data
            co2_raw = fetch_noaa_co2_data()
            if co2_raw is not None and not co2_raw.empty:
                st.session_state.data_status['co2'] = 'Live'
            else:
                co2_raw = get_sample_co2_data()
                st.session_state.data_status['co2'] = 'Sample'
            st.session_state.co2_df = preprocess_dataframe(co2_raw)

            # Employment Data
            wb_employment_raw = fetch_worldbank_employment()
            if wb_employment_raw is not None and not wb_employment_raw.empty:
                st.session_state.data_status['employment'] = 'Live'
            else:
                wb_employment_raw = get_sample_employment_data()
                st.session_state.data_status['employment'] = 'Sample'
            st.session_state.employment_df = preprocess_dataframe(wb_employment_raw)
            
            st.session_state.data_loaded = True
            time.sleep(0.5)
            st.rerun()
    
    # --- Display Status and Error Panels ---
    display_data_status()
    display_api_errors()
    
    # --- Tabbed Interface ---
    tabs = st.tabs(["ğŸ“Š ê¸€ë¡œë²Œ ë™í–¥", "ğŸ” ì‹¬ì¸µ ë¶„ì„", "âš–ï¸ ì§ë¬´ ì˜í–¥ ë¶„ì„", "ğŸš€ ë‚˜ì˜ ë¯¸ë˜ ì„¤ê³„í•˜ê¸°", "ğŸ“ ì„¤ë¬¸ ë° ì˜ê²¬"])
    with tabs[0]:
        display_global_trends_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tabs[1]:
        display_analysis_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df)
    with tabs[2]:
        display_job_impact_tab()
    with tabs[3]:
        display_career_game_tab()
    with tabs[4]:
        display_survey_tab()

if __name__ == "__main__":
    main()

