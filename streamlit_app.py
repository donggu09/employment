"""
Streamlit Dashboard (Korean) - FULLY INTEGRATED VERSION (V2)

Topic: 'The Impact of Climate Change on Employment'

Merged Features:
- Advanced interactive dashboard with real-time public data (NASA, NOAA, World Bank).
- Interactive 'what-if' scenario simulation for job market forecasting.
- A detailed, text-based 'Analysis Report' page for qualitative insights.
- Sidebar navigation to switch between the features.

V2 Enhancements:
- Added 'Promising Future Jobs' page with career-focused information.
- Added renewable energy generation data visualization to the main dashboard.
- Improved UI/UX with a card-based layout for better readability and aesthetics.
- Added icons to headers for intuitive navigation.

Data Robustness:
- All API calls have fallbacks to generate sample data upon failure.
- Data is cached and stored in session_state for efficient performance.
"""

import os
import io
import time
import datetime
from typing import Optional, Dict, Any

import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.graph_objects as go

# ==============================================================================
# 0. CONFIGURATION & INITIAL SETUP
# ==============================================================================
st.set_page_config(
    page_title="ê¸°í›„ì™€ ì·¨ì—…: í†µí•© ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸŒ",
    layout="wide"
)

# --- App constants ---
TODAY = datetime.datetime.now().date()
CONFIG = {
    "nasa_gistemp_url": "https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv",
    "worldbank_api_url": "https://api.worldbank.org/v2/country/all/indicator/SL.IND.EMPL.ZS",
    "noaa_co2_url": "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt",
    "font_path": "/fonts/Pretendard-Bold.ttf",
}

# ==============================================================================
# 1. UTILITY & DATA LOADING FUNCTIONS
# ==============================================================================
def retry_get(url: str, params: Optional[Dict] = None, **kwargs: Any) -> Optional[requests.Response]:
    """Robust GET request with retries and user-agent."""
    final_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    for attempt in range(kwargs.get('max_retries', 2) + 1):
        try:
            resp = requests.get(url, params=params, headers=final_headers, timeout=kwargs.get('timeout', 15))
            resp.raise_for_status()
            return resp
        except requests.exceptions.RequestException as e:
            if attempt < kwargs.get('max_retries', 2):
                time.sleep(kwargs.get('backoff', 1.0) * (attempt + 1))
                continue
            st.sidebar.warning(f"API ìš”ì²­ ì‹¤íŒ¨: {url.split('?')[0]} ({e})")
            return None

@st.cache_data(ttl=3600)
def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """Standardize and preprocess a dataframe."""
    if df is None or df.empty: return pd.DataFrame()
    d = df.copy()
    d['date'] = pd.to_datetime(d['date'], errors='coerce')
    d = d.dropna(subset=['date'])
    d = d[d['date'].dt.date <= TODAY]
    d['value'] = pd.to_numeric(d['value'], errors='coerce')
    subset_cols = ['date', 'group'] if 'group' in d.columns else ['date']
    d = d.drop_duplicates(subset=subset_cols)
    sort_cols = ['group', 'date'] if 'group' in d.columns else ['date']
    d = d.sort_values(sort_cols).reset_index(drop=True)
    if 'group' in d.columns:
        d['value'] = d.groupby('group')['value'].transform(lambda s: s.interpolate(method='linear', limit_direction='both', limit_area='inside'))
    else:
        d['value'] = d['value'].interpolate(method='linear', limit_direction='both', limit_area='inside')
    return d.dropna(subset=['value']).reset_index(drop=True)

def normalize_series(s: pd.Series) -> pd.Series:
    """Normalize a pandas Series to a 0-1 scale."""
    if s.max() == s.min(): return pd.Series(0.5, index=s.index)
    return (s - s.min()) / (s.max() - s.min())

@st.cache_data(ttl=3600)
def fetch_gistemp_csv() -> Optional[pd.DataFrame]:
    """Fetch and parse NASA GISTEMP global monthly anomalies."""
    resp = retry_get(CONFIG["nasa_gistemp_url"], max_retries=1)
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8', errors='replace')
        lines = content.split('\n')
        data_start_index = next((i for i, line in enumerate(lines) if line.strip().startswith('Year,')), -1)
        if data_start_index == -1: return None
        df = pd.read_csv(io.StringIO("\n".join(lines[data_start_index:])))
        df.columns = [c.strip() for c in df.columns]
        months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
        present_months = [m for m in months if m in df.columns]
        df_long = df.melt(id_vars=['Year'], value_vars=present_months, var_name='Month', value_name='Anomaly')
        month_map = {name: num for num, name in enumerate(months, 1)}
        df_long['date'] = pd.to_datetime(df_long['Year'].astype(str) + '-' + df_long['Month'].map(month_map).astype(str), errors='coerce')
        df_final = df_long[['date']].copy()
        df_final['value'] = pd.to_numeric(df_long['Anomaly'], errors='coerce')
        df_final['group'] = 'ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ)'
        return df_final.dropna(subset=['date', 'value'])
    except Exception as e:
        st.sidebar.error(f"GISTEMP ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data(ttl=3600)
def fetch_noaa_co2_data() -> Optional[pd.DataFrame]:
    """Fetch and parse NOAA Mauna Loa CO2 data."""
    resp = retry_get(CONFIG["noaa_co2_url"], max_retries=1)
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8')
        lines = [line for line in content.split('\n') if not line.strip().startswith('#')]
        df = pd.read_csv(io.StringIO('\n'.join(lines)), delim_whitespace=True, header=None,
                         names=['year', 'month', 'decimal_date', 'value', 'value_deseasonalized', 'num_days', 'stdev', 'unc'])
        df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))
        df_final = df[['date', 'value']].copy()
        df_final['group'] = 'ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm)'
        return df_final[df_final['value'] > 0].reset_index(drop=True)
    except Exception as e:
        st.sidebar.error(f"NOAA CO2 ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data(ttl=3600)
def fetch_worldbank_employment() -> Optional[pd.DataFrame]:
    """Fetch World Bank API for Employment in industry, including ISO codes."""
    params = {'format': 'json', 'per_page': '20000'}
    resp = retry_get(CONFIG["worldbank_api_url"], params=params, max_retries=1)
    if resp is None: return None
    try:
        data = resp.json()
        if not isinstance(data, list) or len(data) < 2 or not data[1]: return None
        df = pd.json_normalize(data[1])
        df = df[['country.value', 'countryiso3code', 'date', 'value']]
        df.columns = ['group', 'iso_code', 'year', 'value']
        df['date'] = pd.to_datetime(df['year'] + '-01-01', errors='coerce')
        return df[['date', 'group', 'iso_code', 'value']].dropna()
    except Exception as e:
        st.sidebar.error(f"World Bank ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def get_sample_climate_data() -> pd.DataFrame:
    """Generate sample climate data as a fallback."""
    dates = pd.date_range(end=TODAY, periods=14*12, freq='MS')
    values = np.round(np.linspace(0.4, 1.2, len(dates)) + np.random.normal(0, 0.05, len(dates)), 3)
    return pd.DataFrame({'date': dates, 'value': values, 'group': 'ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ)'})

def get_sample_co2_data() -> pd.DataFrame:
    """Generate sample CO2 data as a fallback."""
    dates = pd.date_range(end=TODAY, periods=14*12, freq='MS')
    values = np.round(np.linspace(380, 420, len(dates)) + np.random.normal(0, 0.5, len(dates)), 2)
    return pd.DataFrame({'date': dates, 'value': values, 'group': 'ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm)'})

def get_sample_employment_data() -> pd.DataFrame:
    """Generate sample employment data as a fallback."""
    years = pd.date_range(start=f"{TODAY.year-9}-01-01", end=f"{TODAY.year}-01-01", freq='AS')
    data = []
    countries = {'í•œêµ­(ì˜ˆì‹œ)': 'KOR', 'OECD í‰ê· (ì˜ˆì‹œ)': 'OED'}
    for country, code in countries.items():
        base_value = 24.0 if 'í•œêµ­' in country else 22.0
        for year in years:
            data.append({'date': year, 'group': country, 'iso_code': code, 'value': float(base_value + np.random.normal(0, 0.8))})
    return pd.DataFrame(data)

@st.cache_data
def get_sample_renewable_data() -> pd.DataFrame:
    """Generate sample renewable energy data as a fallback."""
    years = list(range(2010, 2024))
    data = {
        'ì—°ë„': years,
        'íƒœì–‘ê´‘ (TWh)': [30 + i**2.1 for i in range(len(years))],
        'í’ë ¥ (TWh)': [80 + i**2.3 for i in range(len(years))],
        'ìˆ˜ë ¥ (TWh)': [3400 + i*30 for i in range(len(years))],
    }
    df = pd.DataFrame(data)
    df_melted = df.melt(id_vars='ì—°ë„', var_name='ì—ë„ˆì§€ì›', value_name='ë°œì „ëŸ‰ (TWh)')
    return df_melted

# ==============================================================================
# 2. UI RENDERING FUNCTIONS
# ==============================================================================
def display_public_data_tab(climate_df: pd.DataFrame, co2_df: pd.DataFrame, employment_df: pd.DataFrame, renewable_df: pd.DataFrame):
    """Render the content for the public data dashboard tab."""
    st.header("ğŸ“ˆ ê³µì‹ ê³µê°œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„")
    st.markdown("NASA (ê¸°ì˜¨), NOAA (COâ‚‚), World Bank (ê³ ìš©)ì˜ ê³µê°œ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´ë©ë‹ˆë‹¤.")

    with st.container(border=True):
        st.subheader("ğŸ“Š í•µì‹¬ ì§€í‘œ ìš”ì•½", divider='rainbow')
        try:
            latest_climate = climate_df.sort_values('date', ascending=False).iloc[0]
            latest_co2 = co2_df.sort_values('date', ascending=False).iloc[0]
            col1, col2, col3 = st.columns(3)
            col1.metric(f"ìµœì‹  ì˜¨ë„ ì´ìƒì¹˜ ({latest_climate['date']:%Y-%m})", f"{latest_climate['value']:.2f} â„ƒ")
            col2.metric(f"ìµœì‹  COâ‚‚ ë†ë„ ({latest_co2['date']:%Y-%m})", f"{latest_co2['value']:.2f} ppm")
            col3.metric("ê³ ìš© ë°ì´í„° êµ­ê°€ ìˆ˜", f"{employment_df['group'].nunique()} ê°œ")
        except (IndexError, ValueError):
            st.info("í•µì‹¬ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    
    st.markdown("<br>", unsafe_allow_html=True)

    c1, c2 = st.columns(2)
    with c1:
        with st.container(border=True):
            st.subheader("ğŸŒ¡ï¸ ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜")
            show_trendline = st.checkbox("5ë…„ ì´ë™í‰ê·  ì¶”ì„¸ì„ ", value=True, key="trend_cb")
            if not climate_df.empty:
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=climate_df['date'], y=climate_df['value'], mode='lines', name='ì›”ë³„ ì´ìƒì¹˜', line=dict(width=1, color='lightblue')))
                if show_trendline:
                    climate_df['trend'] = climate_df['value'].rolling(window=60, min_periods=12).mean()
                    fig.add_trace(go.Scatter(x=climate_df['date'], y=climate_df['trend'], mode='lines', name='5ë…„ ì´ë™í‰ê· ', line=dict(width=3, color='royalblue')))
                st.plotly_chart(fig, use_container_width=True)
                st.download_button("ì˜¨ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", climate_df.to_csv(index=False, encoding='utf-8-sig'), "climate_data.csv", "text/csv", key="dl_climate")

    with c2:
        with st.container(border=True):
            st.subheader("ğŸ’¨ ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„")
            st.markdown("<p style='font-size: smaller;'>í•˜ì™€ì´ ë§ˆìš°ë‚˜ë¡œì•„ ê´€ì¸¡ì†Œ ê¸°ì¤€</p>", unsafe_allow_html=True)
            if not co2_df.empty:
                fig = px.line(co2_df, x='date', y='value', labels={'date': 'ë‚ ì§œ', 'value': 'COâ‚‚ (ppm)'})
                st.plotly_chart(fig, use_container_width=True)
                st.download_button("COâ‚‚ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", co2_df.to_csv(index=False, encoding='utf-8-sig'), "co2_data.csv", "text/csv", key="dl_co2")

    st.markdown("<br>", unsafe_allow_html=True)

    with st.container(border=True):
        st.subheader("ğŸ­ ì‚°ì—…ë³„ ê³ ìš© ë¹„ìœ¨ ë³€í™”")
        if not employment_df.empty:
            employment_df['year'] = employment_df['date'].dt.year
            min_year = int(employment_df['year'].min())
            max_year = int(employment_df['year'].max())
            selected_year = st.slider("ì—°ë„ë¥¼ ì„ íƒí•˜ì—¬ ì§€ë„ë¥¼ ë³€ê²½í•˜ì„¸ìš”:", min_year, max_year, max_year)
            st.markdown(f"**{selected_year}ë…„ ê¸°ì¤€ ì „ ì„¸ê³„ ì‚°ì—… ê³ ìš© ë¹„ìœ¨ (Choropleth Map)**")
            map_df = employment_df[employment_df['year'] == selected_year]
            if not map_df.empty:
                fig_map = px.choropleth(map_df, locations="iso_code", color="value", hover_name="group", color_continuous_scale=px.colors.sequential.Plasma, labels={'value': 'ê³ ìš© ë¹„ìœ¨ (%)'})
                st.plotly_chart(fig_map, use_container_width=True)
            else:
                st.warning(f"{selected_year}ë…„ì—ëŠ” í‘œì‹œí•  ê³ ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown("**êµ­ê°€ë³„ ì‚°ì—… ê³ ìš© ë¹„ìœ¨ ì¶”ì´ ë¹„êµ**")
            all_countries = sorted(employment_df['group'].unique())
            default_countries = [c for c in ['World', 'Korea, Rep.', 'China', 'United States', 'Germany'] if c in all_countries] or all_countries[:3]
            selected_countries = st.multiselect("ë¹„êµí•  êµ­ê°€ë¥¼ ì„ íƒí•˜ì„¸ìš”:", all_countries, default=default_countries)
            if selected_countries:
                comp_df = employment_df[employment_df['group'].isin(selected_countries)]
                fig_comp = px.line(comp_df, x='year', y='value', color='group', labels={'year':'ì—°ë„', 'value':'ì‚°ì—… ê³ ìš© ë¹„ìœ¨(%)', 'group':'êµ­ê°€'})
                st.plotly_chart(fig_comp, use_container_width=True)
                st.download_button("ì„ íƒ êµ­ê°€ ê³ ìš© ë°ì´í„° ë‹¤ìš´ë¡œë“œ", comp_df.to_csv(index=False, encoding='utf-8-sig'), "employment_selected.csv", "text/csv", key="dl_emp")

    st.markdown("<br>", unsafe_allow_html=True)

    c3, c4 = st.columns(2)
    with c3:
        with st.container(border=True):
            st.subheader("ğŸ”„ ê¸°í›„ ì§€í‘œ vs. ì‚°ì—… ê³ ìš© ìƒê´€ê´€ê³„")
            try:
                c_ann = climate_df.copy(); c_ann['year'] = c_ann['date'].dt.year
                c_ann_agg = c_ann.groupby('year')['value'].mean().reset_index().rename(columns={'value':'temp_anomaly'})
                co2_ann = co2_df.copy(); co2_ann['year'] = co2_ann['date'].dt.year
                co2_ann_agg = co2_ann.groupby('year')['value'].mean().reset_index().rename(columns={'value':'co2_ppm'})
                e_ann = employment_df.copy(); e_ann['year'] = e_ann['date'].dt.year
                e_ann_agg = e_ann.groupby('year')['value'].median().reset_index().rename(columns={'value':'employment_median'})
                merged = pd.merge(c_ann_agg, e_ann_agg, on='year', how='inner')
                merged = pd.merge(merged, co2_ann_agg, on='year', how='inner')
                
                corr_choice = st.selectbox("ê³ ìš© ë°ì´í„°ì™€ ë¹„êµí•  ê¸°í›„ ì§€í‘œë¥¼ ì„ íƒí•˜ì„¸ìš”:", ('ì˜¨ë„ ì´ìƒì¹˜', 'COâ‚‚ ë†ë„'))
                normalize = st.checkbox("ë°ì´í„° ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼)", help="ë‹¨ìœ„ê°€ ë‹¤ë¥¸ ë‘ ë°ì´í„°ë¥¼ 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ì„¸ ë¹„êµë¥¼ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.")
                
                x_var = 'temp_anomaly' if corr_choice == 'ì˜¨ë„ ì´ìƒì¹˜' else 'co2_ppm'
                y_var = 'employment_median'
                plot_df = merged[['year', x_var, y_var]].copy()
                correlation = plot_df[x_var].corr(plot_df[y_var])
                st.metric(f"{corr_choice} vs. ê³ ìš© ë¹„ìœ¨ ìƒê´€ê³„ìˆ˜", f"{correlation:.3f}", help="Pearson ìƒê´€ê³„ìˆ˜. 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„, -1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.")
                
                if normalize:
                    plot_df[x_var] = normalize_series(plot_df[x_var])
                    plot_df[y_var] = normalize_series(plot_df[y_var])
                fig_corr = go.Figure()
                fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[x_var], name=corr_choice, yaxis='y1'))
                fig_corr.add_trace(go.Scatter(x=plot_df['year'], y=plot_df[y_var], name='ì‚°ì—… ê³ ìš©(ì „ì„¸ê³„ ì¤‘ì•™ê°’)', yaxis='y2'))
                fig_corr.update_layout(title_text=f"ì—°ë„ë³„ {corr_choice}ì™€ ì‚°ì—… ê³ ìš© ë¹„ìœ¨ ë¹„êµ", yaxis=dict(title=f"{corr_choice} (ì •ê·œí™”)" if normalize else ('â„ƒ' if x_var=='temp_anomaly' else 'ppm')), yaxis2=dict(title="ì‚°ì—… ê³ ìš© ë¹„ìœ¨ (ì •ê·œí™”)" if normalize else "%", overlaying='y', side='right'))
                st.plotly_chart(fig_corr, use_container_width=True)
                st.download_button("ìƒê´€ê´€ê³„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", plot_df.to_csv(index=False, encoding='utf-8-sig'), "correlation_data.csv", "text/csv", key="dl_corr")
            except Exception as e:
                st.error(f"ìƒê´€ê´€ê³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    with c4:
        with st.container(border=True):
            st.subheader("â˜€ï¸ ì „ ì„¸ê³„ ì¬ìƒì—ë„ˆì§€ ë°œì „ëŸ‰ (ì˜ˆì‹œ)")
            st.markdown("<p style='font-size: smaller;'>IEA ë“± êµ­ì œê¸°êµ¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì˜ˆì‹œ ë°ì´í„°ì…ë‹ˆë‹¤.</p>", unsafe_allow_html=True)
            fig = px.area(renewable_df, x='ì—°ë„', y='ë°œì „ëŸ‰ (TWh)', color='ì—ë„ˆì§€ì›', title='ì¬ìƒì—ë„ˆì§€ì›ë³„ ë°œì „ëŸ‰ ì¶”ì´')
            st.plotly_chart(fig, use_container_width=True)
            st.download_button("ì¬ìƒì—ë„ˆì§€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", renewable_df.to_csv(index=False, encoding='utf-8-sig'), "renewable_data.csv", "text/csv", key="dl_renewable")


def display_user_prompt_tab():
    """Render the content for the user prompt simulation tab."""
    st.header("ğŸ“„ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„")
    st.markdown("ì™¸ë¶€ ë¦¬í¬íŠ¸ì˜ ì˜ˆì¸¡ì„ ë°”íƒ•ìœ¼ë¡œ, **ì‚¬ìš©ìê°€ ì§ì ‘ ë³€ìˆ˜ë¥¼ ì¡°ì ˆ**í•˜ë©° ë¯¸ë˜ ì¼ìë¦¬ ë³€í™”ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    with st.container(border=True):
        st.subheader("âš™ï¸ ì‹œë‚˜ë¦¬ì˜¤ ë³€ìˆ˜ ì¡°ì ˆ", divider='rainbow')
        col1, col2 = st.columns(2)
        green_growth_rate = col1.slider("ì—°ê°„ ë…¹ìƒ‰ ì¼ìë¦¬ ì„±ì¥ë¥  (%)", 1.0, 20.0, 10.0, 0.5) / 100
        fossil_decline_rate = col2.slider("ì—°ê°„ í™”ì„ì—°ë£Œ ì¼ìë¦¬ ê°ì†Œìœ¨ (%)", 1.0, 20.0, 8.0, 0.5) / 100
        
    st.markdown("<br>", unsafe_allow_html=True)
    
    with st.container(border=True):
        years = list(range(2025, 2042))
        green_jobs = [500]
        fossil_jobs = [1000]
        for _ in range(1, len(years)):
            green_jobs.append(green_jobs[-1] * (1 + green_growth_rate))
            fossil_jobs.append(fossil_jobs[-1] * (1 - fossil_decline_rate))
        user_jobs_df = pd.DataFrame({
            'date': pd.to_datetime([datetime.date(y, 1, 1) for y in years] * 2),
            'group': ['ë…¹ìƒ‰ ì¼ìë¦¬(ë§Œ ê°œ)'] * len(years) + ['í™”ì„ì—°ë£Œ ì¼ìë¦¬(ë§Œ ê°œ)'] * len(years),
            'value': green_jobs + fossil_jobs
        })
        st.subheader(f"ğŸ’¼ {years[0]}ë…„ ~ {years[-1]}ë…„ ì¼ìë¦¬ ë³€í™” ì‹œë®¬ë ˆì´ì…˜")
        fig = px.line(user_jobs_df, x='date', y='value', color='group', labels={'date':'ì—°ë„', 'value':'ì´ ì¼ìë¦¬ ìˆ˜(ë§Œ ê°œ)', 'group':'êµ¬ë¶„'})
        st.plotly_chart(fig, use_container_width=True)
        st.markdown(f"**{years[-1]}ë…„ ì˜ˆì¸¡ ê²°ê³¼**")
        m1, m2, m3 = st.columns(3)
        final_green = user_jobs_df[user_jobs_df['group'] == 'ë…¹ìƒ‰ ì¼ìë¦¬(ë§Œ ê°œ)']['value'].iloc[-1]
        final_fossil = user_jobs_df[user_jobs_df['group'] == 'í™”ì„ì—°ë£Œ ì¼ìë¦¬(ë§Œ ê°œ)']['value'].iloc[-1]
        m1.metric("ë…¹ìƒ‰ ì¼ìë¦¬", f"{final_green:,.0f} ë§Œ ê°œ")
        m2.metric("í™”ì„ì—°ë£Œ ì¼ìë¦¬", f"{final_fossil:,.0f} ë§Œ ê°œ")
        m3.metric("ì´ ì¼ìë¦¬ ë³€í™”", f"{((final_green + final_fossil) - (500 + 1000)):,.0f} ë§Œ ê°œ", delta_color="off")
        st.download_button("ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", user_jobs_df.to_csv(index=False, encoding='utf-8-sig'), "scenario_data.csv", "text/csv", key="dl_scenario")

def display_report_page():
    """Render the content for the static analysis report page."""
    st.title("ğŸ“ ê¸°í›„ë³€í™”ì™€ ì·¨ì—… ë³´ê³ ì„œ")
    
    with st.container(border=True):
        st.header("ì„œë¡ ")
        st.write("""
        ìµœê·¼ ê¸°í›„ìœ„ê¸°ëŠ” ë‹¨ìˆœí•œ í™˜ê²½ ë¬¸ì œê°€ ì•„ë‹ˆë¼ **ì²­ë…„ì˜ ë¯¸ë˜ ì§ì—… ì„ íƒ**ì—ë„ í° ì˜í–¥ì„ ì£¼ê³  ìˆìŠµë‹ˆë‹¤.
        
        ë³¸ ë³´ê³ ì„œëŠ” ê¸°í›„ë³€í™”ê°€ ì‚°ì—… êµ¬ì¡°ì™€ ê³ ìš©ë¥ ì— ì–´ë–¤ ë³€í™”ë¥¼ ì¼ìœ¼í‚¤ëŠ”ì§€, íŠ¹íˆ ì²­ë…„ ì·¨ì—…ë¥ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
        """)
    st.markdown("<br>", unsafe_allow_html=True)
    with st.container(border=True):
        st.header("ë³¸ë¡ ")
        st.subheader("1. ê¸°í›„ ë³€í™”ì™€ ì‚°ì—… êµ¬ì¡° ë³€í™”", divider='blue')
        st.write("""
        - NASA ê¸°ì˜¨ ë°ì´í„°ì— ë”°ë¥´ë©´ ì§€êµ¬ í‰ê·  ê¸°ì˜¨ì€ ê¾¸ì¤€íˆ ìƒìŠ¹í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        - ì´ë¡œ ì¸í•´ **ë…¹ìƒ‰ì‚°ì—… ì¼ìë¦¬**ëŠ” ë§¤ë…„ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ë°˜ëŒ€ë¡œ **í™”ì„ì—°ë£Œ ê´€ë ¨ ì¼ìë¦¬**ëŠ” ê°ì†Œì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.
        """)
        st.subheader("2. ì²­ë…„ ì·¨ì—…ë¥  ë³€í™”", divider='blue')
        st.write("""
        - í•œêµ­ì§ì—…ëŠ¥ë ¥ì—°êµ¬ì›(YPEC) í†µê³„ì— ë”°ë¥´ë©´ ëŒ€ì¡¸ ì²­ë…„ ì·¨ì—…ë¥ ì€ 2017ë…„ ì•½ 67%ì—ì„œ 2022ë…„ 68% ìˆ˜ì¤€ìœ¼ë¡œ ë“±ë½ì„ ë°˜ë³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.
        - ê·¸ëŸ¬ë‚˜ **ì¹œí™˜ê²½ ì „ê³µ ì·¨ì—…ë¥ ì€ ê¾¸ì¤€íˆ ìƒìŠ¹**í•˜ëŠ” ë°˜ë©´, **ë¹„ì¹œí™˜ê²½ ì „ê³µ ì·¨ì—…ë¥ ì€ í•˜ë½ì„¸**ë¥¼ ë³´ì…ë‹ˆë‹¤.
        """)
        st.subheader("3. ì •ì±…ê³¼ ë¯¸ë˜ ì§ì—… ë°©í–¥", divider='blue')
        st.write("""
        - ê³ ìš©ë…¸ë™ë¶€ì™€ ì •ë¶€ëŠ” íƒ„ì†Œì¤‘ë¦½ ì •ì±…ì„ í†µí•´ ë…¹ìƒ‰ì‚°ì—…ì— ëŒ€í•œ íˆ¬ìë¥¼ í™•ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        - ì•ìœ¼ë¡œì˜ ì²­ë…„ ì·¨ì—… ê¸°íšŒëŠ” **ì‹ ì¬ìƒì—ë„ˆì§€, ì¹œí™˜ê²½ êµí†µ, ê¸°í›„ê¸°ìˆ  ê°œë°œ ë¶„ì•¼**ì—ì„œ í¬ê²Œ ëŠ˜ì–´ë‚  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤.
        """)
    st.markdown("<br>", unsafe_allow_html=True)
    with st.container(border=True):
        st.header("ê²°ë¡ ")
        st.write("""
        ê¸°í›„ìœ„ê¸°ëŠ” ìœ„ê¸°ì´ì ê¸°íšŒì…ë‹ˆë‹¤.
        
        ì‚°ì—… êµ¬ì¡° ì „í™˜ ì†ì—ì„œ ì²­ë…„ë“¤ì´ **ì¹œí™˜ê²½Â·ë…¹ìƒ‰ ë¶„ì•¼ ì „ê³µ ë° ì§ì—… ì—­ëŸ‰**ì„ ê°–ì¶˜ë‹¤ë©´ ì•ˆì •ì ì´ê³  ìœ ë§í•œ ì¼ìë¦¬ë¥¼ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        ë”°ë¼ì„œ ê¸°í›„ë¥¼ ê³ ë ¤í•œ ì§„ë¡œ ì„ íƒì€ ë‹¨ìˆœí•œ í™˜ê²½ ë³´í˜¸ ì°¨ì›ì´ ì•„ë‹ˆë¼ **ë¯¸ë˜ ì·¨ì—… ì „ëµ**ì´ê¸°ë„ í•©ë‹ˆë‹¤.
        """)
    
    st.markdown("---")
    st.caption("ì¶œì²˜: NASA GISTEMP, ê³ ìš©ë…¸ë™ë¶€ ë³´ë„ìë£Œ, í•œêµ­ì§ì—…ëŠ¥ë ¥ì—°êµ¬ì›(YPEC), ê¸°í›„ë³€í™”í–‰ë™ì—°êµ¬ì†Œ, ê¸°í›„í™˜ê²½í¬í„¸ ë“±")

def display_future_jobs_page():
    """Render the content for the promising future jobs page."""
    st.title("ğŸ’¼ ë¯¸ë˜ ìœ ë§ ë…¹ìƒ‰ ì§ì—…")
    st.markdown("ê¸°í›„ ë³€í™” ëŒ€ì‘ì€ ìƒˆë¡œìš´ ì§ì—… ì‹œì¥ì„ ì—´ê³  ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ì£¼ëª©ë°›ëŠ” ìœ ë§ ì§ì—… ë¶„ì•¼ì…ë‹ˆë‹¤.")

    c1, c2 = st.columns(2)
    with c1:
        with st.container(border=True):
            st.header("â˜€ï¸ ì¬ìƒì—ë„ˆì§€ ë¶„ì•¼")
            st.image("https://images.unsplash.com/photo-1558495033-69b14739265f?q=80&w=2070&auto=format&fit=crop", caption="í’ë ¥ ë°œì „ì†Œì˜ í•´ì§ˆë…˜")
            with st.expander("**1. íƒœì–‘ê´‘/í’ë ¥ ë°œì „ ì„¤ë¹„ ê¸°ìˆ ì**"):
                st.markdown("""
                - **ì£¼ìš” ì—…ë¬´**: íƒœì–‘ê´‘ íŒ¨ë„, í’ë ¥ í„°ë¹ˆ ë“± ë°œì „ ì„¤ë¹„ì˜ ì„¤ì¹˜, ìœ ì§€ë³´ìˆ˜, ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
                - **í•„ìš” ì—­ëŸ‰**: ì „ê¸°/ì „ì ê³µí•™ ì§€ì‹, ê¸°ê³„ ì„¤ë¹„ ì´í•´, í˜„ì¥ ì‹¤ë¬´ ëŠ¥ë ¥, ë“œë¡  ì¡°ì¢… ëŠ¥ë ¥(ì ê²€ìš©)
                - **ì˜ˆìƒ ì—°ë´‰**: ì´ˆë´‰ 4,000 ~ 6,000ë§Œì›, ê²½ë ¥ì— ë”°ë¼ 1ì–µ ì´ìƒ ê°€ëŠ¥
                """)
            with st.expander("**2. ì—ë„ˆì§€ ì €ì¥ ì‹œìŠ¤í…œ(ESS) ì „ë¬¸ê°€**"):
                st.markdown("""
                - **ì£¼ìš” ì—…ë¬´**: ìƒì‚°ëœ ì „ë ¥ì„ ì €ì¥í•˜ê³  í•„ìš”í•  ë•Œ ê³µê¸‰í•˜ëŠ” ESSì˜ ì„¤ê³„, êµ¬ì¶•, ìš´ì˜
                - **í•„ìš” ì—­ëŸ‰**: í™”í•™ê³µí•™(ë°°í„°ë¦¬), ì „ë ¥ ì‹œìŠ¤í…œ, ë°ì´í„° ë¶„ì„, ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ëŠ¥ë ¥
                - **ì˜ˆìƒ ì—°ë´‰**: ì´ˆë´‰ 5,000 ~ 7,000ë§Œì›, ê¸°ìˆ  ì „ë¬¸ì„±ì— ë”°ë¼ ê³ ì—°ë´‰ í˜•ì„±
                """)
    
    with c2:
        with st.container(border=True):
            st.header("ğŸš— ì¹œí™˜ê²½ ëª¨ë¹Œë¦¬í‹° ë¶„ì•¼")
            st.image("https://images.unsplash.com/photo-1617886322207-6f504e7472c5?q=80&w=2070&auto=format&fit=crop", caption="ì¶©ì „ ì¤‘ì¸ ì „ê¸°ì°¨")
            with st.expander("**1. ì „ê¸°ì°¨(EV) ë°°í„°ë¦¬ ì—”ì§€ë‹ˆì–´**"):
                st.markdown("""
                - **ì£¼ìš” ì—…ë¬´**: ì „ê¸°ì°¨ì˜ í•µì‹¬ì¸ ë°°í„°ë¦¬ ì…€/ëª¨ë“ˆ/íŒ©ì˜ ì—°êµ¬ê°œë°œ, ì„¤ê³„, í…ŒìŠ¤íŠ¸
                - **í•„ìš” ì—­ëŸ‰**: í™”í•™/ì¬ë£Œê³µí•™, ì „ìíšŒë¡œ, ì—´ ê´€ë¦¬ ì‹œìŠ¤í…œì— ëŒ€í•œ ê¹Šì€ ì´í•´
                - **ì˜ˆìƒ ì—°ë´‰**: ì´ˆë´‰ 6,000 ~ 8,000ë§Œì›, R&D ë¶„ì•¼ ìµœê³  ìˆ˜ì¤€ ëŒ€ìš°
                """)
            with st.expander("**2. ììœ¨ì£¼í–‰ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì**"):
                st.markdown("""
                - **ì£¼ìš” ì—…ë¬´**: ì°¨ëŸ‰ì˜ ì„¼ì„œ ë°ì´í„°(ì¹´ë©”ë¼, ë¼ì´ë‹¤)ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì£¼í–‰ì„ ì œì–´í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ ê°œë°œ
                - **í•„ìš” ì—­ëŸ‰**: ì»´í“¨í„° ê³µí•™, ì¸ê³µì§€ëŠ¥(AI), ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹, C++/Python í”„ë¡œê·¸ë˜ë°
                - **ì˜ˆìƒ ì—°ë´‰**: ì´ˆë´‰ 7,000ë§Œì› ì´ìƒ, IT ì—…ê³„ ìµœìƒìœ„ê¶Œ
                """)

    st.markdown("<br>", unsafe_allow_html=True)

    with st.container(border=True):
        st.header("ğŸŒ³ í™˜ê²½ ë° ì§€ì†ê°€ëŠ¥ì„± ë¶„ì•¼")
        st.image("https://images.unsplash.com/photo-1542601906-8e9a43a4925b?q=80&w=2070&auto=format&fit=crop", caption="ìˆ²ì—ì„œ í™˜ê²½ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ëª¨ìŠµ")
        with st.expander("**1. ESG ì»¨ì„¤í„´íŠ¸**"):
            st.markdown("""
            - **ì£¼ìš” ì—…ë¬´**: ê¸°ì—…ì´ í™˜ê²½(Environment), ì‚¬íšŒ(Social), ì§€ë°°êµ¬ì¡°(Governance) ì¸¡ë©´ì—ì„œ ì§€ì†ê°€ëŠ¥í•œ ê²½ì˜ì„ í•˜ë„ë¡ ì „ëµ ìˆ˜ë¦½ ë° ìë¬¸
            - **í•„ìš” ì—­ëŸ‰**: ê²½ì˜/ê²½ì œí•™, í™˜ê²½ ì •ì±… ì´í•´, ë°ì´í„° ë¶„ì„, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥
            - **ì˜ˆìƒ ì—°ë´‰**: ì»¨ì„¤íŒ… íŒ ì§ê¸‰ì— ë”°ë¼ ìƒì´ (ì´ˆë´‰ 5,000ë§Œì› ì´ìƒ)
            """)
        with st.expander("**2. íƒ„ì†Œë°°ì¶œê¶Œ ê±°ë˜ ì „ë¬¸ê°€**"):
            st.markdown("""
            - **ì£¼ìš” ì—…ë¬´**: ê¸°ì—…ì´ë‚˜ êµ­ê°€ì˜ íƒ„ì†Œ ë°°ì¶œëŸ‰ì„ ë¶„ì„í•˜ê³ , ë°°ì¶œê¶Œ ê±°ë˜ ì‹œì¥ì—ì„œ ë§¤ë§¤ë¥¼ í†µí•´ ì´ìµì„ ì°½ì¶œí•˜ê±°ë‚˜ ë¹„ìš©ì„ ì ˆê°
            - **í•„ìš” ì—­ëŸ‰**: ê¸ˆìœµ/ê²½ì œ, í™˜ê²½ ê·œì œ ì§€ì‹, ì‹œì¥ ë¶„ì„ ëŠ¥ë ¥, ë¦¬ìŠ¤í¬ ê´€ë¦¬
            - **ì˜ˆìƒ ì—°ë´‰**: ê¸ˆìœµê¶Œ ìˆ˜ì¤€ì˜ ë†’ì€ ì—°ë´‰ (ì„±ê³¼ê¸‰ ë¹„ì¤‘ ë†’ìŒ)
            """)
        with st.expander("**3. ìŠ¤ë§ˆíŠ¸íŒœ ì „ë¬¸ê°€**"):
            st.markdown("""
            - **ì£¼ìš” ì—…ë¬´**: ì •ë³´í†µì‹ ê¸°ìˆ (ICT)ì„ ë†ì—…ì— ì ‘ëª©í•˜ì—¬ ìƒì‚° íš¨ìœ¨ì„ ë†’ì´ê³ , ê¸°í›„ ë³€í™”ì— ëŒ€ì‘ ê°€ëŠ¥í•œ ë†ì—… ì‹œìŠ¤í…œì„ êµ¬ì¶•
            - **í•„ìš” ì—­ëŸ‰**: ë†ì—…ìƒëª…ê³¼í•™, ë°ì´í„° ë¶„ì„, ì‚¬ë¬¼ì¸í„°ë„·(IoT) ê¸°ìˆ , ìë™ì œì–´ ì‹œìŠ¤í…œ ì´í•´
            - **ì˜ˆìƒ ì—°ë´‰**: ì´ˆë´‰ 4,000 ~ 5,500ë§Œì›, ê¸°ìˆ  ì°½ì—… ê¸°íšŒ ë‹¤ìˆ˜
            """)

# ==============================================================================
# 3. MAIN APPLICATION LOGIC
# ==============================================================================
def main():
    """Main function to run the Streamlit app."""
    st.title("ê¸°í›„ ë³€í™”ì™€ ì·¨ì—… ë™í–¥ í†µí•© ëŒ€ì‹œë³´ë“œ")

    # --- Data Loading ---
    if 'data_loaded' not in st.session_state:
        st.sidebar.title("ë°ì´í„° ë¡œë“œ ìƒíƒœ")
        with st.spinner("ê³µì‹ ê³µê°œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            climate_raw = fetch_gistemp_csv()
            st.session_state.climate_df = preprocess_dataframe(climate_raw if climate_raw is not None else get_sample_climate_data())
            co2_raw = fetch_noaa_co2_data()
            st.session_state.co2_df = preprocess_dataframe(co2_raw if co2_raw is not None else get_sample_co2_data())
            employment_raw = fetch_worldbank_employment()
            st.session_state.employment_df = preprocess_dataframe(employment_raw if employment_raw is not None else get_sample_employment_data())
            st.session_state.renewable_df = get_sample_renewable_data()
            st.session_state.data_loaded = True
            time.sleep(0.5)
            st.rerun()

    # --- Page Navigation ---
    page = st.sidebar.radio("ğŸ“‘ í˜ì´ì§€ ì„ íƒ", ["ğŸŒ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ", "ğŸ“„ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„", "ğŸ’¼ ë¯¸ë˜ ìœ ë§ ì§ì—…", "ğŸ“ ë¶„ì„ ë³´ê³ ì„œ"])

    if page == "ğŸŒ ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ":
        display_public_data_tab(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df, st.session_state.renewable_df)
    elif page == "ğŸ“„ ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„":
        display_user_prompt_tab()
    elif page == "ğŸ’¼ ë¯¸ë˜ ìœ ë§ ì§ì—…":
        display_future_jobs_page()
    elif page == "ğŸ“ ë¶„ì„ ë³´ê³ ì„œ":
        display_report_page()

    with st.sidebar.expander("ê°œë°œì ë° ì‹¤í–‰ í™˜ê²½ ì°¸ê³ ì‚¬í•­"):
        st.markdown("""
        - ì´ ì•±ì€ NASA/NOAA/WorldBank ê³µê°œ APIë¥¼ ìš°ì„ ì ìœ¼ë¡œ í˜¸ì¶œí•˜ë©°, ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨ ì‹œ ë‚´ì¥ëœ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ì „í™˜ë©ë‹ˆë‹¤.
        """)

if __name__ == "__main__":
    try:
        if os.path.exists(CONFIG["font_path"]):
            st.markdown(f"""
            <style>
            @font-face {{ font-family: 'PretendardCustom'; src: url('{CONFIG["font_path"]}') format('truetype'); }}
            html, body, [class*="css"] {{ font-family: 'PretendardCustom', Pretard, sans-serif; }}
            </style>""", unsafe_allow_html=True)
    except Exception: pass
    main()

